{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AssnWUVlxtH"
      },
      "source": [
        "https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/directory_loader.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fulYnj9nZr3n",
        "outputId": "358cd3d8-43a3-41dd-efd5-60e2679a91b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "directory = './content/data'\n",
        "\n",
        "def load_docs(directory):\n",
        "  loader = DirectoryLoader(directory)\n",
        "  documents = loader.load()\n",
        "  return documents\n",
        "\n",
        "documents = load_docs(directory)\n",
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwaCosqsogzw"
      },
      "source": [
        "https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lF8jA6xZ0Hm",
        "outputId": "f52c114c-231a-4d77-aeef-285a041dcd07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2047\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def split_docs(documents, chunk_size=500, chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  return docs\n",
        "\n",
        "docs = split_docs(documents)\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content=\"[00:00:00] Sam Charrington: All right, everyone. I am here with longtime friend of the show, John Bohannon, who is Director of Science at Primer AI. If you recognize John's name and maybe from his May, 2018 interview or his appearance in our TWIML Fest Office Hours which were focused on NLP back in October of last year.\\n\\nJohn, it is so great to have you back on the show.\\n\\n[00:00:25] John Bohannon: Welcome. Great to be back.\" metadata={'source': 'content/data/550 - John Bohannon.txt'}\n",
            "page_content=\"[00:00:59] John Bohannon: Yeah. First of all, this has been so fun over the past week. I've been preparing for this. I don't think anyone's keeping up with everything in NLP. There's just so much happening. So I really had to dig in, talk to my team, really review. So I've learned a ton. The big picture that emerged for me at least was two things.\" metadata={'source': 'content/data/550 - John Bohannon.txt'}\n"
          ]
        }
      ],
      "source": [
        "print(docs[0])\n",
        "print(docs[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVcFjgHJZ8S9",
        "outputId": "9b14917f-0822-44a2-bda8-47faa5894173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(page_content=\"[00:00:00] Sam Charrington: All right, everyone. I am here with longtime friend of the show, John Bohannon, who is Director of Science at Primer AI. If you recognize John's name and maybe from his May, 2018 interview or his appearance in our TWIML Fest Office Hours which were focused on NLP back in October of last year.\\n\\nJohn, it is so great to have you back on the show.\\n\\n[00:00:25] John Bohannon: Welcome. Great to be back.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:00:29] Sam Charrington: I'm really looking forward to digging into our conversation. This is part of our AI rewind 2021 series. You are going to help us review all of the amazing things that happened in the NLP sphere this past year. We were talking about that a little bit before we started. The big news in summary was I'll let you say it.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:00:59] John Bohannon: Yeah. First of all, this has been so fun over the past week. I've been preparing for this. I don't think anyone's keeping up with everything in NLP. There's just so much happening. So I really had to dig in, talk to my team, really review. So I've learned a ton. The big picture that emerged for me at least was two things.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"One is that what we used to call NLP? Just text, text in stuff comes out. But nothing else. That seems to be chilling out. That like for the past few years it didn't seem like a month would go by without some huge revolution, some brand new architectures and totally new way of dealing with the data.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Now that's like flattening out and we're in what I think you can call the incremental phase of the science. So the big explosion, and now it's just like heads down trying to make it more efficient, just better. Then the second big theme that emerged for me was that NLP is like eating up the rest of ML.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"They used to say like a software's eating the world and then it was ML eating software. Now I think NLP is eating ML because computer vision and language are just coming together. So I think that was the most, freakishly new, really cool stuff. The rest is just get into business, making it work.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:02:32] Sam Charrington: Yeah. That's awesome. In fact, that theme was the core that latter of the two themes that you mentioned was the core of the conversation in our computer vision episode in the AI rewind series. I think we'll talk about it from, well, obviously a slightly different take in this conversation but so far the consensus is that, that has absolutely been the case.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Let's maybe dive into that particular point. What were some of the specific things that you saw that led to this feeling of NLP eating the world?\\n\\n[00:03:13] John Bohannon: It was right in January of this year that Dolly came out. Open eyes, just crushing it, opening eyes, just owning this weird new hybrid space. They're clearly having a blast. You almost giggle while you read their papers, you could just tell how fun it is to do this new work.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:03:33] Sam Charrington: I mean, we were talking earlier about how hard it is to keep up with the space, but it's hard to keep up with just open AI.\\n\\n[00:03:39] John Bohannon: Yeah. I know, I know. God, it's just a really exciting time. So, Dolly was followed by CLIP and most recently we have this new thing called Glide. That just came out like in the recent, like past week or two. I actually played with it this morning and I emailed you some of the output.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='I was just playing with it this morning. It\\'s just getting so dang good. You just literally use language to ask a model to generate images that you want. One way that we\\'ve been using it, you can actually make it do useful work, too. You can do image search. So if you\\'ve got a whole bunch of images, let\\'s say that you\\'ve harvested from Twitter or something, and you want to say, \"Hey, find me, blah.\" You just describe it, like write the caption for an image you think exists. So you just take all', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='So you just take all those images and you put them into this embedding space that lives in the same world as the text. So it takes your text. It finds that high dimensional address. Then it just goes finds images that are in that neighborhood and shows it to you. So like semantic search on images is suddenly really, really working.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:04:50] Sam Charrington: Well--\\n\\n[00:04:50] John Bohannon: That's just\\n\\n[00:04:52] Sam Charrington: Yeah. absolutely. The images will maybe include as an overlay in the YouTube video of this interview. The images that you pulled together but maybe contextualize Glide relative to Dolly and CLIP. What are the differences between the two?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:05:07] John Bohannon: Yeah. So Dolly generates images. CLIP is this classifier. That's the thing that knows how to take captions and images? That's the training data originally and put them into a common, high dimensional space so that you can go from text to image or image to text. So Glide is a new innovation where rather than guiding the generator of the images to try and satisfy the caption you gave it, with a classifier, it uses a noising technique so that you actually don't even need\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"don't even need the classifier and the result, which I'm pretty convinced by even sending you those low res images is that it's much better at making photo realistic images.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"You know, up till now, most of the fun that people have been having with VQGAN and CLIP systems has been like dreamy stuff. Something crazy. Like I did a whole holiday themed one at primer where I was just doing variations on Christmas trees. One of them was a Christmas tree growing in a bathroom and sure enough, it created this surreal image of a Christmas tree growing out of a toilet with a hand towel, looking like a Santa hat, just like you're not gonna make anything useful for the world, but\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"for the world, but it's fun.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"But with Glide, they're getting so good that I think it actually will get commercial use and the really cool innovation is in painting. So now you can use this system to make an image. Let's say you're a designer and you want to make a mock-up of a living room or a landscape or whatever it is you're trying to visualize. So you describe it and then you want to change something about it. What you can do is literally like finger paint. You can circle a little zone of the image, and then you can add\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"and then you can add an element. You give, be like a red barn, and then you could go in on that red barn, you'd be like with yellow windows.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So this is the future of Photoshop. There will be a language interface to Photoshop. Either Adobe is gonna do that, or someone's going to eat their lunch.\\n\\nRight? That's what we're going to be using in the future.\\n\\n[00:07:24] Sam Charrington: And so is a Glide using CLIP to--\\n\\n[00:07:28] John Bohannon: No, you don't need it. That's the whole point. You don't need it anymore.\\n\\n[00:07:31] Sam Charrington: Okay.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:07:32] John Bohannon: Yeah, so it's pretty cool. They haven't released the full weights model, but they released a small version which is what I used this morning to send you the a corgi in a robot costume and robot for giant friendly robot visiting St. Louis.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:07:49] Sam Charrington: And those images are... you were just mentioning this but they're generated images based on the text, as opposed to the way you originally described it. It was almost like an image search where it's finding the images.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:08:04] John Bohannon: So the old way, you still need a generator that knows how to take text and try and generate an image. But the way they used to it in the back and I think like from now on, we're not going to be using CLIP to guide that generation. So it starts off with just a random bunch of pixels and then it tries to move in the direction of an image that matches your caption, because there's that common space. So CLIP was doing all that guidance before. Now with Glide, you don't need\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"you don't need CLIP to do that.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:08:35] Sam Charrington: Got it.\\n\\n[00:08:35] John Bohannon: That's the idea and it's pretty fast, too. I mean, even though they're not very high res, it was like a minute per image this morning to make those so I can just play around.\\n\\n[00:08:46] Sam Charrington: That's awesome. That's awesome. Along the same lines, you mentioned a few other models and papers that were in similar vein. What were some of those?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:08:58] John Bohannon: Yeah. So on the theme of NLP eating the world, papers and usable systems that started to merge in chemistry, in medicine, and I think it's just going to keep on going. The general utility of the transformer architecture and the approach of feeding in data in a similar way that we teach these models in an unsupervised fashion language is just starting to pay off. So we've seen protein structure prediction. We've seen chemical formula like manipulation. I think it'll just\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"I think it'll just keep on going. We're going to just keep... it's like a little acid that's eating through problem space. I don't know where it'll stop, but I also don't think it's gonna stop with these things that are like clipping Glide.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"There's nothing special about images other than we just happen to have a whole bunch of data. We have a whole bunch of images with captions. That's super convenient, but I think what's coming next to courses, video, and with robotics, you've got other senses. What about tactile? What about movement? I think that the trend is going to be towards multimodality with a single system. So you'll be able to just describe things in text or show like a video example of what you're trying to get at, or a\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"to get at, or a sketch. You come in from any angle and there will be this massive, common embedding space for all modalities. I think that's probably where we're headed.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:10:45] Sam Charrington: Yeah. A lot of ways, we're approaching this world that NLP folks had been evangelizing for a while in the sense of we create language around all these concepts that we care about. So NLP is a fundamental currency of thought, right? So the NLP community has been arguing that all the work in that field is going to pay off because that's the way we think using language, we communicate using language. Whereas before computer vision was in isolation, that wasn't grounded\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"that wasn't grounded by language. So now we we're starting to bring it all together. What you're saying is we're just getting through.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:11:38] John Bohannon: Oh, yeah. Oh yeah. This is just like the very beginning. A lot of people are saying that video's coming this year. I don't think so. I think that's really hard. I think it's going to be a little while before we have a CLIP or Glide equivalent for video. But what I'm waiting for is that first moment, like the very first moments of audio recording when you get that first hello world moment. Hello, world moment for computer generated video like GAN-style generated video\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"generated video will probably be like a little cartoon animation, like an animated GIF. I don't know why has anyone hasn't done it yet, but...\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:12:21] Sam Charrington: What's thinking that what's the closest thing you've seen?\\n\\n[00:12:24] John Bohannon: I haven't seen a thing. The closest I've seen is you take a real video and then you basically apply something like--\\n\\n[00:12:31] Sam Charrington: Like like transfer kind of thing?\\n\\n[00:12:33] John Bohannon: Yeah. You basically take frame by frame and you just transform it.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So you can find Reddit just flooded with these cute short clips of real video that had been transformed into weird things. But we're sitting on a gold mine of data called Giphy. It's just someone's gotta be doing that right now. Just take that dataset and make a version of CLIP for Giphy so that we can have animated GIFs on demand.\\n\\n[00:12:58] Sam Charrington: Yeah.\\n\\n[00:13:01] John Bohannon: So that's going to be the hello world, and from there, it's onwards.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:13:05] Sam Charrington: Yeah. You mentioned the work that's happened in proteins and chemistry and medicine. What's the common theme behind these papers? What are they trying to do?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:13:19] John Bohannon: It really all boils down to the original trick of the transformer. It's amazing how valuable that idea was. A paper in 2017 has just completely taken over the world. The idea is if you have a sequence of some kind - language, it could be pixels, it could be sound, could be DNA or protein sequences. You just make what we call language model and NLP it'll probably, maybe it will always be called language model even when it's not language. I see that in papers, like I link\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"papers, like I link to papers and what I sent you, one's called a protein language model. So maybe that'll be the trend. You just call that a language model even if it's not human language.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"The idea is you just teach the system to learn the patterns in the data by having itself supervised at a massive scale. It's just essentially doing we call it tokens by tokens. You just take this attention. When do you stick it in there? The usual trick is you do a mass token task where you hide some of those tokens and you teach it to fill them in or auto regressive.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"You cut it, and you say, what would you continue writing from here? It's all amounting of the same thing. You're forcing this very, very massive function. That's all neural network is it's just a huge function with a ridiculous number of variables that we call parameters to essentially satisfy this objective of being able to predict. The weird thing is, all of these cool skills just seem to emerge from that, I think, dumb trick, and that's not a pejorative. I think it's a beautiful, dumb trick.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"dumb trick. That's another thing by the way, we still don't understand. We don't understand how it works, which blows my mind.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"ML used to be a branch of Math. Now it feels more like Biology. It feels like we're studying things that we don't fully understand, and we're just taking an empirical approach, probing and prodding, trying to figure out how they work.\\n\\n[00:15:24] Sam Charrington: Do you follow the more theoretical side of NLP and the efforts that are taking place to try to better understand--\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:15:34] John Bohannon: The The extent of my engagement with that full honesty, full honesty is here at primary. We have a slack channel called algorithms, just for historical reasons, and people drop papers in there and start discussions. Every once in a while I will see something. It's a theoretical paper that just seems to be making some bold claim.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='Usually it sounds like Physics to me and I\\'ll just tag and people, usually people with a Physics background who are on my team and say, please explain this, is this a big deal? So we dig into it. Usually the consensus is \\'maybe\\'. Even people on my team who can really come to grips with these theoretical papers are always like, \"Well, let\\'s see.\" It feels very nascent.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='There hasn\\'t been any big reduction and reductive understanding that you would get in Physics with these models. It\\'s still very empirical. When people take a theoretical take, it\\'s intriguing, but I\\'m just waiting for someone to say, \"Oh yeah. This is the breakthrough we\\'ve been waiting for. This explains a lot. \" I just haven\\'t heard that.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:16:51] Sam Charrington: Along those lines, one comment that was recently made to me relating to NeuRIPS was this feeling that the NeuRIPS, and let me be clear and individual's experience with NeuRIPS was that they got less out of it, I guess, is the only way to say it. I was reflecting on that and this idea that over the past few years, one of the things that's been really interesting about this field is that to stay on top of the field and to implement useful things that were beyond\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"that were beyond something that was already packaged in a library. You had to read papers to understand what folks were doing because the field was evolving so quickly. I think you alluded to this in your opening and that the field is in some sense, slowing down. I wonder if there's a corollary to that hardcore research is diverging from practice more so than in the past.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[00:18:23] John Bohannon: Yeah. I agree.\\n\\n[00:18:24] Sam Charrington: Does it resonate at all?\\n\\n[00:18:25] John Bohannon: It does resonate and it manifests in a bunch of different ways. One of them... Here\\'s a really practical way that this manifests early on and by early, I mean like circa 2018 and OPA. You know, modern NLP is so new. These benchmarks emerged, it was like, \"Okay, let\\'s get down to business people.\"', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='Natural language processing needs to take the measurement of these models seriously \\'cause we started to create these giant language models that had these amazing capabilities and everyone wanted to play the game of, \"Is my model better than yours?\" So you had glue and then that got beaten and we had super glue. Now we have something called gem and there\\'s like a whole zoo of benchmarks out there.\\n\\n[00:19:14] Sam Charrington: Yeah.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:19:15] John Bohannon: Something I've noticed is that they are just less and less useful. I think of them as academic benchmarks, academic data sets. So what you do is, if you want to know how good named entity recognition is one of the, like the old school core tasks of NLP, find me, the people, places, things in this text.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"There's this old dataset floating around called Conwell L, it's really old. It's just a little sample of news just from, I think, ne source from one period of time, and we've been using it ever since to measure how good you are at NPR. It wasn't that long before when we built our own NPR model, we started to notice that performance on that benchmark, that academic Conwell benchmark started to drift away from the performance on real customer data that we'd gold labeled that we cared about.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"That was trend that we just saw happening over and over again, is that it does, if you're chasing state-of-the-art on these big benchmarks, you're actually often driving down the performance on something you care about. So you have to make your own internal benchmarks and I think we're not alone. I think everyone across the industry is quietly maintaining their own internal benchmarks to keep track of stuff and that's bad, right?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:20:37] Sam Charrington: This was a thing that came up in the computer vision conversation. Also, we've focused on the flip side of that, which was the academic tendency, at least in CV to quote/unquote overfit on ImageNet.\\n\\nRight. You're describing the flip side of yours will be overfit on blue or glue or whatever it is.\\n\\nRight.\\n\\n[00:20:59] John Bohannon: One of the manifestations though of this problem is--\\n\\n[00:21:03] Sam Charrington: RIght.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[00:21:03] John Bohannon: --that early on when NLP just started to explode, a big conference, like these kind of shared resources, like these benchmarks made sense, like we didn\\'t even have a map. We didn\\'t have a compass. We were just, \"Okay, let\\'s get together to figure something out.\"', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='Now we\\'re past the explosive. We\\'re in the like, settling, like stable phase of the science where it\\'s like, \"Okay, let\\'s make it good. Let\\'s make it efficient.\" it\\'s like very applied now, like the performance of some base language model on some completely kooky task, like natural language inference.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"It's beside the point, that's not even helpful anymore. So yeah, no one solved this, but that's a big story of this year is like turmoil over benchmarks, how to measure the performance. What's relevant, how to improve things. All the big companies came out with their own new, big approach.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"This, the only thing that I've seen this year, that's a truly new take on this is something from Facebook Meta called Dynabench. That's an experiment that's running now. So there, rather than just have a frozen gold label set and a test, and everyone takes the same test. It's an ever evolving test that's adversarial.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"The whole point is to have humans in the loop, try and trick models. So you're collecting all these adversarial examples that models find really difficult. So it's just constantly evolving. As a side virtuous side benefit, you're generating all this useful, truly instructive adversarial data.\\n\\nThat's a really fresh take. I'm going to be really interested this year to see what results come in.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:22:44] Sam Charrington: That is really interesting. Do you, on this benchmark, this idea that in industry, folks are collecting their own benchmark datasets. Is that a feature or benefit? That's not really what... I guess what I'm trying to get at is do you see that changing in the sense of industry consortia or groups of organizations kind of sharing? This information to credit tried to create better data sets or is it more, either some combination of this is our proprietary advantage and\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"advantage and so we're going to keep or it's really only relevant to us anyway. Cause it's our specific problem, our specific customers, that kind of thing.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:23:36] John Bohannon: No, I don't think there's a lot of goodwill around in this space anymore. The trend I'm seeing is to use benchmarks to be able to brag about achieving state-of-the-art, even if it's not really relevant, and quietly curating your own high value data that actually gets you models that solve the problems that people pay money for. The big exception to this that's going against that tide is Eleuther. If that's how you pronounce it, I've actually never heard that.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:24:09] Sam Charrington: The GPT, the creators of the GPT-3 alternative.\\n\\n[00:24:13] John Bohannon: Yep. The GPT-Neo folks. So I love that they're out there open sourcing nonstop. They put out a huge dataset called the pile. They put out GPT-Neo, and I think, they're a force for good going against the tide of basically a closed, closed ML development because the problem is that's going to slow down the science.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"That's the beauty of shared resources and standards is we can all march to the same drum beat and make progress more quickly, but there's just a lot of money to be made right now. I mean, NLP is where all the investments' going. So you're going to see a lot of anti-scientific trends.\\n\\n[00:24:55] Sam Charrington: Along those lines, are you seeing a decrease in publishing by corporate research teams?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[00:25:07] John Bohannon: No, I haven\\'t seen any trends like that. They\\'re still publishing solder chasing papers. \"Oh, we gotta stay there.\" This there even when it\\'s just crazy. I mean, in a lot of NLP, they\\'re still using this standard called ROUGE. So it was invented for machine translation. Now it\\'s used to evaluate summary quality, and everyone just openly knows that it\\'s completely flawed, but people just keep on reporting standard state of the art resultswith the ROUGE metric even though', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"metric even though we have alternatives now. But it just reveals that a lot of the publishing that's happening, whether it's in universities or big companies, is really just bragging rights.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:25:52] Sam Charrington: Yeah.\\n\\n[00:25:53] John Bohannon: Rather than true scientific sharing. I mean, there's a mixture. There's a lot of goodwills still, but yeah, it's a troubling trend.\\n\\n[00:26:03] Sam Charrington: So maybe going back to this idea of incremental progress within NLP, it sounds bad but when you think about the hype cycle and--\\n\\n[00:26:17] John Bohannon: Oh it's not bad.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:26:17] Sam Charrington: --way markets evolve, it sounds less exciting, less sexy than NLP eating the world. ButI think we're saying the same thing here. It's a necessary phase and it's where we talk, we throw around this idea of democratization and stuff like that is hard. This is related to the point I was making about know everyone needed to be a researcher to use NLP. Like it's not the case anymore because things are settling down. The tools are standardizing. You can pull state of the\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"pull state of the art stuff off of hugging phase, and just use it and you don't have to implement the paper.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:26:53] John Bohannon: Yeah, exactly. I think it's great. That's the business I'm in. We're trying to build stuff that people pay money for so you gotta make that stuff efficient and actually high-performance so, yeah, it's just settling down into normal science, normal engineering but the revolution is still ongoing. It's just that this first big explosion that was made possible by transformer based language models. It's cooling down. It's like a lot of alternatives to transformers have been\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='have been proposed and it was a paper. You can forget transformers, you can use 48 transform, forget this. You can use this, and none of them seem to have taken off transformer seems to be here.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[00:27:37] Sam Charrington: So what are you seeing in the dimension of improving efficiency?', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:27:45] John Bohannon: Well, the really exciting thing is, it started with something called the switch transformer that Google implemented successfully. Apparently the idea is a lot older. I didn't realize that, but in a nutshell, rather than having one [gi-gundo] neural net, where when you feed in something at the bottom, it has to do Pachinko through the whole network to get your answer out the other side, you instead fragment it into what's called a mixture of experts. So bunches of little\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='So bunches of little neural networks, and then you have something at the bottom that does the routing. So when little piece of information comes in like language token or whatever, it gets routed to the right expert. Sometimes these systems routed to a couple experts and let them duke it out.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"But the point is you can have a gigantic system that's very sparsely activated. So it's way cheaper to train, way cheaper to do inference on, and you can do it with distributed architecture very naturally. Whereas if you have your whole neural network that needs to be in memory, maybe the nano chip, there's a hard limit to how big you can make these things.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"The size, the parameter size of these models has been outstripping Moore's law by a healthy, healthy helping over the past few years. That's got people worried, you know, money, power consumption, climate change impact. Only a few giant companies being able to even operate with these things.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So the switch transformer has been a really exciting development this year. Two models, one from DeepMind, one from Google, came out just recently, Gopher and GLaM. Ben's been around longer that implemented and also there's a really amazing result from Facebook AI. They go by Facebook AI or Metta AI.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Now, I guess it's Meta AI then where they had a multi-lingual translation model that beat all of the bilingual models for the first time on the big WMT annual machine translation contest so it used this mixture of experts architecture. So it ran a lot more efficiently. So that idea seems to be taken off.\\n\\nI can expect that this year it'll just keep going and maybe eventually we'll say goodbye to a single neural network systems.\\n\\nnetwork\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"network\\n\\n[00:30:16] Sam Charrington: Is there anything special required at the infrastructure, hardware, lower level...\\n\\n[00:30:25] John Bohannon: For sure, and that will come; we'll get the PyTorch for distributed mixture of expert transformers in due time. I'm sure.\\n\\n[00:30:34] Sam Charrington: Yeah.\\n\\n[00:30:35] John Bohannon: But yeah, for now it's pretty bespoke. I think you need a real team of experts to implement this.\\n\\n[00:30:40] Sam Charrington: Got it.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:30:41] John Bohannon: But can't be long before tools get good.\\n\\n[00:30:45] Sam Charrington: Well, I think it's the same process that we've been talking about. There's an innovation and this switch transformer it's standardized and demonstrated to be effective across, or at least from several different groups. Now the PyTorch community and others can take it and push it down into their level and take advantage of it.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='What are you seeing around building operational pipelines around transformers or transformers and production, that kind of thing. This relates somewhat to the broader problem or your challenges around like fairness and predictability of language models, and ethics, that kind of thing.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"I'm thinking about the guard rails that an organization needs to put in place around large language models, if they're productizing them. But also the kind of ML ops processes that are required to operationalize them, or are they diverging from any other kind of model? Are you seeing the same practices applied to transformers?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:32:13] John Bohannon: Well, this touches on a pretty rich vein. We could take this from a lot of different angles. There's the whole issue of ML ethics and responsible ML. That's been a sea change over this past year. That really is starting to have really practical effects on, as you say, ML ops, like how do you actually operationalize this stuff?\\n\\n[00:32:39] Sam Charrington: Yeah but let's--\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:32:42] John Bohannon: Increasing the quality of data by accounting for things like bias and toxic language. So all of that is happening. There's also more boring side of this, which is just how do you make these systems cheaper to drive down cost to serve, make it more data efficient to train these models.\\n\\nThere's whole bunch of new tricks that are emerging on that side, too. So there's the sign of spicy, spicy side and the mild side. Which do you want to,..?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:33:13] Sam Charrington: Yeah. Yeah. Let's start with the mild side...\\n\\n[00:33:16] John Bohannon: Okay.\\n\\n[00:33:17] Sam Charrington: ...and we'll get to the spicy side.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:33:19] John Bohannon: Sounds good. All right. So for the mild appetizer, one thing that's emerging is all kinds of clever tricks for increasing data efficiency. So when I say data efficiency, I mean how many training examples did you need to get your model to some target perform? So, you have some target in mind, how long did it take you to get there?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"The whole trend has been that that number is getting lower and lower and lower. The most exciting thing over the past year has been a few shot learning. When GPT-2 and GPT-3 came out, people started using the phrase few shot learning and zero shot learning erroneously. So it's really confusing because when you do prompt engineering and you write--\\n\\n[00:34:11] Sam Charrington: It's like a learning prompt.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:34:13] John Bohannon: There's no learning happening here. You've just changed the format of the input. But true few shot learning has started to actually emerge. So all kinds of really clever tricks for driving down that costs in terms of data to get some performance measurement. Here's one of the really cute tricks. So when you want to make a class file, document comes in and you tell me whether it belongs in bucket A, B or C.\\n\\n[00:34:40] Sam Charrington: Yeah.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:34:41] John Bohannon: This is like NLP task. One-on-one. Usually what we do old school is you give it a whole bunch of label data, and the first thing the model has to do during training is figure out what the task even is. You don't give it instructions, you just punish it every time it gives a wrong answer.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So the whole beginning of the training is just figuring out what the task is, and that's not efficient. That's like administering a test to students where you don't even tell them what's going on, and they just have to figure out what it is first. So one of the cute tricks I've seen emerge is just make it multiple choice.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Just literally spell it out right there in the input data what the possible choices are. It's just like such a nice, simple trick. That's what I mean when it comes to incremental science. It's bunches and bunches of little artistical improvements to how we do things that squeezing out efficiency and performance.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:35:39] Sam Charrington: Is that an example, and as your broader point related to you've already got a trained large language model, and you're trying to figure out basically how to get it to do what you want?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:35:54] John Bohannon: Yep. It's just old-fashioned now old fashioned fine tuning of a language model, the same old, same old, another neat trick that's emerged is the pipelines themselves. So this is something we've been grappling with at primer. If you're just some person at home wanting to do a little batch of data, using some hugging face model, you don't worry too much about the cost.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"It's just a quick one-off, it's no big deal, but if you need to do millions of documents with, let's say dozens of different machine learning models for a customer and you're on the hook for the cost to serve. It really matters. You look at your monthly AWS bill and you're shocked. There's a lot of motivation out there to try and figure out how do we drive down the cost of service of these systems once we scale it.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So one of the things that you can do, and this is borrowed so true of NLP these days take an old concept from like computer vision and just figure out how to reapply it. So it's the idea of model cascades. That's what they call it over in computer vision, rather than just have your big, great model doing all the work.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"You have a cascade of models, maybe not that good, better, best, and you do what I call inference triage. So what we found and we're about to publish a paper on this, as you can, with some really expensive classification tasks, you can have an old school scikit-learn CPU driven, no GPUs needed model do 99% of the work. All it has to learn how to do is take the ambiguous tricky cases and pass those on to the big model.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"It's stuff like that. Just like really simple tricks. That's what engineering evolution looks like. Just an accumulation of tricks.\\n\\n[00:37:43] Sam Charrington: Yeah. I mean, I guess all the best tricks sound obvious once you say them, right?\\n\\n[00:37:48] John Bohannon: Yeah. Although I got to say transformers, that's clever. It's still such a cool idea. It's to me, it's never going to feel obvious. That's just such a cool idea. Language models, even like cool idea.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:38:02] Sam Charrington: Yeah, yeah.\\n\\n[00:38:03] John Bohannon: So that's the mild side.\\n\\n[00:38:09] Sam Charrington: Yup. So you're what you're specifically describing. There again is a prompt engineering. I think there's a medium. We're getting to spicy, which are these hardcore issues around... Actually let's jump to spicy and then I'll swing back if needed.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So let's talk about the evolution of the way we're thinking about ethics and responsibility in the context of NLP. What are you seeing there?\\n\\n[00:38:46] John Bohannon: Well, I'll start by making a prediction for 2022, since we're supposed to be doing some of those.\\n\\n[00:38:50] Sam Charrington: We're going to do some of those apps.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:38:52] John Bohannon: All right. I'm going to throw one up, throw one in. I don't think that Amazon Alexa or Apple's Siri or Google Assistant are going to get dramatically better this year, even though they could. I think it's because these companies are rightly cautious about the language models that would power that.\\n\\n[00:39:12] Sam Charrington: huh.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:39:13] John Bohannon: It just doesn't feel safe enough yet, and it just takes one really, really egregious public relations disaster to nuke the whole effort. I think they're going to hold back until that stuff is all ironed out. So I don't think you're going to, even though, like you're going to have hugging face models and maybe little startup efforts that are, feel like they're miles ahead. In some regards with human interaction, whether it's speech or text or just making sense of things.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"sense of things. I think that the big companies are going to lay low a lot longer. So that's my prediction and rightly so.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:39:52] Sam Charrington: Okay.\\n\\n[00:39:53] John Bohannon: So on the spicy side, in retrospect, this no one should have been surprised by any of that. Like, what are these models? They're just big mathematical objects trained on data, or that data come from us. It's our written text on the internet, mostly. Where did that come from? Well, a very biased point of view and very, very biased point of view, English speaking, almost entirely Western industrialized, male dominated.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"You know, it comes from a human history that is only now starting on the timescale of human history kind of yesterday woke up to equality. So it shouldn't have surprised anyone that if you put a language model behind a free-form interface where you can just like talk to it or make it safe.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='That you can very easily make it say things that are just like politically unacceptable and sometimes ethically shocking. Yet the past year, I mean, really it started the year before, but it continued this year. People just keep on stepping in that landmine.\\n\\n[00:41:15] Sam Charrington: Yeah.\\n\\n[00:41:16] John Bohannon: The one that I noticed this year was the Allen Institute for Artificial Intelligence made this cute little experiment called Delphi. You remember this?', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:41:29] Sam Charrington: Yeah. Yeah.\\n\\n[00:41:30] John Bohannon: Man, that blew up in their face. I don't think it was a mistake to do the science. It was a cool question. Could you, if you made a big dataset of ethical statements, things that are right and wrong. Could you generalize at all? Could you get a model to take statements as input and say whether it sounds ethically right or wrong? Interesting idea. It's like basically a toy experiment.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"The one mistake they made was they put it online in a way that allowed anyone to say anything to this model. Of course, if you're motivated, you want to make the model say something racist. It'll take you like 15 seconds.\\n\\n[00:42:11] Sam Charrington: Yeah.\\n\\n[00:42:12] John Bohannon: Then they, this is the part I don't like, then they absolutely mob bullied.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"These poor scientists who had good intentions come on, like they weren't out to harm anyone. So that's the trend we've been seeing is just people making these self-inflicted mistakes, using language models, and like Twitter beating up on them. I mean, there was a time when we talked when it came to machine learning and ethics, we talked about systems that were deployed in the world, like things that determined whether you got hired or not that we're having impacts today. People were truly being\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"were truly being harmed and like those facial recognition systems being used to hassle people that clearly had racial bias. Suddenly that whole conversation moved to, can you make a language model say something racist. So what's come of that? Some very good things.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:43:06] Sam Charrington: I don't think it's a complete shift. I think there are still people that are--\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:43:09] John Bohannon: There are, there are, but it has made a lot of heat and noise and I think some good things are finally coming out of this one is that you can't not talk about the ethics of your work anymore. Like papers routinely will have an ethics section it's just expected now. When you dream up some. You're not going to be able to avoid the conversation hopefully before you even get started of well, what are the possible harms? That's a sea change that just a couple of years ago,\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"couple of years ago, that just wasn't the case. I think that's the biggest, positive impact of all this is that we're talking about it.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Then the second one is people are starting to get practical about it. DeepMind, I saw put out a blog post describing practical ways that they try and reduce these kinds of biases in data. Also ameliorate like the impact on the other side. So we're just starting to get really practical.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"One of the really cool results from the recent glam and go for papers. I can't remember which one, but one of two of them, they claimed that they got a lot of bang for buck by. Practically addressing the problem of data quality. So they had all kinds of clever filters on huge gobs of internet data to try and get rid of some of the worst stuff like internet chat and toxic language, pre-filtered that out and they got better performance on the task that they cared about practical. So it's not just\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So it's not just a bunch of heat noise. It's actually productive.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:44:51] Sam Charrington: I don't think I saw the DeepMind paper that you referred to. I have to get that link from you. Think you're touching on the medium spicy that I was referring to earlier. The example that comes to mind for me was this, it was a tweet from a while back. This was end of October.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Someone did a search on Google about what should you do when someone's having a seizure and you know how it has the featured snippets, The feature snippets basically gave us some bullet points, which if you go went to the text of the page, that it was referring to where the things not to So I wrote a little piece about that and talked generally about the need for governance and we're starting to see more kind of model monitoring and governance tools. But I wanted to get your take for an\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"get your take for an organization that's putting these models out into the wild, like what are the tools and processes that you're using to try to constrain their behavior? One is just, don't put them, don't put them up. Another is, we've seen with Google, like they'll filter like you can't search this, you can't use some set of search terms because it knows the model breaks under those searches. So it'll create lists of filtered terms. You know, that's one thing I'm curious - what are the other\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"- what are the other things that you're seeing folks doing, and the full spectrum of sophistication, or is it just an exclusion list upfront?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:47:03] John Bohannon: Well...\\n\\n[00:47:04] Sam Charrington: Is that the kind of sophistication were at?\\n\\n[00:47:06] John Bohannon: I can tell you as an outsider to this, because you know where I am primer primers, working with a small number of very big customers. So relationship we have when we deploy models, we can talk directly to the very small, manageable number of people who actually need it. So there's a trusting relationship.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"There that's very dynamic. We can fix problems as we acquire them. So in a certain sense, we can be a little less, I guess you could say, just less cautious, but you don't need to be as cautious. When you unleash something onto the internet and anyone at scale is using it, you gotta be really cautious.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So it's a different game. What have I observed looking at how people deal with that? I think we're still stepping in the do-do phase, honestly. I just see it happening over and over again, things going horribly wrong. I guess that's probably because it still pays off. The game out there is to be the first to do something.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='There\\'s a huge payoff for doing that and so people are, we\\'re still in this era of just cowboy, just make something and put it out there and see what sticks. Then when it blows up too bad for you, but it was still worth the risk. I think that\\'s going to change. I think that\\'s going to change for one thing, like the number of new things, it seems to be decreasing over time. I don\\'t think people are that impressed by a chat bot on Twitter anymore. \"Okay. Yeah. We\\'ve seen that.\"', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:48:50] Sam Charrington: Right.\\n\\n[00:48:50] John Bohannon: So I think we're going to be moving into practical stuff like can you solve problems? The nature of solving practical, narrow problems I've noticed is that it forces you to be more cautious, just for good engineering, you know?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So we're going to see less and less of interfaces where there's just a raw language model willing to say anything 'cause that it's just, there aren't that many problems that require that it's going to get more and more narrow. I think that the things that are left, where it's still dangerous, yeah, we're going to have to figure it out how to do it to your point, like, I think we are still essentially filtering. I think that is the best tool we have right now is to just exclude lists of terms and\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"lists of terms and keep on adding to it. I've done that myself. Not for toxicity, but I mean, we were building a system once and it wasn't dealing very well with certain famous people that it would just pollute your data. So we would just exclude them because they weren't relevant. So we just clean up results. That way it's an old school trick. I think we're still doing that. I think that'll continue ultimately though. Well, a lot of people think that the solution is to train better language\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"better language models, make them more polite and helpful and cautious from the get-go. Other people feel like that's too hard. Just train them on the raw world as it is, and then do something downstream to clean up their output. I don't think that's been settled.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:50:32] Sam Charrington: You mentioned chatbots. Have you seen anything there...?\\n\\n[00:50:40] John Bohannon: Nope. No matter what you're going to say, the answer is, nope. I don't think chatbots have improved at all.\\n\\n[00:50:45] Sam Charrington: I mean, you would think they would inherit some improvement due to transformers and that whole thing, but--\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:50:53] John Bohannon: They are more fluent in terms of... it's not word salad, but they still can't keep track of what you're talking about.\\n\\n[00:51:03] Sam Charrington: They still haven't achieved utility.\\n\\n[00:51:05] John Bohannon: Yeah, I don't think so. I don't think so. I've one thing I loved this year was AI Dungeon. Have you played with this game or at least heard about it?\\n\\n[00:51:15] Sam Charrington: I don't remember.\\n\\n[00:51:18] John Bohannon: Do you remember Zork?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:51:21] Sam Charrington: Yep.\\n\\n[00:51:21] John Bohannon: So it's just a text adventure game like Zork but it's powered by GPT-2 or 3.\\n\\n[00:51:25] Sam Charrington: Yeah. I think I remember this.\\n\\n[00:51:27] John Bohannon: So it's a text adventure that you get to basically be the player and dungeon master simultaneously.\\n\\n[00:51:33] Sam Charrington: Yep.\\n\\nYep\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Yep\\n\\n[00:51:35] John Bohannon: I think that's a glimpse at what the really cool hello world of tomorrow's chatbots is going to be. think that you're not trying to solve a problem that you're stressed about and money's on the line. It's gonna start with games, something fun, where it's a little more freeform and it can be kooky and it's okay. I think that's where the first really sophisticated chatbots are probably gonna get used.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"I don't think it's going to be customer service. Everyone thinks it's going to be chat bots helping you with questions. That you have of a company or your phone company or something like that. You can solve those kinds of problems with much simpler systems because you don't need just to have a conversation with those bots. It's really just a fancy menu.\\n\\n[00:52:22] Sam Charrington: Right.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:52:23] John Bohannon: But with games, you really do want to have a conversation. So something that really bugs me is they haven't figured out code reference resolution, which is, if I'm talking about something and then I say, what do you think about that? That is a reference to something that we've talked about earlier.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"You have an in memory, you know what it is? These models really struggle with code reference resolution so someone's got to crack that code. Someone's got to figure out how to make a chat bot that can keep track of things. One of the really cool papers that came out this year, that was a really truly innovative idea is something called Scratch Pad. There's a Google paper. The idea is you let the model literally take notes as it processes stuff. So you can imagine they did it for Mathematics.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='it for Mathematics. Their paper was all about having this model work on a mathematical problem and it could take notes, but the sparks flying in my head were like, \"Oh, it\\'s not going to stop there.\"', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Imagine you have a model that has to deal with a book length document or an hour long conversation. We can't fit all that stuff into a standard transformer attention window. It's just got this little key hole that it looks at the world and it forgets everything as soon as you move that window. So this might be a way forward.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"You give it a space where it can keep notes of the most important things and keep referring to it as it goes. I've been thinking about trying some version of this for longer documents. That's something that I care about in the chat bot. Maybe it'll be something like that where you literally have a model that's keeping track of the most important information, erasing it and changing it as it goes so that it can remember what that is when you say that.\\n\\nWe'll see. I don't know.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[00:54:09] Sam Charrington: had some interesting conversations on the general topic of fusing various types of memory with modern deep learning models. That seems to be one of the well, \"Hey, there\\'s a lot of activity and B seems to be high potential.\" If we get that right, we open up a whole another dimension of performance.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:54:33] John Bohannon: Yeah, absolutely, 'cause right now we live in the world of the attention window. It's only about 500 words. It's really small. Imagine you had amnesia where you forgot everything you read before 500 words ago, free, tough.\\n\\n[00:54:52] Sam Charrington: I think I've seen that movie, and the solution was writing things on your hand, thus your scratch pad, right?\\n\\n[00:54:56] John Bohannon: The scratch pad.\\n\\n[00:54:58] Sam Charrington: Yup.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:54:58] John Bohannon: We've reinvented memento.\\n\\n[00:55:00] Sam Charrington: Yeah. There's going to be a paper called memento. Actually the're ready.\\n\\n[00:55:05] John Bohannon: That's a strong prediction. That's strong prediction.\\n\\n[00:55:10] Sam Charrington: I feel like there is one though. I'm going to have to look that up.\\n\\n[00:55:14] John Bohannon: It can be rebranded. I think it can be reappropriated.\\n\\n[00:55:17] Sam Charrington: It can be rebranded, for sure. For sure.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"You briefly mentioned multilingual results this year, and yeah, that's something that the community has been advocating for our elements in the community. I've been advocating for a long time. Pushing NLP beyond English or our English dominant. What were the highlights in that domain?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:55:51] John Bohannon: This year, Chinese has just completely blown up. Chinese NLP is just amazingly, amazingly rich. Now multiple models, language models, bigger than GPT-3, whole new dialogue type models that is like Chinese based. So there's just no doubt, the language that's going to be on par with English, if it isn't already, is Chinese huge investment.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='Then a bunch of other languages are starting to play catch up. I noticed that a Korean version of glue came out and GPT-3 Korean model called Hyper Clover. A whole bunch of other languages are also playing catch up mostly by utilizing English models and then doing tricks to make them multi-lingual.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"The most exciting thing in multi-lingual NLP was this result from Facebook Metta where a multi-lingual model beat all the bilinguals. That's a paradigm change, but I think actually the thing that's going to have the bigger impact long-term potentially is this other thing also from Metta called XLS-R. I'm just going to click on this, make sure I'm getting this right.\\n\\n[00:57:18] Sam Charrington: It is XLS-R, isn't it? XLS-R, our self supervised speech processing for 128 languages.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:57:25] John Bohannon: So this is really new and intriguing. The idea here is forget about the written text. Let's just do language and audio the way humans learn it and use it. Besides opening up an unbelievably vast potential data source, most human speech is actually audio. NLP has just been grounded in texts because we can easily deal with it with the computers of today,\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:57:53] Sam Charrington: This is an interesting problem that kind of formulate. Certainly the volume in terms of bits of audio data is going to be greater than written data.\\n\\n[00:58:04] John Bohannon: Right. but that's not relevant.\\n\\n[00:58:07] Sam Charrington: Are you saying that we have more recorded words in audio formats than in written formats?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:58:13] John Bohannon: Making a slightly weaker claim which is that every human alive today who utters language in any form is mostly doing it with their throat, not they're typing fingers.\\n\\n[00:58:27] Sam Charrington: Got it.\\n\\n[00:58:29] John Bohannon: Different question is, if we had to do this today, how much data do we actually have counted by words, let's say Yeah. written versus recorded.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Probably written if I had to guess just the lbraries accumulated, but with all the listening devices we now have in our pocket, in our home, in our meetings, that could be eclipsed very, very quickly.\\n\\n[00:59:01] Sam Charrington: Yeah. But do we even know how to build models that are channel characteristic agnostic?\\n\\n[00:59:07] John Bohannon: Well, so that's the exciting promise here is like maybe, but I think that the XLS-R...\\n\\n[00:59:14] Sam Charrington: What are they trying to do?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:59:18] John Bohannon: Well, the thing that excites me about it is this unlocks low resource languages in a way that we never could with written texts. You just don't have enough written texts from all of the African languages and all of the Aboriginal languages of south America and even a bunch of European languages. I hear Icelandic has this problem. There just isn't enough written text...\\n\\n[00:59:40] Sam Charrington: Um.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:59:40] John Bohannon: ...to train a language model the way we do today, but you could easily get a whole bunch of recording. So that's pretty exciting that might be longer-term the bigger deal.\\n\\n[00:59:51] Sam Charrington: Yeah.\\n\\n[00:59:52] John Bohannon: We'll see.\\n\\n[00:59:53] Sam Charrington: Very cool. The multilingual model that you referred to, I think it was Metta. Was that trained in a multi-task kind of one shot? I'm overusing one. I'm using one shot incorrectly here but...\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[01:00:14] John Bohannon: You talking about XLS-R?\\n\\n[01:00:17] Sam Charrington: No, the prior was it...?\\n\\n[01:00:20] John Bohannon: Oh, the multilingual.\\n\\n[01:00:21] Sam Charrington: The multilingual.\\n\\n[01:00:22] John Bohannon: Yeah. They did English to many and many to English was the paradigm.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So yeah, and by the way, they use this nice, efficient, new distributed mixture of experts, architecture which is great, but yeah, it was English to many and many to English. So they're still English at the heart of this effort but it's like it's the node connecting all the other languages data-wise.\\n\\n[01:00:48] Sam Charrington: Got it. Got it.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So we've covered NLP eating the world. We've covered this transition to incremental progress and a driving efficiency, multilingual benchmarks, ethics...\\n\\n[01:01:07] John Bohannon: Spicy and mild.\\n\\n[01:01:08] Sam Charrington: Spicy and mild, and you've got this section here on some bad things that did not happen in 2021.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:01:16] John Bohannon: Yeah. People are always talking about the things that did happen. I think it's worth talking about the things that didn't happen, even though I expected them to. So one of those was... man, there was so much concern about GPT-3 generated texts flooding the internet. I mean, I had to sweat it myself. I'd let a whole team working on this problem for a whole year.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:01:39] Sam Charrington: Oh, we had that concern about GPT-2 also. The whole thing is too powerful to share with anybody. Right.\\n\\n[01:01:47] John Bohannon: I've been looking real hard and I just don't see it happening yet.\\n\\n[01:01:53] Sam Charrington: Could that be because it's so good that you can't detect it?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:01:57] John Bohannon: Of course, of course. I don't think so though, because I can tell you that someone who's done this before, the first thing that'll happen is someone will announce a prank and I haven't even seen a large-scale. I haven't seen anyone maintaining, well, regarded or widely read blog that turns out to be all GPT texts. I haven't seen a Twitter account that's had a big account, a big impact on the world that turns out to be all generated. Nothing. It's just like a big\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"It's just like a big whimper. I think having used these models myself to solve problems with text generation, the reason I think is that they're just not that easy yet.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"It's not the case that you can command an army to generate things that are actually going to achieve some goal. It's still too weird, too much hallucination, too much fuss. But I do think that troll farms, state-sponsored troll farm,s and they continue to toil away at trust me. If aren't already, they will soon be using GPT style models to accelerate the human effort.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So there are going to be efforts, part of primary work. I'm part of, one of surely, many such efforts to try and make detection systems to combat these. But that will be a problem, but it didn't seem to happen this year. I just didn't see any evidence that any bad actors were using these text generation model at scale.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So that's nice. I didn't see that. The other thing that didn't happen was reinforcement learning didn't take over a NLP. A lot of people thought it was inevitable because RL is just so amazingly impactful and other fields just didn't make any inroads. There was one exception that I noticed, which was this open AI paper which was using reinforcement learning to shape a summarization model to humans.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Neat. I mean, the results weren't like mind blowing but worked. But yeah, it hasn't. RL is not eating ML. That's not happening yet. The other big surprise of course, is that we still don't know how language models work, still big mystery. We're still in this era of treating these things like cells that you have to do experiments on to figure out what they can do and how they do it.\\n\\nVery surprising.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:04:35] Sam Charrington: One of the things that we've talked about line was models, of course, throughout this conversation. We've mentioned open AI specifically, we haven't specifically talked about GPT-3 and all the things that have happened just in that world. Do you think... Maybe a place to start is, do you think it's worthy of talking about, do you think GPT-3 will have an outsized impact relative to the innovation that is large language models or is it just a hosted example of which\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='example of which there are many?', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[01:05:17] John Bohannon: That is the million dollar question. It is crazy how big the gap is between the excitement about these large outer aggressive language models like GPT-3 and the paucity of applications.\\n\\n[01:05:34] Sam Charrington: Um.\\n\\n[01:05:35] John Bohannon: Unbelievable divide there.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[01:05:37] Sam Charrington: When you say the paucity of applications, do you mean in fact actual, in the wild applications or the paucity of use cases for which they could be reliably applied, or are they the same?', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:05:55] John Bohannon: I think that you put your finger right on the problem. I think of GPT-3 and its many cousins as wild horses. It's clearly an awesome horse, really powerful, but good luck riding that thing to get to town. They're just very hard at this point to control, to do the things you need for most tasks and trust me, we were trying like others to use them to try and make progress on the problems.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='We care about you\\'re usually better off with a smaller, simpler, just a training data is more important than parameter size for the narrow, practical applied ML problems of today. That could change though. One way we tried to use, we haven\\'t been using GPT-3 but GPT Neo, the 16 billion parameter one or a 6 billion yeah, it\\'s called GPT-J, 6B. So that\\'s the biggest. That was open-source from [Leothur]. We\\'ve been trying to use it for data augmentation. So we were like, \"Okay, well, if you can\\'t', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='well, if you can\\'t put this model literally into production to do a task, maybe you can use it as a tool to train a simpler model more efficiently.\"', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So we've been trying to find all kinds of ways to get it to teach another model to do cool things. Can't even get it to do that yet. I have to admit, we just have not cracked the code on that. What you can do with it is all kinds of fun stunts. So I mean, it's just irresistibly fun to engineer, a prompt to do some brand new trick all in the space of 10/ 20 minutes.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Where else in ML you can do that? I've used it to generatenew neologisms, urban dictionary style neologisms, where you give it a description of a word you wish existed. It just spits out a weird word, fun. I've used it to generate movie plots or movie names, given a plot. I just made a prompt from stuff I copy pasted from animals.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Prime, super easy. I've recently used it to generate what I call deep talk questions. So this is a real practical use case. So COVID came and we were all a bunch of people who used to work in an office and breathe the same air and feel connected. It's very hard to stay connected when everyone's a little tiny face in a grid.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='I have this Monday ritual with my team. Now that we start with deep questions, we used to use a list that was floating around the internet of a bunch of deep questions. It\\'s stuff like, \"What is something you regret from your childhood?\" \"Who is the most influential person in your life?\" \"If you could go back in time and change one thing, what would it be?\" These kinds of questions, they elicit real conversation. We blew through that list \\'cause we were doing it every week and we would randomly', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='we would randomly choose three and then vote on one. So we got exposed to all the questions pretty fast.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So what I did was I just made a prompt of actual deep questions and use GPT Neo to just generate tons of these things. I put it on the internet. It's like taking a life of its own. It's on the internet now, but yeah, you can use them for certain things, but no one's figured out how to tame that horse.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:09:39] Sam Charrington: Hmm. Hmm. Do you follow, and have you played with the various kind of incremental things that open AI has done with the API like the instruct engine? I think technically it's not 2021. It was actually a year ago from the recording of this conversation.\\n\\n[01:10:02] John Bohannon: I haven't, but only because I'm so busy using GPT Neo...\\n\\n[01:10:09] Sam Charrington: ah.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:10:10] John Bohannon: ...trying to figure out how to make it useful. So I have access to GPT-3 hat for a long time, but I didn't find myself using it 'cause every trick that could do, I could do myself with an open-source model.\\n\\n[01:10:22] Sam Charrington: Okay.\\n\\n[01:10:23] John Bohannon: But for all, I know that they've improved by leaps and bounds. I just wouldn't know. Yeah.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:10:30] Sam Charrington: Yeah. The instruc model allows you to bypass a lot of the prompt creation and just say a natural language, what you want the model to create. That's interesting and they've got fine tuning and specific ways to use it for classification and question answering and other things. The idea being to make it easier and more accessible, and to try to reduce the need to be a prompt engineering ninja that gets something done.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:11:10] John Bohannon: Oh, well, I'll give it another try, yeah. I mean, opening eyes, doing such wonderful things. ,I wouldn't be surprised if they've made some really cool advances on that front too. One thing that we have been using that I think should go in the list of most successful applied ML, NLP, most successful examples of actual day-to-day useful NLP is Copilot.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"I know it's gotten a lot of complaints, especially about copyright, but people on my team actually use it. It's like, if you know what you're doing and you understand its limitations, it's pretty wonderful. It takes a lot of dreary boilerplate code writing out of your life. You switch to a mode of taking a template that's generated by the model and making sure it's correct in a lot of cases. That is 10 times faster than writing that boilerplate yourself.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[01:12:13] Sam Charrington: Yeah. How are they using it?\\n\\n[01:12:16] John Bohannon: In VS Code.\\n\\n[01:12:17] Sam Charrington: In VS Code? Okay.\\n\\n[01:12:19] John Bohannon: Yeah, I haven\\'t done it myself but it\\'s top of my to-do list now to try it \\'cause I only discovered this past week that they were using it. I was like, \"Oh wow!\" So it\\'s gotten to the point where it\\'s actually useful. All right, I\\'m going to check it out.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:12:33] Sam Charrington: Yeah, I haven't checked in a while but the thing that I was most looking for was some Jupiter Notebook plugin.\\n\\n[01:12:40] John Bohannon: I It's through VS Code because you can imagine you have to make these API.\\n\\n[01:12:44] Sam Charrington: Yeah,\\n\\n[01:12:45] John Bohannon: There's a lot of guts that have to be set up for that.\\n\\n[01:12:48] Sam Charrington: Yeah, yeah. Interesting.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Interesting. Yeah. That's one that I can relate to quite a bit, just that I'm not a professional engineer, data scientist, whatever, day to day, I forget. What's the specific format for doing such and such in Python or PANDIS or whatever?\\n\\n[01:13:07] John Bohannon: You do what anyone does, which is you go to Stack Overflow, you find some version of the problem and then you have to copy paste and then change it because that's actually not quite the problem I was solving.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:13:17] Sam Charrington: Right.\\n\\n[01:13:18] John Bohannon: Copilot is just doing exactly that but as a neural network, it's already got all of GitHub. So it knows how to spit out boilerplate.\\n\\n[01:13:30] Sam Charrington: Yeah. So I'm definitely going to have to go look at that plug and I had not played with it yet. If anyone knows about a way to do that inside of Jupiter, let me know.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[01:13:40] John Bohannon: That would be a really cool little gadget, if someone in the open-source Jupiter community would make that, that would be really cool.\\n\\n[01:13:48] Sam Charrington: Yeah, Yeah. Absolutely. Absolutely.\\n\\nSo, also on your list of fun things that did happen in 2021, My Little Pony GPT, what is that? I think I missed that one.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:14:01] John Bohannon: Yeah. So I think of the things that happened this year that I noticed and remembered where the delightful things, and so one of the delightful things with someone, of course someone did this, they basically trained a language model on My Little Pony text so that it speaks in the language of this kid's toy universe.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"I think we're just going to see a lot more of that playfulness before people start cashing in and figuring out how to make industrial scale text generation which is coming. But I think it's going to be the artist and pranksters who are going to lead the way and you see that already with Clifton and these things. It's play is leading the way, which is cool.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:14:49] Sam Charrington: That's great. That's great. I think we've talked about a lot of your predictions already. Are there ones that we've not mentioned yet?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:15:00] John Bohannon: Let me see. I made myself a little list. One thing we didn't mention is that I think that we're going to have the emergence of AI first gaming companies. So AI Dungeon, I think, can claim the mantle of being the first I know of. But there's going to be many AI first gaming companies, and they're going to be taking advantage of this concept of an infinite game where NPCs are actual agents that evolve and you can talk to, and the world itself is evolving in response to\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='in response to your decisions.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Not just through procedural generation but more sophisticated things. So that's going to be really fun.\\n\\n[01:15:38] Sam Charrington: Um, while you're describing this, I'm looking for this interesting company that a friend just told me about transforms that AI,\\n\\n[01:15:50] John Bohannon: Oh, never heard of it.\\n\\n[01:15:51] Sam Charrington: TNever heard of that? I'm trying to remember how much of this I can say.\\n\\n[01:15:58] John Bohannon: Hang on. I've got to go to the link forms that AI,\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:16:01] Sam Charrington: They're 30,000 foot bolting language models on to AR/VR as kind of a metaverse gaming play. Interesting stuff.\\n\\n[01:16:13] John Bohannon: Hhuh? Cool. Well, it looks like a lot of this stuff's already arriving then. Great. Yeah, that's going to be fun.\\n\\n[01:16:22] Sam Charrington: Yup.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:16:23] John Bohannon: The other thing is, there are a bunch of very narrow application AI startups in the NLP space that are only going to get better like Grammarly. I think Expensify is an NLP startup, even though it's a mixture of computer vision.\\n\\n[01:16:41] Sam Charrington: Like OCR kind of--\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:16:42] John Bohannon: Yeah, but they're just so good. I use them all the time and it's like a beautiful example of narrow, but really nailed it applications. I think all of those very narrow startups are going to get better at what they're doing, but they're going to start to expand inevitably, like you're only just a walk away from this neighborhood and you can support that workflow.\\n\\n[01:17:03] Sam Charrington: Yeah.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:17:04] John Bohannon: I think they're going to get acquired real fast and those that remain are going to be contenders. It'll take more than a year, but the ones that don't get acquired and stick around and keep expanding are going to be new fan companies eventually. That'll be cool to see. Let's find out.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Let's see the fan companies are going to be very, very cautious about anything involving a language model because of PR and rightly so, But I do think they're going to be putting more and more AI muscle behind their existing features. There'll be invisible progress. You won't realize it, but more and more of the stuff you take for granted will be taking advantage of AI.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Then I guess the other thing that I haven't mentioned is, we're not going to stop at language to image, CLIP and Glide and Dolly.\\n\\nThat's just the first shot across the bow. I think all the rich multimodality will start to get eaten up. I just can't wait for movement to be part of it.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So first of all, of course we'll have videos where you can say what you want, a boy walking down the street. Right now you get an image of a boy walking down the street. Next step of course is to get a little video. Little animation of a boy walking down the street. But where it gets interesting is where it gets really rich; where you could just write a little scene, a little movie plot, and it'll just make that coherently. I can't wait for that. Then also some really weird stuff like MCAT\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='stuff like MCAT mechanical hand, the data coming in and out of this electronic gadget is just data.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So you can imagine, like essentially doing the trick that computer vision has been using with text as data, brand new data paradigm with robotics. I don't see why NLP won't start to eat robotic. Where you rather than just having kinematics where you have to do all the vector math to figure out how to pick up something, or use reinforcement learning to somehow train it to do this.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"I think language will somehow come into the mix sooner or later. I don't know if that'll be this year, but it feels inevitable. Language is just so good for encapsulating information at the highest level about the goals that we care about.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:19:42] Sam Charrington: Yeah. The thought that prompted me was, do you see or anticipate a role for artificial language? Is what's happening in NLP going to enable, like lay people, DSLs that allow us to accomplish tasks better. It's a half-formed thought but--\\n\\n[01:20:15] John Bohannon: Do you mean, like you could say do my taxes and you don't have to be more tactical than that?\\n\\n[01:20:22] Sam Charrington: Yeah, I'm not sure what I mean.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[01:20:25] John Bohannon: I thought you were going someplace even weirder.\\n\\n[01:20:27] Sam Charrington: You know, maybe one thing in the back of my head is like really, really early on, it\\'s probably like five or six years ago, was some crazy article about, \"Hey, Facebook had these two chatbots talking to one another and they invented their own language.\"\\n\\n[01:20:44] John Bohannon: That\\'s what I thought you were talking about.\\n\\n[01:20:45] Sam Charrington: For transacting.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:20:46] John Bohannon: Okay.\\n\\n[01:20:48] Sam Charrington: I've always remember that plus what a cool concept in engineering, computer science to me has always been like the DSL you can write code to do something. You can configure an engine to do something, or you can create a language that allows someone to do the task at a higher level of abstraction than code and in a more kind of meaningful and fluid and visualized and understandable way then configuration.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So I find myself just everyday productivity trying to put together, using tools like Alfred on the Mac, how can I put together a bunch of three letter things that we'll do some task for me.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:21:41] John Bohannon: You're just talking about compression. You're hinting at something even cooler, which is making thoughts possible that aren't yet possible. So this is all theory and linguistics. Yeah. That, like thought, is truly composed of language. If you don't have the language for it, you truly can't think it, I don't know if that's true or not, but I do know that practically it's very difficult to do the mental gymnastics for certain things without the vocabulary and the\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='vocabulary and the linguistic structures that support that.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"I think what it comes down to, if you're talking about machine learning is, do you need a human in the loop? So the example of two machines talking to each other, evolving their own language, I mean, imagine you took the dataset of a whole bunch of audio and a whole bunch of good transcription of that audio.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So you've got speech and you've got texts. I've been thinking about this quirky, pointless experiment where you could then take that system that's been trained on that. Then in fact, let's just do English. You've got a ton of English, recording and the transcription, you got a model that's good at that.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"Now you give it a language it's never heard. It'll try and write it in English with English phonemes. It'll make a Anglicised version. I imagine of that language, right? So why stop there? Imagine, like going from let's say mathematical descriptions to formulas like English to Math or maybe from between any two domains and you basically have a grounding vocabulary. You have a system discover a brand new language for some new domain. What's the utility of that? I couldn't tell you, but I think it\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='you, but I think it would be hilarious.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:23:41] Sam Charrington: The thing that it made me think of, you may have seen this video a few years ago. It's like what English sounds like to non-English speakers on YouTube. Do you remember that?\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='[01:23:50] John Bohannon: Yes, exactly. So do you need a human in the loop? Not necessarily. But I think we should care about that more than anything else. I had a really simple, simple idea implemented once. This is not ML. This is old school NLP. I made this algorithm that detected jargon and specify specifically abbreviated jargon which the scientific papers I was reading was just so full of.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content='I was trying to learn new fields and you get all these big acronyms and you have no idea. So an algorithm that would find all those things and find their expanded forms, usually regular expressions. It was nothing fancy. It occurred to me that you could use the opposite of this to invent new jargon that text seem to need because phrases seemed to be just used over and over again.', metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"So you could just invent an act, an algorithm, an invented acronym, an abbreviation that you didn't realize you needed, and you could even invent. If you want to get machine learning involved, you could define it. You could have something that will generate definitions of these things and just make a glossary of invented jargon.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:25:04] Sam Charrington: Yeah. Yeah. Well, I think the last few minutes of this conversation illustrates the delight aspect of NLP and then to some degree machine learning.\\n\\n[01:25:15] John Bohannon: Absolutely.\\n\\n[01:25:15] Sam Charrington: Computer vision as well we were--\\n\\n[01:25:16] John Bohannon: NLP is finally fun. I'd say it was not fun in 2017 and before it was hard.\\n\\n[01:25:23] Sam Charrington: Yeah.\\n\\n[01:25:23] John Bohannon: Now it's just fun.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[01:25:26] Sam Charrington: That's awesome.\\n\\nWell, that sounds like a great way to finish up this year's AI rewind. John, it's so great reconnecting and talking through what you've seen this year and what you expect to see looking forward.\\n\\n[01:25:42] John Bohannon: Happy holidays and looking forward to 2022.\\n\\n[01:25:45] Sam Charrington: Absolutely. Happy holidays. Thank you.\\n\\n[01:25:49] John Bohannon: Yay. Cool.\", metadata={'source': 'content/data/550 - John Bohannon.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: All right everyone, I am on the line with Errol Koolmeister. Errol is Head of AI foundation at H&M group. Errol, welcome to the TWIML AI Podcast.\\n\\n[00:00:10] Errol Koolmeister: Thank you so much, Sam. It's a pleasure to be here.\\n\\nHey, it's great to have you on the show and I'm looking forward to digging into our conversation. I'd love to have you start us off by sharing a bit about your journey. How did you come to work in AI?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:00:24] Sam Charrington: Yeah, thank you so much. My journey really started about 15 years ago. I was still in school studying finance. I got the opportunity to join one of the largest bank here in the Nordic region of Europe.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='I joined Nordea Bank basically as a fraud analyst in the beginning. Keep in mind, this was 15 years ago. We weren\\'t into deep tech back then. Basically, I was set at the position where they said, \"Can you help us fix the fraud?\" so immediately, I was exposed to real time problems, trying to, in real time, work with the credit card companies to stop it.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='In the past, it was just rule-based, given that I had a finance background studying math at the time. I started to doing statistical analysis, improving the results significantly and back then, my love for data and machine learning and algorithms were born.\\n\\nBasically, I just took it from there. I then of course graduated, went on to be a part of building up the fraud unit in the bank, did that for a few years when I went on to actually anti-money laundering.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"I was a part of building up the first detection systems in the bank as well which was really interesting. I did that for about three years and the algorithms, screening, I couldn't get enough of it.\\n\\nI had my first child and my second child during that period when I realized I need some more exposure to data problems. I felt like this field is moving so fast so I got the opportunity within the bank to have open roles, so to say, so I moved around a little bit in the bank every [inaudible]-\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"Was it the children that gave you the insight that you needed more exposure to data problems?\\n\\n[00:02:13] Errol Koolmeister: Definitely. Here in Sweden, we're very luxurious. We get a lot of free time we get children, we get it by [inaudible] off. I can take all the time but it makes you think a little bit about what should I focus on.\\n\\n[00:02:27] Sam Charrington: Okay.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:02:28] Errol Koolmeister: I realized I wanted to go broader, [inaudible] wasn't enough for me. At that time, I had the opportunity to start playing around with Hadoop installations, vanilla. Of course, this was early days still. Had the opportunity to integrate the SAS platform with Hadoop, distributed computing, early days of Spark and I just was hooked so I deep dive into the technical aspects of data science and I just couldn't get enough. I really love this field and I have a strong\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='and I have a strong passion for it.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='After a year or so in that relatively free role, I got a phone call and it was from a headhunter working on London and they were recruiting for a lead data scientist role for Vodafone group. Basically, the second largest cell phone provider in the world and I said, \"This is a great opportunity,\" so I decided to take my kids and wife and moved to the UK where I worked out to their global office, setting up their AI department as one of their lead data scientists.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='So still early days for me and early days for Vodafone so I had the opportunity to work with some very talented individuals and being a part of building out that team that I think is now over 500 people.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"We still, I would say, had set up infrastructure that I had some problems with, with today's perspective on the [inaudible], large clusters, distributed computing, and very long lead times actually, rolling out models so I got a little bit frustrated. I like living in the fast lane, especially when it comes to extracting value so I spent about a year and a half in London when I had the opportunity to actually start my own business.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='I spent a lot of time in airports, moving back and forth between Sweden and London, servicing clients, primarily banks and startups, with AI implementations but after less than a year, my partner decided to pull out and my good friends at Think Big Analytics, that was purchased by Teradata, gave me a call and asked, \"Why don\\'t you join us now that your partner pulled up?\" so I decided to do so.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='I came in as a Director of Data Science for the Nordics, Eastern Europe and Russia, managing a team of 25 people approximately and what I did was traveling around in this region, advising the large corporations on how to implement AI and data. I did so for about a year then I get a really interesting phone call from one of the largest companies not just here in the Nordics but also in the world.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='H&M group said, \"Hey, we are investing heavily in AI. We want to build out this internal capability. Can you help us do it?\"\\n\\n[00:05:28] Sam Charrington: Awesome.\\n\\n[00:05:30] Errol Koolmeister: At that point, I said, \"Okay so do you have a buy-in from senior stakeholders? Do you have budget and do you have data?\" and I got a positive answer to all three of those and I said, \"Okay, let\\'s do it,\" and that was two and a half years ago and I haven\\'t stopped running since.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:05:47] Sam Charrington: That's fantastic. So for those who may not be familiar with H&M group, tell us a little bit about the company.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:05:56] Errol Koolmeister: The H&M group, of course, come from the original H&M brand that startED in 1947 here in Sweden, in a small town called Vsters. It was a very successful business model in the beginning. The founder, Erling Persson, said he wanted to democratize fashion. Fashion In the pre-war era was relatively expensive so he basically cut prices and made it available for everyone. In after war Europe, everybody wanted to get the economy started so this was a [inaudible].', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='The model was so successful so in around year 2000, they had 2,000 stores, when we opened the in Manhattan. Now, today, 20 years later, we have 5,000 stores globally.\\n\\nH&M, of course, the group consists of more than the H&M brand which is very well-known for most people. We have other brands like Weekday, Monki, & Other Stories, H&M Home, et cetera so we, as a group, we serve all of them and most additionally, these initiatives are still being centrally managed [inaudible] of Sweden.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:07:08] Sam Charrington: Okay, nice. You mentioned you got that call that said that they wanted to invest heavily in AI, what stage was H&M at when they gave that call?', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:07:24] Errol Koolmeister: I mean to the listeners listening to this, you probably met the CEOs or the senior managers that says, \"Hey. AI? I\\'ve heard about it at a conference somewhere. What is it? Shouldn\\'t we be investing in it?\" H&M came to that conclusion around 2016. That meant that the CEO at the time, Karl-Johan Persson, the grandson of the founder, went to business development and he gave that line, pretty much, \"What are we doing within AI?\" so business development went out into the', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='went out into the business and said, \"We got some bad news, we\\'re not doing much. We do have a CRM department, we do have some central initiatives here and there but hey, we\\'re H&M, we\\'re not doing it at scale, we\\'re not taking advantage of our economy of scale we could be doing here,\" so business development, they engage in external consultancy firm for the first proof of concepts in around 2017 with the aim to go to production if they were good.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='They were good, the first indicative results so they went to production. They started seeing payback immediately. The return on investment was less than a year in most of the business cases they started. It was so successful so in 2018, when I got that call, they decided to establish AI as its own function and a function in H&M is kind of a big deal.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"The one prior to that is sustainability department nda if you know H&M a little bit, sustainability is something very important for us, then you can imagine how important AI is now.\\n\\n[00:09:02] Sam Charrington: Maybe tell us a little bit about the various use cases for AI at H&M. How do you organize them? Do you think about them by business unit or by functional area? I'm imagining or based on our previous conversation, that there's quite broad use at this point.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:09:24] Errol Koolmeister: Yeah so H&M covers the entire value chain of a retail company except actually manufacturing the clothes. For us, AI needs to cover the entire value chain, we have an end-to-end responsibility here so when we started assessment of what use cases to actually do, we looked on value and feasibility.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='We wanted to pick the low-hanging fruits first which was a very good strategy. We looked on, okay, in the beginning of the cycle, before we started manufacturing the clothes, when we actually do it at the sign, \"Can we detect the trends that are going to be interesting, relevant in eight months when we\\'re going to get the clothes back?\" so we started, one of the use cases was fashion forecasting. Very interesting, looking on social media, \"What are the trends?\" so our designers could go in with', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='could go in with their hypothesis and actually validate them in this tool.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"Other the parts of this was, of course, demand forecasting so when we do have some of these things, how much should we buy? That's also very important for us in the past, when we had hyper-growth in the physical retail.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='We could just say, \"We\\'re going to grow 10% next year,\" if we didn\\'t reach that target, we could open a new store and put all the garments there and just sell them out anyway. Now we need it to be more granular in our predictions so demand forecasting for the company was, of course, something we focused quite a lot on.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='Then on the other side, we needed a way to negotiate with different production plants so we applied AI into different pricing algorithms, in negotiations, and also then their selection algorithms for the production part. On top of that, when everything is produced, we needed to allocate them to warehouses so allocation became a relatively good use case for us as well, what governments should go where and to what store should they get.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"It's not a one size fits all. It needs to be individual depending on the market as well, and then of course, in the end of the sales cycle, we need to handle pricing so mark downs for the online store was one of our more successful use cases and then of course, covering everything. It's the personalization, recommendation engines and tailored offering for our customers. Those were our main, relatively high level use cases that we've been focusing on most recently.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:11:53] Sam Charrington: You joined H&M at a time where the company had, excuse me, completed several proof of concept efforts, had demonstrated some value. I believe didn't have much of a team relied primarily on external resources at this point. What were your first steps in taking on the challenge to scale this more broadly within the organization?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:12:26] Errol Koolmeister: It\\'s a very good question and I think my first reaction when joining H&M is, \"What have I given myself into?\" It was relatively [inaudible] with some really talented consultants but they were focused so much on value and I came in with the perspective of course with value but how do I scale these types of efforts?', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='I started thinking, \"How do we actually recruit the amount of people that we need to recruit to replace these consultants? How do we streamline the technology and architecture?\" so one of the first things we started doing was communicating a lot more around the topics we were working on to make the market aware that we were doing these type of investments to be able to attract talent into some of the very challenging problems we\\'re working on.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"We started crafting a storyline that we wanted to introduce to the general market as well. You should never underestimate communication to create a bit of buzz in the Nordics because that's primarily where we started out but also then, more globally as well. Then, of course, pumping the hood of all the use cases, looking at the technical architecture, trying to understand what external consultants the firm had actually built.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='Some of the first thing I did was going out and hiring more technical people that could understand the engineering aspect. It\\'s one thing to build a model but it\\'s another thing to push it to production and keep it there which requires a lot of engineering effort so my first hires were some really senior machine learning engineers and we created something we call a \"Reference Architecture\" because we wanted to maintain autonomy of the actual data science teams that were building the algorithms', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='the algorithms and the products to be able to run as fast as possible but to be able to get as much central support as possible.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"It didn't make sense for us to make 10 different technical choices when they were trying to solve the same problem so we started streamlining some of these choices to be able to speed up deliveries, started to harmonize the technical choices, and then of course started taking the use case over and rolling them out at a faster pace.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:14:43] Sam Charrington: At that point, were there existing data scientists within different business units and you were supporting them centrally or were you also staffing up across the business and the various business units or departments?', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:15:02] Errol Koolmeister: It's a very relevant question. I've seen different companies do it differently. The H&M approach was to do it centrally from the start. Basically, to incubate the capability raw, to spread it out. What we realized and what I realized from my experience as well is if you put a data scientist in a team as the only technical and algorithmic person, they're going to have a problem delivering not because they are bad at delivering but they're not in the right context so\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='the right context so you tend to see a relatively high turnover of data scientists being set as an isolated island in a business unit and so we decided to initially start with a central incubation.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:15:45] Sam Charrington: Okay. When you pull back the covers on these proof of concepts, you were trying to understand them technically but what did you also learn from a value perspective? Often, there's misalignment between the needs of a proof of concept meaning to show something flashy or fancy and the ultimate needs of the business and how you align in a sustainable, long-term way. Did that kind of issue come up for you?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:16:26] Errol Koolmeister: I think that some of the really good things with the external firm that we worked with, they were really good at understanding the business requirements so they've worked very closely and I think a strategy from H&M side, given that they have had no bit of technical development and external firm was to actually have an integrated person from the business in each use case so the alignment around the value and the delivery of these things, I would say, were very well\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='say, were very well aligned.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"The problems were more on the technical side because showing something shiny doesn't always scale. My learnings and experiences start with the simplest thing that's better than random, that gives some sort of initial uplift but you can scale it better. You don't go with the most complex technology or algorithm from start because you don't know how that will scale so it's better to create a stable and scalable infrastructure rather than focusing on the modeling from day one if you're serious\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"if you're serious about these things.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:17:30] Sam Charrington: What were some of the things that you built into that infrastructure as you started to pull these projects together?\\n\\n[00:17:36] Errol Koolmeister: Some of the things that we did is we looked at the process and what I've realized is if you understand what you're building, then you can map the processes and then you can actually automate most of the things. Vis-a-vis, the MLOps type of setup.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='What we did was basically to map out the development process and look on where are some of the major pain points that we have today.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"What I started realizing is that we had a lot of stale clusters on the cloud that weren't used 70% of the time so we started moving over to a more scalable infrastructure. We moved most of our development away from Jupiter notebooks into Databricks, given that then we could have on-demand compute and we could have more virtual control over the infrastructure. We standardized on how we actually did model development. With those things, we also started looking on the orchestration so we\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='orchestration so we standardized it a lot around the work for orchestration going more into AirFlow, building new pipelines into that things and also looking on how do we productionalize and how do we follow up on these things.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='For each of these process step, we took a few design decisions and created supporting infrastructure for that.\\n\\n[00:19:03] Sam Charrington: Maybe taking a step back, were you building the infrastructure and promoting these proof of concepts into a more production capability at the same time or did one come before the other, did you pause on the POCs, build the infrastructure and then returned to the POCs to make them scale? How did you approach all of that?', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:19:27] Errol Koolmeister: My general comment is super hard but it's on the concept of technical depth. These POCs, some of them were in production already delivering value and if you are POC, in production delivering value, it's hard to pull back because the business is going to go crazy but what we started doing was we slowly worked with the different products, identifying their major pain points and gave them a boilerplate code to start migrating towards. Some of the engineers, they went\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='engineers, they went in, they did a small proof of concept. For instance, moving into AirFlow and Kubernetes. In some of the use cases, show them the benefits and then we had them pay down the technical depth in our OKRs, I even formulated goals for the product area to actually handle technical depth in their use cases or product in this case.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='We mandated them that not all your efforts should go into new feature development then you roll out to new markets. It should be paying down the debt that we see low on the proof of concepts.\\n\\n[00:20:33] Sam Charrington: Can you walk us through a particular use case before you had this infrastructure and once you establish the infrastructure and how that use case evolved along with the platform technologies that you put into place?', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:20:59] Errol Koolmeister: Yep. I can tell you about the first use case we started as the H&M team solely based on the reference architecture and how we actually developed that. We started assortment quantification for online which is demand forecasting for the online store from scratch. We wanted a green field with all the experience of all the proof of concepts considered in mind based on the reference architecture.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"Basically, what we started of course with was creating this blueprint, the reference architecture, and then started building the different building blocks out of that so from scratch, we of course made the modeling on Databricks, we created the AirFlow orchestration, the integration, the scoring, the hyperparameter tuning, the inference part and all of that. It took end-to-end to build out this infrastructure approximately 12 months and I'm not going to say this was super fast but given the\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='fast but given the complexity and dependencies that we had and the team was relatively new to building this, I think it was relatively good.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:22:05] Sam Charrington: Were you building the infrastructure for this particular product or were you building the infrastructure with many products in mind and this was a tracer bullet?', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:22:16] Errol Koolmeister: That's exactly the question I wanted to get to. Because we had all the use cases in mind, this time we didn't just build it for one, we built it for many and the learning that we made from that is the second use case that we started which was the balancing of warehouses took six months.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"Basically, the same prerequisite. Of course that's not the same data and the same business output but the process and everything associated with it is very similar so we could reuse much of the infrastructure because we built it in such a way so all of a sudden, we had saved 50% of development time in the new use case and our new strategic approach is to even reduce that further with 50% and hopefully getting it down to three months in the ones that we're starting right now so we see enormous\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"so we see enormous productivity gain with designing an infrastructure that's reusable rather than building independent use cases at this scale because it doesn't make sense.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:23:17] Sam Charrington: Yeah. You've talked about some of the trade-offs between simplicity and complexity in modeling. I wonder if you can talk a little bit about what the portfolio looks like from that perspective? What kinds of models are you using and the way you're approaching it today, now that you've built some of the infrastructure?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:23:39] Errol Koolmeister: Yep. Most of the things that we have taken to production the last year or so are all relatively simple. Most of our models are LightGBM. LightGBM is a house model these days. I mean it produces good results and its computational power isn't that expensive so we get the results that we need and it's also relatively easy to integrate into the use cases and the infrastructure that we have.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"When we started out and some of the consultants' early use cases and some of our early use cases, many of the people in the teams throw themselves directly into the latest research, wanted to do neural networks, wanted to get just a 0.1 uplift but what we realized as well is this isn't a Kaggle competition. It is not about optimizing that metrics and then you're done, it's about carrying it over into production, into infrastructure as well.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"These days, we tend to start with something relatively simple as a benchmark. It can be anything from LightGBM, XGBoost and some other regression models for instance and now we're slowly moving towards more advanced tools so looking at graph neural networks, et cetera, more latest modeling because we then see an extra need for it.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"It is a relatively wide range. We have experts in all of these areas, we have optimization experts as well in some of our use cases so we tried to keep it as simple as possible but we're not 100% there yet.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:25:25] Sam Charrington: You talked about one of your biggest challenges being scaling your organization from zero to many employees, data scientists. Do you run into the issue of the folks that you're trying to attract wanting to play with cool, fancy, shiny toys and here, you're working with XGBoost and LightGBM. How do you address that?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:25:52] Errol Koolmeister: It's super hard. I think it also comes with seniority and I think of those of commons with establishing different type of teams. What we're seeing is the most valuable thing for us right now when we look on scale are the [inaudible] models. They produce a good value and they're easy to maintain and put into production but we also have established research teams which have, as a purpose, to look on how can we improve what we have to date, how can we introduce more\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='we introduce more research into these product teams but they have another time perspective so what we tend to talk to our data scientists and machine learning engineers is that you have to go see the timing into this.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"We have to have a positive ROI in our investment today to actually get the funding to be able to scale this but at the same time, we are investing in the research but the research needs to be heavily associated with what you're doing with as well so we are trying to have a long and a short term perspective.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"Can we attract everyone that wants to work with the latest and the shiny thing? No, of course not. Hopefully, we can get some of them and that will be enough and hopefully one day we are advanced enough so that most of the things we're working on are the latest but we are a company with a lot of legacy and it's going to take us a bit of time before we are there.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:27:18] Sam Charrington: You just touch on a topic that I hear fairly frequently when talking to folks that are in enterprise leadership positions and that is the importance of managing the project portfolio, needing to have some swing for the fences, big goals in mind to keep executives excited and keep the funding coming in but also needing to have small wins and pick off low-hanging fruit, that kind of thing. I'm wondering if you see that as well and how you approach that portfolio\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='that portfolio management aspect of the role.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:28:04] Errol Koolmeister: Yep. I would like to put a little bit more context as well. We had a major reorganization recently, integrating AI with the IT department of business development into one large unit called \"Business Tech\" so these days, we are an enabling domain as well which means we serve all of the business with enabling capabilities so majority of the use case is actually prioritized by half the units than ourselves these days and we support them with building them out.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='This put us in a tricky situation, trying to identify how should we accelerate AI now, given that we are an enabling domain. We sat down and we formulated a strategy which we call the \"Fountainhead\" which is the encapsulation of all AI capabilities. One of the cornerstones of that is going from vertical capabilities which is basically use case by use case because we see that\\'s not a scalable business model into horizontal scaling. Basically, what that does, it gives us another factor of', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"us another factor of prioritizing. If we, in the past, prioritize our use cases in our portfolio by value and feasibility, we have now added the notion of reusability and the notion of reusability, basically is because take the move box, balancing a warehouse, this use case that we had, that's in-season demand forecasting.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"If we built it just for move box, this is not an infrastructure question but if we build that specifically demand forecasting just for move box, that means that we created once and we use it once but if we prioritize our use cases for all the use cases now that can do in-season demand forecasting because we just created that capability and we've prioritized them, that means we reach value much faster so we scale smarter not harder by just doing more use cases so we have flipped the roadmap over\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='the roadmap over in our portfolio of AI use cases, work together with the domain and create that type of roadmap to prioritize time to value which gives us a relatively good ROI quickly, within the first year is our estimate, rather than a sequence with small value lumps along the way in the next few years.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='We have spent quite a lot of time recently and are seeing that the first results already now.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:30:31] Sam Charrington: Maybe to replay that a little bit to make sure that I\\'m catching what you\\'re saying. It sounds like you started out, you had a bunch of proof of concepts and you built some fairly low level infrastructure, things like DataBricks and AirFlow and other things to enable you to scale those proof of concepts and more recently, what you\\'re seeing is you\\'re pushing up the level of abstraction and so you\\'re saying, \"Okay, instead of building out this vertically integrated', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='integrated demand forecasting app for a particular use case, hey well, we need to do forecasting across lots of different use cases potentially. Let\\'s build another level of platform at the forecasting level or the application level at the risk of throwing around too many buzzwords here.\"', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:31:28] Errol Koolmeister: You're spot on and that's exactly what we're doing. We increased the abstruction level so I think that's a very good summary of what we actually are doing, focusing more on the reusability effect not just on technology but on the output as well because we are, right now, obsessed with scaling the value aspect.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"I did the math and it's not complicated. If we are a 100 people today or 120-ish working on the AI use cases, we have around 10 use cases in production right now, if we're going to have all our core operational decisions amplified by AI by 2025 which is our tech leap that we're aiming towards, we're going to need thousands of people if we're scaling it's vertically so we need another way of assessing the talent gap and the time to value assessment as well.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:32:22] Sam Charrington: You mentioned that part of this recent reorg put you in the same organization as IT. I'm curious about the implications of that or the impacts of that and how you work together with IT. In what ways has it impacted your workflow and the way you approach your tasks?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:32:52] Errol Koolmeister: That's the thing. One of the good decisions that was taking a few years back was that we were going to start the AI efforts all on cloud with basically no limitations around the technology, we could pick pretty much whatever we wanted. It was a curse and a blessing but if you look on a traditional IT on the prem, traditional waterfall approaches, relatively long cycles, deployment, synchronizations not so agile, going into the new business tech organization where we\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='where we establish around 250 product teams, all supposed to work [inaudible], the IT department coming down from a monolithic type of situation, trying to break that down into product teams, relatively small, of course they have a lot of legacy so we are running really fast, we are able to ship with every delivery.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"The integration with IT is still relatively few but what we are experiencing now is that we are encountering some of the traditional processes from that type of organization so I would say it's good for the company because we are getting everybody up to the same standard on how you deliver in modern software organization or modern tech organization but on our side, of course the lead times become a little bit longer when we're trying to integrate.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:34:25] Sam Charrington: But it sounds like you're still operating well. Is AI operating primarily cloud first but the rest of IT is not primarily cloud first? Is that part of what I'm hearing?\\n\\n[00:34:40] Errol Koolmeister: The strategy's called first for the company then of course the migration takes a bit of time for the rest of the organization so we are 100% cloud-first which makes life a lot easier.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:34:54] Sam Charrington: When you get a proof of concept or a project to production, does that stay within your org for operational responsibility or is there a handoff to IT? How have you structured around Ops long-term?\\n\\n[00:35:17] Errol Koolmeister: IT doesn't exist any longer as a notion. It's just business tech now.\\n\\n[00:35:23] Sam Charrington: Got it.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:35:24] Errol Koolmeister: What it is on the outside is that we have the notion of \"You run it, you build it.\" What we said to try to do is work together with the domains so our domains like sourcing and production, customer fulfillment, et cetera, they are responsible for the actual use case. We are responsible for the capability, the best practice and the [inaudible] so what we do is we work together with the domain, they are going to run the product longterm but we are going to make sure', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"going to make sure that they have the specialist to solve the problem so take in-season demand forecasting for instance. We are running the algorithm, the part that actually produces, they will handle the integration and the actual usage of the product so we can specialize on being specialist in demand forecasting and they can integrate with the business and the change management and run it through them so it's going to be two product teams working together.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:36:18] Sam Charrington: The business units, it sounds like they have their own technical capability to operate these applications long-term but they rely on business tech as an enabler to help them build in emerging technologies. Is that the idea?', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:36:41] Errol Koolmeister: Yeah so the business units, they are actually the ones running the business and then business tech is a traditional, old IT organization but being a more agile organization these days so we serve the needs of the business units in the group.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"They don't run but they use the products that we develop so for instance on the customer side, what we're building now is a platform to integrate with H&M.com to make it fully personalized so we can deploy microservices that can interact and create a personalized experience.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"Of course, those that actually are working with the use cases, working with the sales and everything, that's our online sales units and that sits in the business units of the H&M brand and business tech is creating the technology to enable them to do their job the best possible way.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:37:31] Sam Charrington: Got it. In all of this, in your journey there at H&M group, growing the team from zero to I think you said 120 employees, you've gone through reorgs and transformations. What are some of your biggest learnings and all that around how to scale an AI team from the start?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:38:02] Errol Koolmeister: I think one of my biggest learnings is perfection is the enemy of done. I think if you wait around and want to create the best product or want to create the best technology, you're never going to reach that end state and if you're serious about running fast and scaling, then you have to start now. It takes time. Even though we have run extremely fast in the last two and a half years, we have just started. We are extracting value.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='Many of the companies I worked with and seen doing these things, they wait too long. They either want to build a perfect infrastructure, they want to build a perfect model, the money evaluate. They want to get everybody on board. Of course stakeholder management is extremely important, communication is extremely important but at some point you just have to say, \"Let\\'s just do it\" The startup mentality. If there\\'s value on the table, let\\'s go out and get it.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='Scaling is being an entrepreneur where you start something from zero. You have to have a bit of guts as well and just go with the notion.', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:39:08] Sam Charrington: Just to get tactical on that particular point, often with these machine learning projects in particular, the looming perfection or the small percent of increase in whatever your target metric is a temptation out there. How do you and your teams stay focused and know when \"Done\" is? Where in the process do you know that and how do you define it?', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:39:40] Errol Koolmeister: It's super hard. It's case by case but at some point, you have to have a baseline, you have to have a target but it's like you're saying this off of the ship with every delivery. This is not the research lab. We do have one of those as well and they have different prerequisites and different targets. What we want to get to here is we want to be able to ship and show something within every sprint. Every PEI needs to be able to ship something so don't expect to be\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"don't expect to be able to sit down and fiddle around and try to optimize for too long and you have to work with your stakeholders as well and agree on a level and have an open dialogue.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"What we don't want areaunicorn data scientist that solves everything themselves. What we want is talented individuals to work together with the team and have a transparent dialogue around their process and what's hard, what's not working so that everybody can take an informed decision if we should go to production with what they have or if we should wait another sprint.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:40:44] Sam Charrington: You've talked a bit about thinking like a startup, entrepreneur, you've mentioned terms that we know from Silicon Valley companies, OKRs and technical debt and the like, clearly you're trying to operate like a startup within H&M group. Does that create friction for you in a large, established enterprise and how have you addressed those kinds of issues if you've encountered them?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content='[00:41:15] Errol Koolmeister: Definitely. I\\'ve seen people looking at us and saying, \"Why can they do these types of things?\" without actually looking at themselves and try it. I think what it comes to is having a good story and communication around these topics. What I try to do in my communication is that I\\'m doing this for the entire company. This is for the better good of this company. It\\'s not for just the success of the AI department so the story is really around how we, as a company, come', metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"as a company, come around and it's not about threatening other people, it's about amplifying other people to make sure that the people in this organization get to stay away from the boring, long tail type of problems and get to focus on the really interesting stuff.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"AI is really good at the long tail type of problems and let's be humans that can focus on the creative things, the development of the organization and the business so we tried to position ourselves not as a threat but as an enabler for people in this organization to be their best themselves.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:42:23] Sam Charrington: Awesome and is part of the way you talk about what your group is doing? Do you have some moonshot project or a vision that captures what you're looking to.Create over the longterm?\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:42:43] Errol Koolmeister: Yeah, I think it goes back to the tech leap we want to do. We want to have all core operational decisions amplified by AI by 2025. That's where we want to be and I think it's possible with the strategy that we have created and I truly believe that if we're able to onboard more resources of talent and then grow with [inaudible], we will be able to transform this company to a truly an AI-first [inaudible] company.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:43:14] Sam Charrington: Awesome. Well Errol, thanks so much for taking the time to share a bit about what you're up to. Very cool stuff.\\n\\n[00:43:20] Errol Koolmeister: Thank you so much, Sam. A pleasure to be here.\\n\\n[00:43:22] Sam Charrington: My pleasure, thanks.\", metadata={'source': 'content/data/503 - Errol Koolmeister.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: Welcome to the TWiML AI Podcast. I'm your host, Sam Charrington.\\n\\nHey, what's up everyone. TWIMLcon is over and what a blast it was. My team and I had a great time bringing over 50 speakers and 40 sessions to attendees from 43 countries around the world. Attendees learned how teams at companies like Spotify, Google, Netflix, Toyota, BP, and more apply their people processes and technology to deliver more ML models into production more quickly and efficiently.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"If you missed the event and want to get a sense for all the great content we shared, check out twimlcon.com/blog for highlights and takeaways.\\n\\nMore importantly, it's not too late to catch up on what you missed. Visit twimlcon.com/ondemand to purchase access to the event videos at special introductory rates. Listen on for one of the five great keynote interviews I did live at the event.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Thanks again to our friends at LinkedIn for their continued support of the podcast and for sponsoring today's show. LinkedIn solves complex problems at scale to create economic opportunity for every member of the global workforce. AI and machine learning are integral aspects of almost every product the company builds for its members and customers. LinkedIn's highly structured dataset gives their data scientists and research the ability to conduct applied research to improve member experiences.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='member experiences. To learn more about the work of LinkedIn engineering, please visit engineering.linkedin.com/blog.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"All right. Onto the show. Without further ado, we are ready for today's keynote interview. I'm super excited to be speaking with Ya Xu, head of Data Science at LinkedIn. Let's get Ya up and jump right into the interview.\\n\\n[00:02:12] Ya Xu: Good morning.\\n\\n[00:02:13] Sam Charrington: Good morning.\\n\\n[00:02:14] Ya Xu: Good morning, everyone.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:02:15] Sam Charrington: I am super excited to have this opportunity to chat with you. Thank you for joining us and for LinkedIn. LinkedIn has been a huge supporter of the podcast over the years and we're very appreciative of that.\\n\\n[00:02:30] Ya Xu: Thank you for inviting me and I know TWiML for many years as well. I know that a lot of folks from my team actually has been showing up on your podcast so it's a great honor to join you here today.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:02:42] Sam Charrington: Awesome. Awesome. So let's jump right in. I think this interview is going to be particularly interesting because earlier in your career, you were on the platform and infrastructure side of things that the thing that we're focused on here, but now you're the head of a large Data Science team. Tell us a little bit about your background and your journey.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:03:01] Ya Xu: Sure. Maybe I'll go a little further back in my journey. Many years ago that I got my PhD in Statistics from Stanford. During my time there, I started in [eight] for those of you who are maybe familiar with the statistics PhD program, it's quite so radical in general.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Stanford also has a very strong tracking that applied approach onto statistical problems, too. So, that's where I essentially spent a lot of my researching, sort of the how do we apply statistical modeling to solve some of the real world problems and did my thesis in semi-supervised learning graphs. Back then, semi-supervised learning wasn't that popular to today. The reason I'm sharing that is also because if I'm thinking about my passion and what I like to do in my career, it's always about,\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"it's always about, even though that I was doing platform earlier in my career, like it's always this internal drive of wanting to solve some real problems. Fast forward to my time, wanting the industry and for my PhD days, worked at Microsoft for a few years and then joining LinkedIn, and I've been in LinkedIn for about eight years now. It's kind of crazy how long, how fast, the time flies. In my early days both when I was at Microsoft and at LinkedIn, I was an individual contributor very much\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"very much focusing on building platforms, enable tooling to solve between [Nable] and many other folks in the company to be able to utilize either that'd be directly applying it in the business and the products that they're in, creating that leverage across the board. That's what I spend most of my career so far.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='About three, four years ago, that was when I decided I wanted to learn how to manage a team. I was very fortunate to be supported in that career journey and transformation by my boss, who is the Chief Data Officer in LinkedIn, and also obviously many other leadership at LinkedIn.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='So then I stepped into more I guess what you call application side of the world, but certainly still very much working very close at the ways the folks who are building the platforms and maybe even more at the customer side, but also at the same time, I do have folks on my team who are working hand-in-hand with the platform teams and from the science angle, to make sure that we have the right methodology, we have the right approach on how our platforms are enabling and solving the problems that', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='the problems that we see.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:06:05] Sam Charrington: Awesome. Awesome. Speaking of those problems, I suspect everyone who is watching us is familiar with LinkedIn and perhaps even some of the ways that LinkedIn uses machine learning, especially if they've caught some of our previous interviews with LinkedIn folks, but what are the specific types of problems that your teams are focused on?\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:06:29] Ya Xu: I'm glad that a lot of you are familiar with LinkedIn, but maybe not everyone is familiar with how LinkedIn is organized. So my team is the global, central data science team. So what that means is there is really only one data science team at LinkedIn but the way that we operate is that we actually work very closely with various different functions and areas across the company. So, if you think about a company has various functions, that's either deliver and develop product\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"and develop product that the folks can think about if you use the LinkedIn app or if you go to linkedin.com on the web, that's what our product is.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='So I have folks in the team who is working in embedded ways of various different areas of a product either that is feed, that is messaging, that is search, that is jobs and careers; all of these aspects of all of our product. I also have folks who are very closely working with our go-to market teams, and this is particularly our marketing teams, our sales team, thinking about how we can use machine learning statistics to actually optimize our go to market motion as well. A simple example would', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"simple example would be as marketing team, who should they target? How should they optimally spend their marketing money? As our sales team, which are the customers that our sales team should really talk to and which customers are more likely to churn so that they can actually engage with them more closely? So there's a lot of things that we do and then on top of that, we also work with the infrastructure teams too, by thinking about if you have a lot of Hadoop jobs, how do you optimally\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='how do you optimally schedule those jobs such that you can avoid the peak time and that you can optimize utilizing your offline resources, both in terms of memory and storage. So there is just array of problems that the team solves. Then going to what I mentioned earlier, I also have folks who are focusing more horizontally. Again, thinking about enabling. So folks who are focusing on developing experimentation methodology, folks who are focusing on differential privacy that we can chat more', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='we can chat more later as well.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='Folks who are more focusing on anomaly detection, algorithms forecasting, since that is more horizontally enabling various different applications that is happening again in the various different areas that I mentioned earlier.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:09:11] Sam Charrington: You mentioned that your team is centralized but also embedded. This is the organization as a topic that's come up quite a bit at the conference and every organization kind of finds a different place on the spectrum, but often I see that at a certain level of size or scale of a data science team, it tends more towards a distributed model because the different businesses want to have their own data science resources.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Tell us about the choice to maintain the centralized embedded model and what works there, what doesn't work, and how do you think about that generally?\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:09:51] Ya Xu: That's a great question, and you're spot on. You know, if you want to have five data scientists, and it's certainly the right decision is to centralize them because you actually are able to offer them a career growth, you offer them up to your group that they can talk with and all of that. When the team gets really, really big, I know that there are certain companies out there that has maybe, I don't know, close to a thousand data scientists across the company. I think then\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"I think then you're definitely getting to a situation where you have enough mass weaving each of the business unit that you can have maybe not a global centralized data science team, but you kind of have the local sort of center of excellence, weaving different units.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"So at LinkedIn, we're somewhere in between in the sense that my team is about 200 to 250 people. So sizable but also at the same time, this goes into my experience on both the platform side and also the application side, is if you think about the benefit of having a team that has seen the central organization, the benefit is delivered. For example, I can put my way behind what are the right tuning that we should be building for all data scientists. So where my team is sitting, because we have a\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='because we have a broad view across all different applications, we understand together collectively - what are the needs that we have from both the algorithm standpoint, methodology standpoint, from the platform 20 standpoint, to be able to make every data scientist to be more successful.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"This allows us to establish that leverage across, but you can say on the other hand, the downside of having a central team is the potential danger of you have this central team think that they are the center of excellence, sit in the corner and not really actually try to figure out what are the problems that we're solving. Like, think about this - I can come up with the best algorithm, the best approach but I could be solving the wrong problem, then what's the use of that being a company if\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"being a company if you're solving the wrong problem. I actually think the LinkedIn model works really well being the way that I have my team organized in the way that they are kind of in their unit and then they work very much embedded each of the product area or the business area they're working at. So they pretty much, you can think about them as one [with] the domain area they're working at, one [with] the rest of the data science teams. So they are solving problems that is really business\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"is really business critical. But also at the same time, they're going to enjoy the benefit of their knowledge sharing, that leverage, and sort of that strategic approach in how we are solving all these applications and problems as well.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:13:04] Sam Charrington: Have you been on both sides of the fence relative to platforms and infrastructure and application side of things?\\n\\nWhat do you think makes for a successful working model between those two different teams? Where do you draw the line between one and two? It sounds like you have some horizontal capability within your team. How do you generally think of that aspect of organizing your team's work?\\n\\n[00:13:32] Ya Xu: This is such a great question.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"First of all, I want to say that I've seen mainly failures in that working model. Not saying like, 'Oh, this is disastrous'. The whole company failed because of that, but you can definitely, even today, I still see pockets of examples that I think made that working model not working. So let me kind of be explicit. The way that I've seen on both sides of the aisle is folks on the application side, they complain about problems - 'Okay, this is not working, is not able to allow me to do X, Y, and\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"me to do X, Y, and Z'. They kind of done so that problem over the wall to the platform team and the platform team catch it. That user are just doing exactly what the applications team tell them to do. For example, I need you to build it in this way so that I can use it. So they either are taking orders from the application team and not thinking about, 'Is that the right architecture? Is this only solving your problem?'\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Other things down the road that this makes this not like a long-term solution. 'Did you go do that?' Or they're like, 'Who are you to talk to me? I'm going to take orders from you? I'm going to just do my thing 'cause that's what I care about the most? I've seen those two extreme examples to play out in reality.\\n\\n[00:14:57] Sam Charrington: Then the way you're describing it sounds like a delicate balance. Some pushed back, but not neither of these extremes.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:15:05] Ya Xu: Absolutely. Absolutely. So the part that I always liked, I'm going to quote one of those legendary engineering leader, I think, Eldridge that he used to say, 'Do you want to be part of the problem or do you want to be part of the solution?' The thing is that a lot of times, application teams think that it's the platform's job to build the solution, and it's a platform's job to make them successful in using those tools and the capabilities, and the thing is that has to be very\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='that has to be very much handing in.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"So let me kind of break it down. You think about there's various different stages as you are building a platform. In day one, as you're building that capability is to have our accountability on both sides. I would always go to my team and say, 'Hey, you know what? It's not just the platform's job to deliver the feature you need. If the feature is delivered and you're like, you know what, that's not the right feature that's going to solve my problem because I have all the problems. I'm not going\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"I'm not going to be able to use that platform.' I'd say, 'Hey, you know what? It's as much of your responsibility as much as their responsibility as it is yours, so I'm going to hold both of you accountable to make this successful.' So I think from day one, that just really forces the teams to think about it together as they have the same goal, the same success, that both sides have, and then once this is sort of maybe a only piece built, and you get into this sort of adoption phase. On a lot of\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"phase. On a lot of times, the platform team has these challenges as they build something they think is amazing, the most wonderful thing in the world. Then the folks on say, 'I've got something here that kind of worked for me. Why would I want to migrate all my approach to yours?' People just have that intrinsically on waiting list to go move into something new, even though there's a new thing, long-term may be beneficial for them.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='The way that I also see that worked really well is having this model that I like to call a champion model.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"So this example you'll get a platform and that you have to convince 10 other teams to use it. Don't say, 'Hey, all of you guys come and use my thing,' but start with a couple of them who are already leaning in. They're already showed interest. They're already like, 'You know what? I'm actually excited about the same.' So get them on board first 'cause the other customers who are more likely to be telling you what's going wrong and they're not going to abandon you like before just because there\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='just because there is a simple bug that you have in your system. So work with them to address really their need, and also allows your platform resources to be able to focus on making them happy. Once you have good team A fully onboarded and happy using your platform, you go to team B, you go to team C, and once you have four out of the 10 teams onboarded, and they started to demonstrate the value of using your platform, boom! You know what? The rest of the six teams would just pull you on.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"So I think, again, in our adoption phase, there is also that sort of approach and that needs to be thinking very carefully as well. I would say then the last phase, we talked about during the building phase, during the adoption phase and then in the mature phase. So let's say you've already got a platform that is running, everybody's using yet, and obviously we all know that you have to be continuously evolving and building on top of there by just creating that holistic culture that the\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"culture that the application team, they should demand the platform teams. Another mistake that I've seen people make is, 'Oh, you know, the platform is not able to solve my problem. So I'm going to go build myself something else.' I think engineers, it's not the greatest, almost it's fueled by me.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"I guess this is in general, but we all have, 'Mine is the greatest.' So creating that culture on the application side to really demand the platform to be able to solve the problems with them. So I think that's one, and also on the application side, having this model what we call SME, the subject matter experts. Thinking about the individuals who are expert at using those platforms and they become this local [champion] full platforms seeing their team. So you imagine that you'll build a platform\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"build a platform at being a team of 20 people, if you have one person who is an expert of using it, then the other individuals on your team can go to that person to learn how to use it. At the same time, if they have an official request, it's actually much easier to go through that person - the SME, because the SME understands the platform capability. So they're not just going to ask any random feature. They're going to ask feature that really matters and to the team. The platform is also much\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"is also much easier for them to take those feature asked and then work with a SME to figure out what's the right solution on to evolve the platform. It really takes both sides of the coin to make this happen really well.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"One last thing I would say is also just from architecture standpoint, from platform architecture standpoint: 'Always think about how to build a platform in an extensible way.' You wanted to democratize as much as you can. If you have a platform, a team of 10 that's building this tool, you have 500 people who are using it and think about how you can give those 500 people a chance to contribute to your platform. The more that you can design your architecture in that way, the better it gets.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='[00:21:09] Sam Charrington: What are some ways that the platforms at LinkedIn support this?', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='[00:21:14] Ya Xu: I want to say many of our platforms do that. I know that you are quite familiar with our [Promel] and the platform and that you can actually build your modules on top of it. A simple example is, my team actually develop this model, like explain ability, capability. They used it in their application that went really well, and they just viewed it as extensive module on the platform so other people who wanted to use it, they can use it, too.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Another example is our platform for anomaly detection and forecasting. Think about there can be use cases where the existing algorithms that we built into the platforms were not enough to detect a particular anomaly. So we asked you again, allow the application teams to then introduce their own algorithms on top of it. So there's always that the platform is focused on the core, but if the platform is architected in a way that allows that stability, then you got all the 500 other people who's\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"other people who's going to be working for free for you to make the platform better versus they decided, 'You know what? The platform is not able to solve my problem. Maybe I'll build my own.'\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='[00:22:29] Sam Charrington: Yeah, yeah. Before jumping into questions and continuing the interview, I just wanted to observe that a lot of what you described about the relationship between the platform team and the application team would equally apply between your team and the business team that you serve. But just from the other direction, do you apply the same kind of philosophy in that relationship?', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:22:51] Ya Xu: Yeah, that's a really good [meta] observation. Absolutely. I think the part that I've always seen of organizations, how to help organizations to be successful is again, for them to feel like they are really not working against each other. They are working towards the same goal. Once the folks really internalize our goal is the same is to make this successful, then everything just fall together. So I agree. I think that's a really good observation.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='[00:23:19] Sam Charrington: Interesting question on this topic from Thomas in Q and A about avoiding quote/unquote \"hero syndrome\".', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='You talked about engineers always wanting to build it themselves. That\\'s maybe related to this idea of \"hero syndrome\", but the team that kind of wants to be \"The Team\" to build the platform, and LinkedIn\\'s maybe a little bit beyond this because you\\'ve got established teams that own platform, but have you seen early on where a new technology or idea comes around and different teams are kind of vying to be the one who builds and owns the official thing?', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='[00:23:59] Ya Xu: First of all, I think it\\'s Thomas who made that comment. I feel very strongly agree with you that you\\'re avoiding the hero syndrome. There was once I heard somebody saying that in terms of which kind of talent they hire, when they interview what matters the most to them. That was a startup founder. His comment is, \"I\\'m looking for somebody who has a high IQ over ego ratio.\"', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"I think sometimes ego can really get in the way of the border picture. So Evan Dean. Maybe the days when LinkedIn was kind of going through a growth pain, when we had multiple teams, multiple data teams in various different parts of the company, so I'm going to take just one sentence to describe LinkedIn a little bit.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"So organizational, LinkedIn is functionally organized. We have engineering team that reports to head of engineering. We have product reporting to head of product. We have the finance team report to our CFO, and then all of them then report up to the CEO. I remembered that when I first joined LinkedIn eight years ago, we didn't really have the data team engineering, which I am a part, and then we also have a data team that is reporting into product. We also have a data team that reports into our\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"reports into our CFO, so you can see that, sure, in the early days it took a lot more effort to align, making sure that we avoid that hero syndrome and then actually all come together in building the right things all together. But I think nowadays it's simpler. It's easier just 'cause also the company is getting a lot more mature from organizational standpoint as well.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:25:50] Sam Charrington: Let's talk about some of the specific areas that your team operates and has built out capability. One of those is experimentation. Can you talk a little bit about experimentation and why it's so important at LinkedIn and some of the things that you've done there?\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:26:08] Ya Xu: Absolutely. Experimentation. I know sometimes that term gets used in various different ways. Here you are particularly referring to this randomized controlled experiment, like AB testing that's also another common term that people use. So why is it important? I'm actually going to first use a story, especially, I know a lot of folks in the audience are ML engineers. You develop a lot of models.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"When I first joined LinkedIn almost eight years ago, and then a couple months after I joined the company, I was pulled in into this discussion, and at that time I think they just had it all backdrop, we didn't really have an experimentation platform running. Experiment was a little bit of spotty, depending on who you are, the way that you want to do it or not, so it wasn't a common practice in terms of our product development at all at the time. So I was pulled into this discussion. The\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"this discussion. The discussion was that there was a experiment that was run launching a new machine learning model. Eight years ago, LinkedIn wasn't that sophisticated when it comes to using machine learning in product development. Yeah. So think about the bar was low and then you got that model that was launched and that was amazing! You're looking at the numbers coming from experiments, it was just like shockingly amazingly good results.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"So the team went ahead and launched it. Back then LinkedIn was still independent, well, it's still a standalone company. We were not part of Microsoft. People were watching us very closely because if you have a 10% lift on revenue, that's huge in terms of what translates into our financial numbers. Then that goes into our stock price and all. So our finance team came and then they looked at me and they're like, 'Wait a minute. You launched this thing.' But I'm watching the numbers in terms of\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"numbers in terms of our revenue, but I did not see a tip. I did not see my time serious. I did not see that there is a game on numbers. That's not real. So what we had to do was we actually had to vamp down that experiment. They don't even think about you've got this wonderful feature. We have to vamp it down. Reverse it. To actually do that, and we saw in that time, boom, okay. You can have a drop right to actually make everybody believe this is actually a great thing that we're launching, that\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"launching, that we're building.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Now let's think about fast-forward to today. Me and Dean, we add every single given time we have about 500 experiments that's running, and that ranges not just from our algorithm on improvements, but also with pretty much every single product launch, every single change that we're making. It goes through AB tests 'cause that's the way that we understand how our members, how our users are actually reacting to the changes we're making. Do they like it or not like it. For every single launch we\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"single launch we monitored effectively like over a thousand matrix just so we get sums as much as we could of how this is a good feature or is a bad feature. But not only that. Internally as our process, every team are taking the results from their experiments and as the counting of how much they have contributed. So they really think about that. Going from eight years ago, where we were for that one launch to today, it's a drastic improvement but the benefit to the company is tremendous because\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"tremendous because think about over the time, over the years. So why did we decide to invest more in ML? It's because we realized, wait a minute, it was a really good investment. Well, when we actually are focusing developing those algorithms that is actually able to bring a lot of upside to the business so that translates into the right investment for the company.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"At the same time, there's also this culture that again, going back to Thomas' question on this hero syndrome, I think maybe I was a bit too harsh on ourselves. I think heroism is everywhere. Like we would have this maybe two product managers who are both thinking, 'My idea of building this product is better.'\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Nowadays instead of arguing with each other, intuition against intuition, the conversation becomes very simple: 'Why don't I just test it?' If I test it and it tells me that it's a better thing. Or maybe it tells me that my intuition is wrong, I will learn something. So it really intrinsically changed this culture of maybe this heroism culture to this learning culture, to this really data informed culture.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:31:20] Sam Charrington: You mentioned something in there that was really interesting, that you measure the contribution of folks on your team based on their results from this experimentation platform. If I'm understanding you correctly, makes a ton of sense. You don't want to measure folks just based on model results in a vacuum because who knows what those actually result in production, but then in production, if a model is in production for a long period of time, you've got all other\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"you've got all other pedals and things happening on the site that are impacting the longterm impact. So tying their performance to the results in the experimentation platforms and interesting way to kind of isolate the impact of that one model. Is that the idea?\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:32:08] Ya Xu: First of all maybe just make a small correction. I don't mean as in one way you're evaluating an engineer, like how much metrics did you gain? In that sense, I think a lot of time he's thinking about in terms of the team, in terms of the area, like we have a goal, we have a target and that target is say to improve metrics X by 5%. Then whether this whole team, when I say team, I actually more like area. We talk about [how the team] cross-functionally, collaborating together to\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"together to achieve that 5%, but deep this area, deep this line of business achieve that 5% and gain on that metric. We do keep a very close eye, and then that is measured against the experiments. We add up all the gains that we have from various different experiments that we have to see 'Do I hit that goal?' But in terms of the individual, there's a lot more that goes into the experiment.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:33:11] Sam Charrington: The point is that the experiment is an interesting way to isolate the real life impact of a model in a way that it's hard to do without exposing it to the real world. Once it's exposed to the real world for a long period of time, there are other factors that make it hard to isolate that particular model's impact.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:33:30] Ya Xu: Definitely. Definitely, and I always think about when we're building models, we obviously we have our utility functioning objective and then you train your model. You really try to optimize that, and we do our offline replay also to see, 'Hey, is this model actually, we think that is going to improve CTR? Is it actually going to be improving CTR? All of these, I like to think about this as like a line my boss used to say, 'Intent versus impact.' So your intent when you're\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"intent when you're building the model is to optimize towards that objective function. That's where experimentation comes in because that is actually measuring the real impact of what your algorithm is doing.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:34:11] Sam Charrington: Another area that LinkedIn has invested quite a bit in is privacy, in particular differential privacy. Can you maybe give us an overview of your team's work in that area?\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:34:26] Ya Xu: Certainly. I think it should not be a surprise to everyone here that privacy is very, very important and I believe is actually one of the biggest disruption that we will have. While disruption always presents challenges and opportunity at the same time but thinking about from the regulation standpoint, which is the bare minimum that we hopefully forces and many of us to start thinking about this area. Most of you were saying like GDPR, CCPA, even thinking about Apple's IDFA.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"about Apple's IDFA. It's not about [if] anymore. It's about really when, and obviously from consumer standpoint, it's a super, super important area as well. For those of you who are intrinsically very driven by solving really challenging problems, technology-wise, this is really also just an area that has tons of opportunities.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"So going back to your question regarding my team's work on differential privacy, I want to first maybe motivate a little bit 'cause when we talk about privacy or data privacy, it's a massive area. You think about it's always interesting like a tussle between human, just the term data and privacy. Data. Think about what data does, we use data. We extract information from data. That's what data is for to data scientists and to ML. Then you got privacy. Privacy is really about how to prevent\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"about how to prevent sharing information. You want us to extract information. You got the other pool that you want it to actually be sort of stopped sharing information. It's that interesting tussle between the two, and we talked about you can introduce privacy. Does that make sense? I think about a lot of what GDPR is doing and say, 'Hey, you know, it's PI information. We should anonymize it.' Then you got a lot of these algorithms that's there as well. You [pay] on anonymity, all these that is\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"all these that is able to do certain level or different levels of anonymization. But that's not enough because if you think about there's umbrella stats from research several years ago that among a US population, 87% of US population, if you know their birthday, zip code, and I think the other one is gender. I think it's birthday, gender, and zip code. Then you will be able to know who they are. You get to pin down who they are. That just says how challenging it is to do privacy well. So coming\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='well. So coming back to like differential privacy. Yeah.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='That has become a more by gold standard for how we preserve privacy data.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"The concept of differential privacy is very simple. So what it really says at a high level is what you can learn from the data should be the same with or without a single person's information as part of it. So think about if you are learning a distribution from a huge dataset, and let's say you learned about a distribution curve, and then you take one member or one user's information out of that data set, and then you'll learn that you'll use the same algorithm. You'll learn another curve. These\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"another curve. These two curves should be very, very close to each other. This is where, what we call, like should be the difference should be excellent. It should be very small. I had to see the absolute number of that. That's differential privacy guarantee.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"So if you have algorithm that is able to meet that criteria, it's guaranteed to have differential privacy and I'm not going to go into a lot of theoretical details, but then it comes with a lot of benefits. You can do the additive and all these. We have very heavily invested into both.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='Ultimately, you are going to apply differential privacy. The ways that we use data across the board, we actually have introducing our ads reporting and think about like you, the reports that we give to our advertisers that we applied differential privacy on top of it.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"When we share our data on externally to public on, for example, what are the companies that are hiring? What are the skills that's trending? All these, we actually did also apply differential privacy before we share the data externally. Just so that we can really make sure that we put our members and customer first so that there's no chance and that their information will be leaked or would be under this sort of there's a bunch of attacks that people can do to back engineer the individual\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"the individual information, and under differential privacy, that just guarantees that there's no such a way that there's no such risk.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:39:30] Sam Charrington: So do you think the differential privacy is ready for prime time for the average company? I mean, LinkedIn has been at the front of this and has spent a lot of time working on it. How ready do you think it is for kind of general consumption and in particular here there's differential privacy and differentially private machine learning, which is a whole other set of challenges.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:39:58] Ya Xu: Yeah, that's a great question. I want to say it is ready. I'm going to be bold on that one. First of all, we all know census. Actually census is using differential privacy now so census is easier now. [My house has been using it,] and on top of it, I do also think that there are a lot of open source capabilities that's out there already, like Microsoft has this big open source differential privacy solutions out there. I think Google also has some. So even if you don't have\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"if you don't have expertise in your own companyto develop your own algorithm, you can still get started by using the ones that's already open sourced.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"I would encourage everyone to start getting into this field. On the other hand, other challenges of building those solutions and applying those solutions. Yeah, absolutely. I have to say one challenge that we see very practical challenge is how do you think about, we talked about this difference between the two curves you learned, the Epsilon. How do you choose it? How do you choose Epsilon? Because that is going to indicate the trade-off between the utility and the privacy. Who's going to\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Who's going to decide to buy Epsilon for your company for your application. That's a very practical challenge that the company has to face.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"The second one is also when people think about differential privacy, they think about, 'Okay, you got data, you add a bunch of noise to it. Then you can forget about the rest.' Everybody knows how to add noise to data.\\n\\n[00:41:39] Sam Charrington: That's the easy part.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:41:41] Ya Xu: It's the easy part. You can choose a lot plus noise. You can choose [gassy] noice. But the hard part is actually depends on the application. Depends on the query. Like different differential privacy algorithms, even though that they could all meet the differential privacy criteria.They're all different differential algorithms, but they can actually have a different information loss in the process. So let's say for example, you have a query. If you apply the noise at the very\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"noise at the very initial step, top of the funnel. When you would go through this whole query, what you get is very little information. So if you turn data into white noise, then there's no point of having the data to begin with. The challenge of differential privacy is also their needs, that sort of this expertise, especially in some applications to come up with the wide algorithms that you can actually preserve privacy, but also preserve the utility of the data itself as well.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:42:43] Sam Charrington: Yeah. For more on this, I refer folks to the interview that I did. The interview was just over a year ago at NeurIPS in Vancouver with Ryan Rogers at LinkedIn on the way that differential privacy was applied to this problem that you call the top K problem, and we go into a ton of detail there.\\n\\nIn our last few minutes, I'd love to hear about some of the tools and platforms that kind of give your team leverage at LinkedIn.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:43:16] Ya Xu: Well, I hope I've made it bluntly obvious that I'm a big fan of platforms.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"We have actually a sister team that to me, they really focus on building a lot of the data platforms. Again, not just to my team. I'm thinking about the ways of the company as well. So I would say a few of them that has been super critical, Wong, I've already mentioned about experimentation platform 'cause that's really, the easier that you'll make the experimentation process to be, the more people is going to be using it. Then the more data-driven that the company will be. Then that will have a\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='that will have a cascading impact on how we are investing as a company and the kind of people that you attract and all that.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='The second of all is certainly our machine learning platform. A platform that is able to both thinking about how to, if I think about any field is how fast different fields has evolved over the past few years, like machine learning area is definitely, literally you got, every time, every day, you open up a research journal, you will see something new that some people has developed that works better than what had happened yesterday. So thinking about the platform is building a way that is able to', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='way that is able to be extensive law, that is able to evolve ways the industry with the field. So super critical with that as well. Again also, how do you seamlessly transition between online and offline? So a lot of really good problems in that space and certainly my team uses that as well.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='The other platform I would say is our platform that devoted to metadata - search and discovery. Thinking about, you have a lot of various different data constructs, data assets, and like metric is a data construct. A model is a debit construct. Just any data set is a data construct. A feature that goes into the model is a data construct. When you start to be really very data focused as a company, you got all of these data constructs and data assets that lies around. How can you make sure that', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='you make sure that they can be leveraged by many people? How can you make sure that there are issues on them that we actually have a way to identify them?', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Having these almost like a catalog of all these data assets in the core of many other applications is really, really important as well.\\n\\n[00:45:53] Sam Charrington: May I know what you're referring to?\\n\\n[00:45:55] Ya Xu: It's DataHub, we call it DataHub.\\n\\n[00:45:56] Sam Charrington: DataHub. Okay.\\n\\n[00:45:57] Ya Xu: Yeah. You can also think about how all these data constructs relate to each other?\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"One big challenge that I'm sure fall out of the data developers here is you got a data maybe that feeds into a model or basing to some other things that you're doing. You have no idea where the data come from, and then over time, this data may deteriorate. This data may change because of five steps ahead. Like in the chain, in the lineage that it's creating that problem. So having again, a tool, a platform that is able to provide them that lineage, I cannot understate how important that is.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Then we also have a platform that is able to help us do anomaly detection, forecasting, and root cause analysis as well. When something goes wrong, what's the data, what caused it. First of all, were we able to detect it. We know, for example, like models, like features can have a distribution shift. For many reasons, I could have a bug in my product all of a sudden - the tenement tree, the tracking is off - and that feeds into my model automatically. Then the model turned out to be not\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content='turned out to be not performing anymore. Am I being able to monitor at every step of the funnel is also obviously very important to model development, to matrix development, all of that as well.', metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Then since you mentioned Pinot, I'm also going to touch down that one as well.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"Pinot is our distributed OLAP storage that we have developed ourselves and ending out open source several years ago that is really able to provide scale. If you think about the scale of data that it operates, that is able to allow us to be able to both serve online use cases. For example, if you go to LinkedIn, on the site, a lot of the analytics that's on the page are powered by Pinot in the backend, and it allows us to do internally able to do our OLAP on it as well. So super powerful. We\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"super powerful. We talked about differential privacy. We also are able to build our meteor on top of Pinot so that we can have all the use cases that's already in Pinot, then be able to use it on board into the differential privacy capability as well.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:48:19] Sam Charrington: Awesome. Awesome. We've covered a ton of ground in this conversation, but it's time to wrap up. Ya, thanks so much for joining us this morning and sharing a bit about what you and your team are up to at LinkedIn.\\n\\n[00:48:33] Ya Xu: Thank you so much for having me and I really enjoyed our conversation.\\n\\n[00:48:36] Sam Charrington: Same here. Thanks, Ya.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"All right, everyone. That's our show for today. To learn more about today's guest or the topics mentioned in this interview, visit twimlAI.Com. Of course, if you like what you hear on the podcast, please subscribe, rate, and review the show on your favorite podcatcher. Thanks so much for listening and catch you next time.\", metadata={'source': 'content/data/453 - Ya Xu.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: All right, everyone. I am here with Oriol Vinyals. Oriol is the lead of the deep learning team at DeepMind.\\n\\nOriol, welcome to the TWIML AI Podcast.\\n\\n[00:00:10] Oriol Vinyals: Hey, Sam, it's great to be here. I'm a big fan of the show.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:00:13] Sam Charrington: Thanks so much. I'm really looking forward to chatting with you. This conversation is long overdue. I'd love to get started by having you share a little bit about your background and introduce yourself to our audience.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:00:28] Oriol Vinyals: Yeah, absolutely. Yeah, this could go a long time, so I'll try to keep it maybe at the more recency bias, I guess. But yeah, I've been in the field of machine learning, deep learning since it was quite not as popular as it is today, so it's been definitely a fun journey. I'm happy to maybe link this back at the end of our conversation a little bit. But in a nutshell, the main passion I've had always is with sequence modeling. So, I started in speech recognition where a\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='recognition where a lot of deep learning, early days, things were going on.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Then I transitioned from doing my PhD in California, in Berkeley to joining Google Brain in very early days. Worked a lot on actually, natural language processing. We had maybe one of the works that links forward to many of the research that I'm doing these days is the sequence work on machine translation that we did back in the day.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Then, my passion for sequences was developing at some point it was a good time to actually go back to Europe. I'm originally from Spain. So, I moved to London in 2016 where I joined DeepMind. Since then, I learned a lot actually about reinforcement learning. One of the most fun projects I've had a pleasure to work with a large team of people is the AlphaStar project, involved in creating an agent to play StarCraft. But actually, in that creation, a lot of the sequence modeling background came\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='background came back as we used a lot of LSTMs, transformers, all these kinds of models that are very popular things. Thanks to their performance in NLP.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"These days, I'm mostly just focusing on leading the deep learning team and trying to just do the usual things that we like to do in deep learning, which is try to unlock state-of-the-art or new horizons and benchmarks in many modalities and as many modalities as we can.\\n\\n[00:02:35] Sam Charrington: As deep learning has matured, folks often get a lot more specialized. Leading the scope of deep learning writ large seems like a very big scope.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:02:51] Oriol Vinyals: Yes, indeed. It was fun because the way it all started it was literally a lot of proving yourself in very specific fields, even very specific application in those fields. So, the very first results that caught people's attention were actually on speech recognition. That started actually mostly, thanks to the Toronto group led by of course, Jeff Hinton. I got to learn that through my internships at Microsoft Research where a lot of action was happening. Then maybe the\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='Then maybe the most obviously notable moment that most people would refer to is the ImageNet moment that really happened almost three or four years. These days, time passes very differently. But yeah, three or four years after that breakthrough the ImageNet moment occurred.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Then, from there on, it's been an adventure of basically trying to find where are the frontiers of what deep learning models can or cannot do. Through the years it turns out that by applying more or less the same methodology through gradient descent, new architectures, but refining ideas, adding the right kind of inductive biases to our models, et cetera, you end up then transferring to more and more areas that involve, of course, natural language, machine translation. Then now, all sorts of\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='now, all sorts of language modeling, multimodal language, vision generative models.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"One of the recent successes, of course, of the year was AlphaFold zin which essentially all these tools just were applied to these very different domains. So, expanding to more and more domains of science in general has been now... it's the day-to-day, and the way to think, perhaps when you're thinking more deep learning in 2021 and beyond.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='[00:04:53] Sam Charrington: Yeah, I\\'d love to have you elaborate a little bit on that. When I think about the field, I tend to think about it in terms of there\\'s this set of work that\\'s been applying deep learning to new application areas. There has been, applying a deep learning approach to the kind of technical field. It\\'s not a great way to put it but like, \"Okay, we\\'ve got graph machine learning. How do we do that in deep learning? We\\'ve got reinforcement learning. How do we do that with', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='do we do that with deep learning?\" That kind of thing. Then, there\\'s been a lot of energy... Just how do we make deep learning more computationally efficient and make it easier to train? That kind of thing. Are you working across all of those areas or do you even think about it similarly? How do you think about that techtomomy?', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:05:58] Oriol Vinyals: Yeah. it's one thing that I tend to-- I found it useful throughout my career. This, I think the level of generality has increased over the years, but the what you try to do mostly, if you're a deep learning researcher having been in the field for a bit, is to try to just identify commonalities across modalities or problem settings. In a way, I have these sorts of arguments and I've given obviously, more detailed technical talks recently about what I call the deep\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='what I call the deep learning toolbox. You can see quite a few examples on some of the major successes recently on applying these toolbox approach. By the toolbox, I mean we have architectures, tricks of the trade on how to train the models, like optimization methods, how to use the hardware more efficiently. This is all part of this gigantic toolbox.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='Then, when you\\'re faced with a new problem, if you\\'re truly embracing the deep learning approach, you\\'re applying almost always the same first principle, which is you learn everything. Everything is learned end-to-end, from the output back to the input, by training a set of learnable weights through gradient descent in general. Then, you just pick and mix and match from the toolbox, the precise elements, be it, \"Oh, I have a sequence. Okay. I\\'m going to use a transformer. It\\'s a very long', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='It\\'s a very long sequence, maybe I\\'ll use an LSTM. I have vision. I use convolutions.\" Et cetera, et cetera. So, you\\'re mixing and matching all these components. Then, when faced with a new problem, like folding proteins, which obviously has some similarities, but in the end it\\'s like at the input, you have a sequence of letters, right? The amino acids that form the protein, and then the output are like this sequence-- an ordered set, almost of 3D coordinates, right? So, when you\\'re faced with', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='you\\'re faced with this problem, you say, \"Okay, I have some data that maps these inputs to these outputs, that people in the community has built over the years.\" Very expensive to do because you need crystallography and some methods to generate these training data.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"But then, with the deep learning mindset, you just go at the problem and then iterate over ideally a very nice training validation split that's usually is done in machine learning. Then, you start playing with details that matter a lot, actually, to unlock performance, to attack this particular new modality.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"So, I think it's the right framing to think about what is the next modality? What is a challenge? Is it a very large graph that we currently cannot quite do because yeah, we have graph neural nets, but do they scale properly? and so on. That is generally how then you see a lot of papers at NeurIPS and other conferences tackle these new challenges. What's beautiful about this is that even though there is a theory of deep learning--that's a field that I've gotten a bit into just because it's just\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"because it's just fascinating--but in general, how the field has advanced is, there is a problem out there. You take it, you cannot change it, but you apply this first principle of end-to-end learning, learnable model, powerful model, and then, hopefully you enable something that that field was not, maybe looking at the time. Although, nowadays many people have heard about deep learning and it's quite permeating everywhere. It's mostly, you don't have to prove yourself in maybe the same way that\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='the same way that we had to, by going one field at a time almost, as we were doing in 2008, 2009 up to maybe 2014, 2015, where things really start taking over and people start paying attention, given the successes were too many maybe to ignore.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:09:51] Sam Charrington: Two, three years ago, a lot of work was happening in the area of just getting the basic machinery working. Tweaking the optimizer, tweaking, learning rates, all this kind of stuff. Are you still involved in that kind of work? Do you think that's accelerating as more people are coming in or slowing down as we've gotten the basic machinery working?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:10:20] Oriol Vinyals: Yeah, it's a good question. Going to all the modalities, right? The ultimate modality, if you extrapolate is well, all the data is just a sequence of bytes, right? You can always represent any data structure, input or output, as a sequence of bytes. That is a very romantic almost, way to think about machine learning--\\n\\n[00:10:44] Sam Charrington: A grand unified theory of deep learning or something?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='[00:10:47] Oriol Vinyals: Yeah. Yeah, exactly. So in that sense, what has happened is that sequence models have evolved enough that we have transformers, which might not be the last iteration over the ultimate model that will rule all the modalities with applying the same model, the same formula to the toolbox. Maybe just reduced to this one model.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"We're not quite there yet but that is one way to see it. Indeed as the field is advancing, I think the details are refined enough that more people can just access these toolbox without being maybe necessarily an expert, and see successes reasonably in a reasonable, simple way.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Obviously this goes hand in hand with the fact that our software has also tremendously advanced with all the frameworks that exist currently and open source and et cetera, that exists to lower the barrier of entry to the field. But I would say that, yes, it's easier to get the details, more so than it was three years ago although I think there's still quite a lot of research to be done indeed.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:12:01] Sam Charrington: Sure. Sure. So when you think... it's just hinging off of this point that you made around sequences and transformers and how we're almost there. Do you have a a feeling or a bet on... Do we get there? Is transformers the thing that gets us there? Is it something that's a slight evolution of transformers? What dimensions do you think get us there if you think we get there?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='[00:12:44] Oriol Vinyals: Yeah, I think transformers have evolved in a very natural, cool way from obviously what has come before transformers, LSTMs, attention mechanisms, et cetera. But indeed, there are also a lot of limitations.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"There's a very computational sort of framing of machine learning, which is to say well, we want to map any modality to any modality. Our model needs to not make many assumptions over the underlying data. So it cannot adapt to all the tasks that we might be interested in tackling.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"I think transformers do quite well here. An obvious challenge that if you look at the property, the amount of papers tackling these, there's probably going to be a few is the fact that transformers is still requires... It's very symmetric in the way that it looks at all the data if you think of language modeling, for example. It just looks at every single piece of text. When you're reading a book, that's not how you're ingesting this information as you read chapter after chapter. So there's some\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"So there's some beautiful work, I think, still to be done in the memory mechanism, being a bit more hierarchical.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Maybe that's losing inspiration from how we think we work in terms of ingesting information and, compressing the information we ingest. We don't remember every single detail. That being--\\n\\n[00:14:08] Sam Charrington: Shaping the way...\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='[00:14:09] Oriol Vinyals: --might not necessarily need to operate like we do. So it is possible that, \"Okay, we cannot do that,\" but while the machines can do it so maybe that is fine. But I think computation there are definite challenges that may make transformers have definitely some limits on the amount of information they can process effectively in parallel as they ingest the sequences of information or fact.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:14:36] Sam Charrington: It sounds like you're suggesting a higher level attention mechanism that more broadly shapes the way that the transformers learning from the data that it's presented.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:14:52] Oriol Vinyals: Yeah. These exist. It's just that, that needs the matter of what details, how the optimization can be made to work. But I think indeed some more forms of hierarchical memory from course to find lots of these ideas existed in computer vision for years as well so I think there's going to be a good mix of ideas and iterative processes until maybe the next model that feels maybe more efficient for other tasks. We might not even be thinking about that. That's what I was\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"That's what I was saying. You push the envelope. So usually it goes hand in hand with a new task that we cannot even dream of doing right now because yeah, the limitations of the state of the art models.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"But I think hierarchy in memories, one of my bets, definitely some work we've done and we made the whole research community is doing that, I think I'm definitely keeping an eye on.\\n\\n[00:15:51] Sam Charrington: Also related to transformers and the impact that we've seen there. Is the work specifically happening around large language models? What kind of work are you doing there?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:16:10] Oriol Vinyals: Yeah. large language models is a very fascinating field that you could think there's been a huge paradigm shift or maybe there's been none, depending on how far you go back in the past. You know, if you look even in the fifties, Shannon, was already intrigued by the fact that if you have statistical pieces of texts, you could actually generate text from Ingram models. Then, you have to go forward to maybe the neural language model error until we start to scaling this\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"to scaling this app with the data and the models and GPUs, et cetera to start unlocking in depth state of the art machine translation, which already feels a bit magical because in machine translation, we're asking the model to translate sentences that definitely have not been in the training set. As we know most of the sentences were either they're probably unique, otherwise we would not be talking to one another because we could always predict what is Sam going to say, what is Oriol going to\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='is Oriol going to say say but thanks to this mix of components.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='I think the last definitely 10 years, last five years, and then transformers as being the last maybe ingredient that has been added to this mix toolbox bill that I was mentioning.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='We\\'ve gotten to two language models. Yeah, we can sample from, and we can query, but it starts to feel like, \"Oh, if we were talking to someone right behind the scenes, like going back to opposite touring and touring test ideas. Although maybe that is not that useful these days. But just thinking like that, you have this pre-trained language model that you can start treating an entity that can obviously alter any text, and that\\'s powerful if it\\'s good enough. I think that\\'s what changed. We were', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='changed. We were doing this all along. I would argue in NLP for many years.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Many people have obviously tried to model language. So the basic principle exists. You could always query the model to ask you the question and see how it reacts. Does it know about color of the sky, et cetera, but recently, thanks to scale there's what is true is that the performance has been so good. Like the change from the millions to billions of parameters has triggered like now, okay.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"A new dream almost of what else could we do if we get scaling on the one side. Also look, it's unbelievable that this, that felt like maybe at that end or sure, we could use language models in a more complex system that was doing the traditional chatbot building with rules and so on. Now these actually feels it's in a state that for some applications and with lots of caveats actually can actually be used and feels like a very powerful tool. Indeed, I mean openly, I've been probably the one that\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='the one that has pioneered this more notably has shown some demonstrations. So at DeepMind, we are definitely looking into this.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"I mean the space of large language models is extremely exciting. Actually if you look a bit at the history and perhaps things like you see in projects such as the one I was involved with, which is StarCraft, the way I always thought about StarCraft coming from where I come from is that it's just modeling sequences of words. These words are not like English words.They're instructions that you send to the game engine, like move this piece here. It's a very rich language. It's an API-like language\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='an API-like language but you could already start seeing the power of these methods beyond language to decision-making and agents.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"I think there's a lot of interesting parallels that we are already witnessing, maybe like human level, go actually the very first steps enough ago, where indeed as well, similar to precise modeling of the probability of the next word in go. The next word is just a two dimensional, like position of where you would the next piece, but in general, these principle has been there since ever. All that it took is for the performance to be at the level of, wow, you can really play a game or reply to\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='a game or reply to almost anything you can ask these models. You will get somewhat sensible replies sometimes enough that these speaks now the interest of many more and the field is indeed expanding a lot, which is super welcome.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:20:59] Sam Charrington: So you mentioned StarCraft once again, and you've got a workshop paper at NeurIPS that is a follow-up to the AlphaStar work. That was maybe 2019, the alpha Can you maybe give us a refresher on that work and then talk about what you are presenting at NeurIPS this year?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:21:26] Oriol Vinyals: Sure. Yeah, I think DeepMind as a company obviously had its own different stages where the very early beginnings on Atari, just showing that deep reinforcement learning is now has to prove itself. It's a bit like deep learning but now a bit more specific.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='So a way to prove itself is actually indeed to master ever more complicated domains or environments as we call them in reinforcement learning. Instead of being datasets you are optimizing a reward, but ultimately actually a lot of the deep learning kind of main components or ideas apply. So you saw these one at a time, right? Almost as a curriculum of increasingly, domains like from Atari to go and chairs, and then ultimately I would say StarCraft being much more complex in many different', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"in many different dimensions as a game or a video game. That's what we were doing at DeepMind and maybe the AlphaStar project that regarded StarCraft two, which is a popular real-time strategy game was the end of that sort of sequence of demonstrations of these deeper route principles really apply to all the domains that we have found interesting in the sense of games that are complex. They require like a synchronous thinking, partial observability. All the right interesting properties that\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='properties that maybe the same way Computer Vision went from [amnesia], which was very interesting until it became soft and then we moved over. So this is a parallel. I like to visualize almost in this complexity versus the kind of game that deep RL was tackling and alpha star essentially did this through an approach that was not purely deep reinforcement learning. It actually employed imitation learning or offline reinforcement learning.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Thanks to the massive amount of games that when humans play one another, I recorded it anonymously by the company that makes the game. So there's a huge wealth of sequences of observations and actions that, as I said, you could see as a bit of a language just that expresses moves in the game, right?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"That was the first seed of AlphaStar. How we reach Grandmaster level at the game was let's take a look at these sequences that we have at scale. There's actually millions of sequences. So we have a lot of data, which is great in deep learning. The more data, the better.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Then we learned to imitate, which essentially is applying the same principles as language modeling. So given all the words that we've seen until some point, we'll try to predict the next word or in the case of StarCraft, we were trying to predict the next move, which is just a complex object, move this unit on to this position in the map.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"But it's actually very similar to modeling language. That first agent was reasonably good. It was actually better than most humans in terms of the median performance, but then we took it to the next level by then initializing a self play system, a multi-agent system, in fact, of many agents that developed different skills and different strategies in the game.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"They played each other for many years, actually. There's like each agent plays a StarCraft over 50 years or so. That's what we did in the nature paper. That achieves from this median level or above median level to really the top, the very top, top level of play that then we verified. We probably, as you said, in the end in the endtail of 2019,\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='So that was very cool. Obviously our goal was, can we just really crack this game? So we took this kind of hybrid approach of initializing the model to imitate humans, and then taking off by just doing self play. In a way he may take how humans have discovered the game by playing online against each other.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Recently we were both motivated by first actually trying both StarCraft or imitating human moves as a challenge for those who study offline around which is this area of reinforcement learning where you're not allowed to interact with the environment. You can observe agents or people interacting with environments but you're not allowed because maybe it's not practical to perhaps go there and plot your agent in the environment, and try to see if you get a reward. So that's a fascinating area.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='What we thought is, \"Look, we have one of the richest offline around datasets, right? Millions of trajectories from humans of all levels playing the game. Would it be great to first try to open these as a challenge for the community?\"', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"So one thing we're working very hard these days actually is to finalizing open sourcing. So anyone can just go download the code and just train their own agent based on these imitation principle only. So we are only looking at the very first beginning of the whole AlphaStar agent.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='But at the same time we were wondering, \"Look, can we push the performance of disease?\" We didn\\'t care to do it at the time because we knew that multi-agent and self play and reinforcement learning were going to be successful at making the agent better. But could we do that only imitating human moves? That is almost the same.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"If you think of language modeling that you're only imitating next word prediction, you never training these models further, but by themselves are quite good. The answer is you can push performance. We definitely beaten like the agent that we published. The initial agent that was learned to imitate with some further refinements, we use music. There's details in the paper that folks go and read, but with some ideas, very key ideas using further than just imitating the next move.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='So we from the offline Earl community were able to beat that first AlphaStar. That was very good and see that, of course, what yielded the nature of publication performance by, I think over 90% of the time, right? So there is performance to be a lot, and this is only the beginning. We tried a few ideas but I think this is a very fruitful resource for those who are interested in this field of line reinforcement.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"To make it maybe go and tackle this challenge and hopefully with the source code available. Just the fact that it's such a fun game to observe and a cool domain, people might go and obviously then take it on and try to get to a next level of performance just with imitating human moves, which is fascinating to me at least.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='[00:28:16] Sam Charrington: Do you think of at least in this context offline. Setting and imitation as synonymous. It seems like they largely are, but that you could also envision other types of processing of the dataset that has some benefit beyond just the imitation itself.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:28:38] Oriol Vinyals: Yeah. So I think, there's a lot of names. People call the supervised learning behavioral cloning, imitation. I think what's powerful about, if you restrict yourself to, I will not interact with the environment, but I am able to see what agents interacting with the environment achieved.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"I think that the powerful and what offline RL really poses is imitation is one part, right? So imitating the actual very well is what language modeling regards with. It's very important, but there is also the reward that we observe in a game like soccer, like who won the game and you can also predict the winner right offline.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='You can say, \"Look, we have this game, two players playing. We have every single action they took. Let\\'s try to imitate that, to understand that very well, like we understand language.\" But also there is a fact that one of them, and if we can model that precisely with a value of function, which is obviously a crucial element of most RL, then we can even in an offline setting, try to find an action that is not just human leg but maximizes the probability, according to our own estimate of the', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='own estimate of the value and maximizes the probability of winning.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"In fact, one of the best performing agents we showed uses music. It's offline. We never use self play but music basically tries to model based on simulating actions that you might take in the future and then pick those that maximize reward or value, but according to your own estimates, right? That extra step we didn't take at the time. But many people flying around obviously are studying not only actions but also estimating the reward or by. We found that already enabled these level of\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"these level of performance that we didn't unlock at the time we were doing the project, but I'm sure there is more on how you train the model. How do you train the actions? How, what the losses are.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"There's a lot of toolbox actually components to be discovered perhaps, and the usage of benchmarks is critical to advancing this. So there are quite a few benchmarks in offline around already. I think StarCraft poses an interesting one, given its complexity in action space and the fact that it's special observable and some properties that make these a unique environment, like many of.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='[00:31:02] Sam Charrington: To what degree are you seeing the learnings from the work that DeepMind and others are doing around games translate to real world non-game scenarios?', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:31:18] Oriol Vinyals: Yeah, that's a great question because I think we're seeing quite a lot. For instance, actually like thinking of AlphaStar and then Alpha Fault. A lot of the work we did in AlphaStar, early days. Transformers just had come up. So we started investing or seeing maybe good performance with transport.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='Maybe the first project that we saw that was AlphaStar actually, and then transformers and self attention, and some further tools that were developed specifically thinking about the protein folding problem were developed. There\\'s losing inspiration right by the fact that, \"Hey, we know that there\\'s this group that found this model, that a different research group.\"', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"That's the great part of research is you take learnings from not only your own company, but of course, any other research institutions. Loosely speaking, you can find always these connections that from one project learnings, then it goes to others and so on from games and reinforcement learning. Actually I see a shift now. With many great examples of just applying the same Earl techniques to other places, there's some that we are applying in language, right? Machine translation, for example,\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"for example, it's difficult. Like we have a few works. I'm not sure that they're quite there in terms of breaking the state of, but certainly there, because you have these, again, going back to maybe the beginning of the conversation, these deep learning approach that the tools must be generic, then anything you discover in any specific domain because you tried not to be very domain specific, then they will not really translate to other domains ideas.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Perhaps one of the things that in StarCraft, maybe it's a very simple idea, but I think this one has a lot of potential when you mix these idea of imitating humans with reinforcement learning refinement is that we added distillation loss, which is a pressure of the RL model to actually look still, even if it wants to change the actions because reinforcement learning is a different law and it's doing different things.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"You make some pressure for the model to imitate a little bit the policy that it started from that imitates humans and that was critical there. In fact, in a lot of now language model applications, for instance, these principle, I see it sprinkled around because it's quite natural to not want the model to divert.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"This comes from obviously all the other work on model, distillation, knowledge, distillation, et cetera. So it's, as I said, there's always these tools that you purpose for some particular reason initially but the consequences or the applications later on along the line, it's going to be, they're going to be unprecedented.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Transformers is a great example of having been developed for machine translation. Now, suddenly they're folding proteins. Even the authors of these papers, it's just sometimes hard to believe probably. How is this happening? It's a bit random and you need a bit of lag and the right titles in the papers.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"There's a lot of interesting actually randomness in the field, which makes NeurIPS such an interesting conference actually, and all the other conferences in ML. But yeah it's cool to think that these are basically [Indian] tools that we want to apply generally anywhere. Many times we see these successes transfer over very surprising areas that even the original inventors did not anticipate.\\n\\n[00:35:02] Sam Charrington: Okay. Nice. Nice.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"One of the historical challenges with reinforcement learning, deep reinforcement learning in particular, is the sample inefficiency that gives rise to topics like few shot, or is related to topics like few shot and one shot learning. You've got a poster at NeurIPS that is looking at a multimodal few shot learning with language models. Is that [NRL] context or...\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:35:34] Oriol Vinyals: It's not in the real context but it is definitely in the imitation learning context. Then it's proposing a way to try to leverage a large amount of data and a big language model that we trained only on language. But can this language model with a little bit of extra training be then tuned to be able to talk about images that it takes us its inputs.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='I mean, this is fascinating because it links to fusion learning which is an area that actually has one of the very first works I did when I joined DeepMind. There was all these meta-learning papers coming from the groups and I was very impressed. So one of the words we did was working on fusion learning.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"What happened with the work is that we proposed a new method that I think it's reasonably simple but actually the benchmark proposing that paper is what made this paper maybe widely known for the benchmark it proposed, which is called mini-ImageNet, and mini-ImagineNet is the task of fusion learning where you just have a few images from one class you've never trained. The goal is to classify it better at that chance. There's been a lot of work following up nicely defined, clear benchmark for the\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='benchmark for the community. The cool thing here is that without even training at all to do mini-ImageNet or fusion learning for images, these language models, just through imitating just generic knowledge that is found on the internet about people talking to one another and so on. With a little bit of fine tuning to understand correlations between images and language, namely image captioning is what we pre-trained these models with, but by freezing the language component, you can then reuse', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='you can then reuse this model to not only do image captioning but also...', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Mini-ImagineNet was one of the tasks that we present in the paper. It's impressive that it's not only doing fusion learning better than chance but it's never trained with the purpose of doing fusion learning. You're in a way borrowing the capabilities of fusion learning from the language modeling, and then with a little bit of vision mixing, you're able to do a few short tasks that you are not even thinking when you are designing the training setting unlike what you were doing at the time we\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='doing at the time we were doing at the time with fusion learning for image classification, where we were training the models to do fusion learning for image classification, and then they were good at that.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"But now it's like almost you don't train them to do this particular task, but they actually generalize over different tasks that involve language and vision in different degrees, of course of accuracy. Not very high but this is actually a lot of work that I see in the vision and language intersection is going this direction.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"It's quite exciting to see all the amazing work that appears as well at NeurIPS and computer vision conferences alike. But it doesn't have RL, although you could always use RL to fine tune the models further but in general that has not been adopted yet too much, I guess, in these communities.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:38:45] Sam Charrington: We spoke earlier about transformers as this innovation frontier, for lack of a better term, and where a lot of the activity is in the toolkit, and this poster is an example of transformers, plus transformers trained with language and in parallel, there's this broader conversation about foundational models and the community. What's your take on that?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Do you think that language is going to provide this substrate that will be able to do a lot of non-language things with, and that's going to be a broadly applied tool in the toolbox?\\n\\n[00:39:35] Oriol Vinyals: Yeah. I honestly think looking at what's been going on and even taking some inspiration from not only transformers, but also ideas around unsupervised learning, self supervised learning, another big area that that's been exploding lately. It does feel that.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='[00:39:55] Sam Charrington: Yeah.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:39:55] Oriol Vinyals: Again, going back to the very beginning of deep learning, you have this principle, right? Like the traditional deep learning. Maybe let's see what the next generation deep learning could look like, but the traditional one is this. As I said, you take the data set of inputs, outputs, and you have these toolbox, you mix and match components. Then off you go, you train your model. It does reasonably well at many tasks but this is quite unsatisfied, right? If you ask many\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"If you ask many of those who have been in the field for a long time, and obviously the ones that are not probably also find it annoying. The annoying bit, the weights are randomly initialized, which is beautiful in a way, but it's also like quite annoying.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"This is very wasteful, right? We're starting to train from scratch, and we're throwing away a lot of energy use to train, find ways that we had for different tasks that somewhat related. So this way to usability, I think it's what these foundational models and these way of thinking is getting at, which is look not only we want to take tools, we might want to take the tools with the weights associated with that, which poses a very interesting challenge of can we initialize parts of the network\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"parts of the network with maybe a language modeling component but practice. Sadly this is at the frontier. It's still not very clear that we found a way to use this idea of pre-trained weights in a successful way, meaning that we start from the pre-trained weights rather than random weights, and we achieve better performance. Although more acception system appear in the field, such as the one from self supervised learning in which you train features that look at image statistics that seem\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='statistics that seem superfluous maybe initially, but these features happen to be quite good at classifying or doing all sorts of image tasks if you use them as pre-trained weights.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"But I do believe that this probably has to be part of an answer for the next generation deep learning that not only reuses the tools, but reuses the weights, but it is extremely tricky. Again, the field has been looking at this problem, not definitely before deep learning was deep learning. But it is very natural to think about that. Also again, maybe looking a bit at how we learn, we don't always like start from a fresh brain when we learn something new. There's always an accumulation of\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"an accumulation of learning capabilities. That feels like a big gap in the way we do deep learning despite the fact that you train these networks from scratch and they are good at protein folding or translation and the components are the same, but the weights it's not.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"That I think, I believe this will be as we do research and find ways to make these weights useful and beating the performance without training from scratch, et cetera. I believe this is definitely a way forward. It's exciting because we tried. Definitely we tried many, many things and it's hard, it's not easy, it feels intuitive. It's one of these things that neural nets don't seem to want to do too well without a lot of effort. So there must be a way. Finding it is definitely in the future. I'm\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"in the future. I'm sure many people are excited about this.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:43:23] Sam Charrington: Yeah. Oriol, I want to as a side, ask one how we're doing on time or how you are on time?\\n\\n[00:43:32] Oriol Vinyals: I'm fine.\\n\\n[00:43:33] Sam Charrington: Okay. Then two, we talked about talking about the panel, the consequences of scaling. Scaling came up earlier. Have we covered...?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:43:45] Oriol Vinyals: I think, yeah, I think we can skip the panel, we actually recorded it, so I know what is in the panel. It's a bit about what, are there good research questions about scaling, and then there's obviously some challenges. I think the interesting bit is how do you make these models accessible? But they're obviously like some harms and so on associated with them, but maybe, yeah, otherwise it might be too long. I think it's great to have a bit of extra discussion, maybe on\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"discussion, maybe on more deep learning background. I think that's been great. I love that topic as you can probably see, so maybe we can skip it otherwise, I don't know. If we were aiming at one hour each, then it might be too much.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:44:30] Sam Charrington: Yeah, I haven't got the time and I think we're good with time for the recording. I've got to finish within 15 minutes. I don't think new and ML will take that long. If it was another topic you want to bring up, we can do that or it doesn't sound like there's a lot of overlap on these consequences of massive scaling with the previous conversation.\\n\\n[00:44:54] Oriol Vinyals: Not too much. No.\\n\\n[00:44:55] Sam Charrington: Not necessarily.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:44:56] Oriol Vinyals: No. Yeah.\\n\\n[00:44:58] Sam Charrington: So you want to stick with that?\\n\\n[00:44:59] Oriol Vinyals: Yeah. I think we stick with that. That's fine.\\n\\n[00:45:01] Sam Charrington: Okay. All right. Great.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"So another thing I wanted to ask about is a panel that you're going to be on also at NeurIPS that is talking about a topic that somewhat related to what we've talked about thus far. But as specifically focused on the consequences of the level of scale that we've achieved, and the way we're approaching machine learning with transformers is requiring. Tell us a little bit about that panel and some of the questions that it is exploring.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:45:39] Oriol Vinyals: Yeah. I think the panel and the question about scale, there's a more profound question which links to actually in the whole field or what makes research good or interesting? I find that is a fascinating evolving topic, right? Definitely. I actually recalled, one of my, I think my very first NeurIPS paper has a theorem and a proof because at the time, you had to put a theorem and a proof in a NeurIPS paper for it to be accepted. That's what you had to do.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"The paper actually talks a bit about actually deep learning with SBMs, which was a very obviously popular model at the time, super vector machines, but the question and I think a challenge is scale is definitely permeating into research. There is, I think, one of the main aspects that will be discussed in the panel is the fact that many research works or papers might be required or asked naturally by reviewers. A, can you try this idea at scale? If you look at reviews, there's many reviews that\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"many reviews that actually public. I really applaud the user systems like open review that has a more transparent way to show how the review process work. It's quite great for people that are new in machine learning perhaps the most, but you often see that does this model scale or not?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"You know, is that a fair question to ask? Should we always aim to scale up our methods as we show results at the conference like NeurIPS. I think the answer is, absolutely not, but the question is if a paper claims to have discovered a new tool or a new advance on an existing tool, the real question perhaps, and that's where it gets maybe a bit tricky is in which data sets or in which benchmarks are you trying this idea on? I think what the community has evolved to words is that let's say in\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"is that let's say in computer vision, if you don't show something works on ImageNet, it's probably a bit inconclusive based on, let's say other very popular data sets that are smaller and does a bit easier to run on like CFAR or [MAMIS]. There's still a lot of good work and insights discovered on those datasets but it is natural that you scale up these experiments to ImageNet. Otherwise, the field is full.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Like it's very big right now. There's another big changes that there are lots of good papers, very well written, and there is a bit challenging signal to noise ratio to understand or slice out what is a meaningful contribution or what needs more work in terms of showing empirically that some method works and here scale plays a big role.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"I think the role is that it's fair to say maybe to run on ImageNet certain models, and then very interesting follow-up question is can everyone in the world scale of dataset, right? Imagine that is not perhaps the most large one, if you think it be tough hardware and we can train ImageNet.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"So there's some results that can train ImageNet in 10 seconds, of course, using a lot of parallelism. So it feels like in this sense it's more accessible. The real question, is it truly accessible? That creates, I think, a challenge and part of the battle, discussing about accessibility to scale and is research at scale, the only, or is there interesting research at scale?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='I think the answer is yes, but is the only research we should look for at scale? I think absolutely not. One very beautiful example that I can think of, again related to transformers, is that at the time we were working on machine translation, at Google we had this sequence to sequence paper in which we use an 8,000 dimensional long, like LSTM, basically to do machine translation.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"We achieved almost a state of the art numbers with a technique that was completely different than what people had been doing at the time, which got, I guess, people's attention. It was perfected further and most of, if not all the machine translation systems nowadays, run with some sort of neural network underneath, but [Montreal] had less GPUs.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"It's not that we use a lot of GPUs. We use 8 GPUs for 20 days. So it was a painful experiment to run. You had to wait 20 days and it's 8 GPUs, they all fit in one machine. But of course it's reasonably large-scale, but I think [Montreal] took a different approach. Instead of scaling up to 8,000 layer, 8,000 units, they only could use 1,000 because maybe they run it on a single GPU.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"But what they did, which was, I think that's maybe the most transformative thing, no pun intended, is to invent attention. So the attention paper, maybe perhaps, because the scale was not as available to a group in [Montreal] as it was for us at Google. I think this is just a lesson that we need to learn that sometimes by just being resource constrained, very good research has happened.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"I mean, I'm not saying that then please be happy and never try to scale up. It's not like that, but indeed, there are examples and it should inspire creativity and different way of thinking, which ultimately might create a balance shift and absolutely as a community, we need to be very careful of course, at discarding ideas because they don't scale.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='It would obviously have been a mistake to discard that idea that created attention, which of course followed up with self attention transformers and who knows what comes next. But that attention principle maybe was the key tool that we keep seeing being quite useful. It was invented by a lack of scaling up to achieve better results. They had to invent this very intuitive attention mechanism, which for translation made a lot of sense. You look at the sentence and you attend over the words that', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='over the words that look like, \"Oh yeah, I\\'m going to translate this word.\" That beautiful principle now is folding proteins. It\\'s like unbelievable.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"But it is what it is. Yeah. So that's one aspect in the panel. I think maybe another big challenging question I think is I don't think we have many answers. Although there were some interesting parallels with different fields like for instance, the large collider that exists at CERN, the question about... companies obviously have access to resources like compute, and I think it is our duty to do the best we can in terms of research publishing and scaling up as responsibly as we can.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='But the real question is, how can you make that kind of research available to more people? You know, a very interesting thought is who should invest on maybe building a computer for academic research? CERN is a very interesting example because the Physics community came together and decided, \"We need to build this device. It\\'s very expensive. It actually uses a lot of energy. it\\'s a quite an interesting place to be.\" Actually, I was very lucky to be there very recently in a bizarre, real world', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='bizarre, real world experience that I had during the pandemic. But that is an interesting model and there are challenges.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='It\\'s not like, \"Oh, we should just build a super computer like CERN and, just have people access it in the same way that you do access CERN by writing grants.\" It\\'s a very interesting system actually but the problem there is that happened with a lot of consensus that physics is, for many years, like they said, \"Oh, we need to test these things and to do them, we will need this device.\"', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Another question we were discussing in the panel is, of course, it might be too early. Scaling up is something that, it has happened in machine learning actually forever. It's not new. When you look at the history of datasets, there's a scaling up of course of everything, thanks to more laws and so on, but the question is, do we feel enough that investing, let's say public money from different governments that maybe could form a coalition similar to CERN?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Is that the right moment to do it? Do we know that's the way to go? That's a good question. My answer to that is scaling up will be part of the solution, but it's not the solution in terms of building intelligence. I think it's unconceivable to me that we need to scale up just because of the sheer amount of learning at the planetary species level that happened.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"If you think of the amount of parallelism years, et cetera, that it got us to be intelligent beings. so does the existence proof tells me that scaling probably will be part of the solution, but it's not the only thing that will be required. So anyways, the panel, no more spoilers that they touch on all these very interesting questions.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='A lot of them of course are inspired indeed by what we were discussing before on scaling up language models and their foundational model capabilities that they seem to exhibit them. You know, if that is true, when is the time to think very carefully about how to get access to the community.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Similar to the hardware that was being made accessible with CERN or another example is obviously the Hubble telescope. Huge endeavors to build those things. So yeah, very interesting questions. I don't know if you have any thoughts or any solutions to these either. What do you think?\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:55:49] Sam Charrington: You know, what occurred to me was when you talked about kind of humans as the existence proof of the requirement for scale, it prompted me to think about, I think we've demonstrated that. scale is required to advance knowledge, but it's not clear that that's the same as advancing intelligence.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"You know, certainly, there's a degree to knowledge that becomes common knowledge, and we take for granted but yeah, it's not obvious the impact of our scale as a species on our intelligence per se. I guess you could argue that our scale as a species has facilitated... For example, nutrition. We've industrialized farming and we become stronger and that's made our brains bigger, and that has advanced intelligence significantly. But I'm not sure that's the same kind of scale argument.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content='[00:57:07] Oriol Vinyals: Yeah, I really liked by the way your knowledge. I think, definitely from a knowledge standpoint I mean, we store all the knowledge in different formats, right? Like over time. Without which, things would be much harder. So even in that sense, accessing all the knowledge and learning how to access that feels like a natural thing.', metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"We need to investigate from a machine learning standpoint, and what maybe, these language models are getting at the very first stages of they have the knowledge in an imperfect way, et cetera, but they have the knowledge that exists in a particular corpus. But then yeah, from there to intelligence, I agree. That's why I'm saying, I think it's part of the puzzle, but definitely not the whole puzzle.\\n\\n[00:58:01] Sam Charrington: Yeah. Awesome. Awesome.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"Well, Oriol, it has been wonderful catching up chatting a little bit about all the things you're working on, particularly with regard to NeurIPS. You are also involved in a new to machine learning panel. We're not going to have a chance to talk about that, but for those who are new to the field, I encourage you to seek out that panel. I'm sure there'll be lots of interesting tidbits to learn from there.\\n\\nThanks so much, Oriol, for taking the time to chat.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:58:33] Oriol Vinyals: Excellent. Sam, it's been a pleasure long overdue and looking forward to be back in a few years. We'll see if we change the discussion topics or it will be like about the same line of thinking about scaling up and so on, but the field is fascinating. So looking forward to our next chat.\\n\\n[00:58:50] Sam Charrington: Absolutely. Thanks so much.\\n\\n[00:58:52] Oriol Vinyals: Thank you.\", metadata={'source': 'content/data/545 - Oriol Vinyals.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: All right, everyone. I am on the line with Yejin Choi. Yejin is a Professor at the University of Washington. Yejin, welcome to the TWIML AI Podcast.\\n\\n[00:00:22] Yejin Choi: I'm excited to be here. Thanks for having me.\\n\\n[00:00:25] Sam Charrington: I'm really looking forward to digging into our conversation. I'd love to have you start by sharing a little bit about your background and how you came to work in the field of AI.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:00:35] Yejin Choi: Right. So I primarily work in the area of natural language processing but like any other [sub] fields of AI, now the boundaries become looser and looser and I'm excited to work on the boundaries between language and vision, language and perception, and also thinking a lot about the connection between AI and the human intelligence, and what are the fundamental differences in that in terms of knowledge and [reasoning].\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:01:07] Sam Charrington: So let's go a little bit deeper into that [Tala]. Talk us through some of the ways that you take on those topics and your research portfolio. What are some of the main projects you're working on and the things that you're exploring.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:01:24] Yejin Choi: Right. So currently I'm the most excited about the notion of a common sense knowledge and reasoning. This was in fact the only dream of AI field in seventies and eighties. People love to think about it and try to develop formalism for it. It turns out it's really trivial for humans but really difficult even for the smartest, the people to really think about how to define it formally so that machines can execute it as a program.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So for a long time, scientists assumed that it's doomed the direction because it's just too hard. So AI didn't really thought about common sense for a long time. Then it's only in recent years some of us got excited to think about it again, which is in part powered by the recent advancements of newer models that is able to understand large amount of data.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:02:30] Sam Charrington: You talked a little bit about the difficulty of or you referenced the difficulty of defining common sense reasoning. How do you define it?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:02:39] Yejin Choi: Right. So I take a broader definition such that it's everyday knowledge, practical knowledge that most people share in order to function safely and reasonably in our everyday life. So for example, in general, it's okay to keep your closet door open for a while, but not as okay to keep your freezer door open for a while. But of course I can add the additional context to make this inference defeasible. So if the refrigerator is new unplugged from the wall, there's nothing\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"there's nothing inside then who cares.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So, and again, the closet, if there are rats around, you may want to close the door. So it's almost like rules of thumb that we live by but the hardness of it is that it's very contextual and depending on your cultural backgrounds and everything, the judgments could change. Yet it seems that there are this common ground that a lot of people agree with. So that's my working definition of common sense.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:04:00] Sam Charrington: Okay. You described it as rules of thumb. How important is the notion of rules in that? I'm thinking about that relative to, we spend a lot of time thinking about deep learning and deep neural networks. In some ways they're may be more pattern-based than rule-based. Is there a notion of fundamental foundational patterns as being akin to common sense, like the low layers of our neural network learning textures and things like that. Does that kind of common sense in a\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='of common sense in a sense?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:04:40] Yejin Choi: Yeah, absolutely. That's a really sharp question. I appreciate the question. In fact, when I say rules, I use the word very differently from how more formal approaches in AI mean by rules. Just so what I mean by rules is really through language. I can describe my rules through language but you can immediately imagine that these rules are just natural language rules. So there's always a different interpretation you could do. These are just generally true statement but they\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='statement but they may or may not be true. It also includes just declarative knowledge about, for example, skies. Usually, on top of my head.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"It might change depending on my location, of course. Usually it's blue unless it's red in the evening. So we have a lot of this knowledge about... I would be surprised if the sky was suddenly pink because that's less expected.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So there's this expectation about how the physical world works, how the social world works and a lot of these is what, as a human, we just have this memory of how the world works but machines today, not as much. If you ask a GPT-3, for example, how many eyes a horse, it might say three, primarily because people usually don't talk about how many eyes a horse have when they see a horse or ride a horse, they never mention it. It's too obvious. Yeah. So yeah, it's very elusive. In my work, it's all\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"In my work, it's all in natural language or in large part it's in natural language except when I'm grounding it with vision.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:06:37] Sam Charrington: So how would you articulate the kind of current state of the world or research frontier in terms of common sense reasoning? How far along are we?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:06:54] Yejin Choi: Yeah. It's a bit of a moonshot research, I should mention still, but I think we're seeing the most exciting results, I would dare say than ever before, because in my group we have some research demo running online. It's a model called the COMET, it means common sense transformers built on top of a transformer neuro language [models], and it's able to make common sense inferences about random situations that we might encounter in lives. What's fascinating about that system\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"about that system is that it has learned from symbolic knowledge graph of some common sense rules. Not all because there's no way we can enumerate them all, and I don't think humans actually really learn different enumerated rules but what's exciting about current neuro language models is that they can generalize out of that symbolic knowledge graph so that it can reason about new events that was never taught directly before. Oftentimes that reasoning is very surprisingly good. It's not perfect\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"It's not perfect yet but it's a running system that demonstrates the new capability that we've never seen before.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:08:12] Sam Charrington: Okay, can you give us a concrete example of the specific task and the kinds of results you're seeing?\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:08:19] Yejin Choi: Sure. It\\'s actually best to describe the three examples. So if somebody is repelling somebody\\'s attack, it\\'s not very contextualized event, I may say person X repels person Y\\'s attack. Usually we might think, \"Oh, X might be strong person to fight back \\'cause I might just run away,\" and maybe why did this something wrong? Probably Y attacked beforehand so we can reason about preconditions post the conditions and causes and effects of their motivations and their mental', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='and their mental state. Probably X is unhappy about the situation.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"If X successfully repelled Y's attack, Y might either attack back or runaway. Unlikely that suddenly Y brings a gift and suddenly celebrate, right? So there are uncertainties about the causes and effects and what might happen before and after, however, we have reasonable expectation about what are the likely things to happen.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So this particular event was in our symbolic knowledge graph but what's not in the graph that somebody gave me as an adversarial problem to challenge my model was what if somebody repelled someone's attack in a chess game. Now that's a very different situation where it's not about a fist to fight situation anymore. It's really intellectual fight, and our model was able to somehow make an analogy between the two various different situations. Now the model inference is all about having maybe chess\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='having maybe chess game beforehand. Maybe the person is very intelligent, a smart, clever person, and things like that so the generalization here is quite exciting.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:10:17] Sam Charrington: So in this example, you mentioned that something was in your knowledge graph. What specifically is in the knowledge?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:10:29] Yejin Choi: So given any [center] event, like a person, X, repels a person Y's attack. In our original atomic knowledge graph, we had the nine different inference types which is generally about people's mental states, so before and after. What they might want to do before and after preconditions and post conditions and things like that. In our later atomic knowledge graphs, we expanded that to include 24 different inference types. In the original version, it was very human centric\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"very human centric activities that we had as a knowledge graph but now we always include object centric knowledge as well as event centric knowledge as well, so that's what's in the graph and the graph has at the moment, 1.3 million, [if-then rules] in natural language. So if this happens, then something else might be true, likely to be true.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:11:31] Sam Charrington: Are the if-then relationships, are the conditions, the if conditions and the eventual outcomes represented? Is that an atomic unit within this graph or you have a bunch of conditions and a bunch of outcomes and the graph links those?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:11:55] Yejin Choi: Yeah, that's a great question. They are all open free texts, short, natural language phrases. They're stored as if they're in a graph structure, but in fact, we're going with natural language as much as possible. There's no logical forms or anything.\\n\\n[00:12:16] Sam Charrington: Okay. Okay. Interesting. Interesting.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"In hearing you describe this scenario and the example, I couldn't help but think about a relationship between this common sense reasoning task, and in a sense like storytelling, creative storytelling, like you pose this scenario and then you're like what if this happened and maybe this happened and this happened, and this happened and all the things that we might expect an author to do to build a story. Is that something that you explore at all? What do you think about that relationship?\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:12:55] Yejin Choi: Absolutely. Yeah, I'm amazed by your question. So, in fact, counterfactual reasoning, what if something else happened? That's really essential part of our reasoning capabilities, and when I think of a human reasoning, it's really fascinating because we can also do a lot of the times what I call, what researchers call abductive reasoning that was originally proposed to [inaudible] a long, long time ago. So he was a philosopher. This is abductive reasoning or abduction is\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"or abduction is about reasoning about the best explanations given partial observations. That's really important aspect of storytelling and story understanding.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So normally when we watch a movie, we might be sitting for two hours that might describe a story that happened over a decade, for example. We do not need to see all the minor details of everybody involved in the scene because we can connect the dots, we can reason about what's not said because in our mind, it's obvious. That reasoning is abductive reasoning in that we fill in the blanks all the time.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"Sometimes, like another example is you come home, [inaudible] the new windows are broken in your house. They were okay in the morning. Then you might infer that maybe thief came in. You don't know for sure but this almost like pops in your mind right away, as opposed to you considering all the other million things that may have happened.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"It's almost like we instantaneously have this ability to reason about what to the best likely explanation to a scenario. Basically, what COMET, the common sense transformers try to do is like a smaller unit of that rich reasoning people do. I also work on abductive reasoning as well as counterfactual reasoning, as well as a storytelling.\\n\\nIn all of these, I try to think about these smaller units of reasoning in the form of common, basic more lower level, common sense inferences.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:15:17] Sam Charrington: Talk a little bit more about COMET. How do you apply transformers to these types of problems?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:15:25] Yejin Choi: Yeah, that's a great question. So now we're entering this knowledge integration. When we have this knowledge, how do we integrate for reasoning? The more I work on these areas, I realized that the distinction between knowledge and reasoning, this is in a continuum as opposed to them being two entirely different things in the following sense. A lot of the times our reasoning is almost memorized knowledge.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"We don't always recompute the whole thing, but anything we computed often enough, we already stored in the background knowledge. So it's a combination of the two. The more the model memorized, the more likely that it performs better even for new situations because it's able to draw a lot of analogy. Perhaps it's just similar to how humans who read a lot of books. Probably not guaranteed to be the best in an exam or writing a book, whatever, but it probably doesn't hurt. It only helps. So that's\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"helps. So that's that. Actually, in a technical sense, integrating knowledge that can be done in many different ways. So sometimes we just provided us additional textual input for any given QA problems. Some other times we can integrate that at the continuous level or neural level and at the neural representation level. Even for that, there are many different ways of doing it. We could do it more deeper integration with many layers of transformers, or it could do just at a shallow level, at the\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"level, at the input output layers. So people are trying different versions. That's what we have tried to do.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:17:13] Sam Charrington: In your case, how do you prepare your data to train a transformer model around these types of problems?\\n\\n[00:17:19] Yejin Choi: Great question. So didn't talk about that at all. COMET is basically starting off from off the shelf neural language models that have already read a lot of a raw data.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"Then we compile atomic knowledge graph as if it's just additional string of texts. So the COMET is reading atomic knowledge graph as if it's just natural language of sentences. We found that by doing so, the model is able to draw or connect to the dots between the implicit knowledge and the raw text to where the more explicit knowledge in the knowledge graph.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:18:01] Sam Charrington: When you say that COMET is reading that, is this a training time or is this your conditioning text when you're doing an inference against your model?\\n\\n[00:18:14] Yejin Choi: Yeah, that's during training time so that during inference, it can operate in a similar way. So given some context, it can then reason about whatever common sense inference types that we want to [look at].\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:18:30] Sam Charrington: I guess I'm trying to think through, how do you get to something that has, I guess I'm trying to get to the relationship between some formal reason, not formal reasoning in the sense of academic, formal reasoning, but something that is, where there's some actual reasoning happening as opposed to a language model spinning out texts based on stuff that it saw that was based on these relationships. If that makes sense.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:19:10] Yejin Choi: That's a great question. Now I'm Now I'm going to say something that some people might disagree with but I think a lot of academics have have these romantic view points about reasoning. It must be something that I cannot easily do but computers can do in a very accurate, precise manner We should We should be able to somehow come up with some logical formalism that really spells out all these inductive or deductive reasoning that we did in the process. I I think that was\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"I I think that was actually the reason why in seventies and eighties, the common sense research didn't go very well because researchers researchers back then back then were a bit too hung up on having to come up with this formal language logical forms or some sort of a logical formula that can describe the things we can reason through language.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='So I came to this conclusion in recent years that actually language is the best medium for reasoning. In fact, even mathematicians, they cannot do very much of a proof without access to natural language. If you ask those people who do this all the time, they actually think also a lot through language and they have to explain what their formula supposed to mean through languages even if they have equations and logical forms so that they define, they really cannot do very much with a language. But', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"with a language. But when we think about how humans learn and how we argue with each other to share our reasoning about an issue, everything is through language. The moment we try to invent to some other formalism, there's a loss of information or loss of expressiveness.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"That loss is so significant, so that it may be okay if I want to only focus on integrating some equations or differentiating some equations, then it's okay to lose the power of natural language. But if I want to do a social common sense reasoning, physical common sense reasoning that I can describe in natural language and all of it, then we are getting into trouble when we try to translate that content down to some mathematical formalism because we never been able to invent such a language\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"such a language that's equivalent to the power of language.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"The part of the problem is that natural language is a bizarre thing. It's just oftentimes ambiguous which is also why, there's a major discrepancy in the way how people might, I mean, even with the science, how how people interpret whether climate change is happening or not, or whether a vaccine works or not. One would expect that this scientific result, so everybody must be able to interpret it in the same way but actually not. So that's a part of the challenge and it seems that we just have to\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='that we just have to embrace it.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"When there's an ambiguity, instead of trying to invent a language that does not have any ambiguity might be that the AI agent has to be able to work with it. So it's a very experimental research direction, I would say, but empirically, it's been the most promising of all.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:22:56] Sam Charrington: I think what I hear you saying or at least the conclusion that I come to based on what you're saying is you're going back to using the transformers and language models as part of these common sense reasoning tasks is that to put it simply like the way you evaluate whether common sense reasoning is happening is if the result that you get is reasonable and not based on some other kind of formal structure.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"You just have to evaluate the results as opposed to applying some kind of formalism or analysis to the method. I'm not sure I agree with them. It seems like that leaves a lot to ask but is that essentially the direction you're going?\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:23:51] Yejin Choi: Kind of, I mean probably yes in the sense that this is a general question against the deep learning altogether, though in that, like can you drive a car by actually learning how to drive a car or can you translate language from one language to another by actually understanding any of those languages or it's just learning the surface pattern matching. So right now everything's surface pattern matching.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:24:18] Sam Charrington: Sure but I think the difference is like, in the language translation, the task is language translation and we're only evaluating whether the network is translating the language. Here you're saying that the task is or the objective is reasoning.\\n\\nSo how do we evaluate if the system is doing reasoning as opposed to producing, doing some task as proxy for reasoning?\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:24:53] Yejin Choi: Take pretending to be reasoning but so long as the common sense inferences that it spit out looks commonsensical, then we are happy. The model performance keeps increasing when judged by humans on events that it's never seen before. So we usually only evaluate on events that are brand new because what's the point of memorizing what was in the training data. So when we do do that, it's been...\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So the first time COMET came out in the world was two years ago. So every year we see some considerable improvement and it's been only two years. Machine translation, people worked on it for more than a decade. So let's not lose hope too soon after two years but machine is not really translating it. I mean, this is a philosophical argument but I want to redefine reasoning a little bit better because there's an intuitive reasoning that's never guaranteed to be correct.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='That\\'s primarily what common sense inference is all about because when you reason, \"Oh, maybe somebody broke into the house and stolen anything.\" How do you know for sure, you cannot know. So the real correct inductive or deductive reasoning should not allow you to make any judgements whatsoever, but then like, how do you leave at all?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"Like how do you understand story? Because story understanding is all about abductive reasoning as opposed to inductive or deductive reasoning. When people think about the correctness of reasoning, oftentimes they're equating that where the induction and deduction, which it feels more intellectually reasoning right because we are more exposed to it and abduction people don't talk about it very much because it's a monster that's hard to really attack for a long time in AI but the truth is everyday\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"truth is everyday human inference is objective reasoning, and that's really what's critical electing with AI without which AI cannot really have this robustness that humans have.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"Like when we encounter previous events in situations, we tend to be pretty good at doing the right thing. Even driving, we learn to drive really fast. We don't have to do all this. I could tell Casey is like previous on scene cases, what do you do with this human, that human, or human of all sorts, wearing crazy outfit. We don't need to see any of that.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"I think there's something really fundamentally lacking in current day, which is too test specific or even data specific, not even solving the task of solving only the data set because it's learning all these without learning the proper conceptual knowledge about how the world works. So I'm trying to get to that more basic knowledge about it. It turns out it's a really broad spectrum of knowledge that we know about the world.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='When we want to go for the broad coverage, language becomes very important to us. Medium for reasoning, medium for understanding between machine and humans. When humans want to check whether machine really know something or not, language is the best communication medium with the machine.\\n\\n[00:28:28] Sam Charrington: So going beyond or digging into the common sense reasoning a little bit more, you pursue research into a couple of, I guess, sub areas there.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='One is physical common sense reasoning, the other social common sense reasoning. Can you describe these efforts?\\n\\n[00:28:47] Yejin Choi: Oh yeah. So I think both are very important. So physical common sense reasoning requires perhaps more of the fiscal grounding as well, perhaps with the vision and robotics.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"For that, I also worked on grounded learning of language or grounding with computer vision signals and trying to learn the mapping between the two. Then for social common sense reasoning, I think that's really important for AI to actually understand humans, like how humans interacted with each other and then be polite, be reasonable, be fair.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"Now we're entering this social norms and moral norms as well because that boundary is not that distinct. Some of our social common sense knowledge, for for example, it's rude to turn on a blender at 5:00 AM if you're living with a roommate unless the roommate wakes up at four but in general, 5:00 AM, but it's not as morally bad compared to maybe stealing your roommate's money.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"I mean, probably like there are many things that are immoral and there's relative strength of their immoral or moral implications. Again, all of these are best to describe them through language. So I worked on a paper, I think it was last year, published last year. So it's called the Social Chemistry or Social Chem 101. It has a lot of annotated rules of thumb of social norms, moral norms, ethical norms, and in terms of ethics theory, it turns out this line of research, that philosophers should\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"philosophers should do, there's theres something called the descriptive ethics. This is when people ask or researchers ask people, what would you do if your roommate ran a blender at 5:00 AM? don't kill the roommate just because of that. So this is asking in a concrete situation, what would they do? We built that symbolic knowledge graph. Then again, we did something similar to COMET which is to build a social norm transformers to see whether they can reason about previous events and situations.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='and situations. Again, we were seeing very promising results there, and I think they should really be integrated into ideally, for example, dialogue systems in the future because currently the dialogue agents can be agreeable with anything. Even if you say, \"I\\'m going to kill myself\", it might just cheer you up to do that or if you say something really questionable in terms of an ethical judgment, it might just be agreeable but all of that should change. For that, we need a model for social', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='a model for social norms, moral almost as well.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:32:03] Sam Charrington: I'm thinking about examples like this Tay chat bot that learned all kinds of racist things and the like, and it sounds like what you're saying is that this is potentially a way for us to model societal norms and I don't know, filter is the right word, but whatever other models we build use something like this in conjunction to give the model a sense of appropriateness or whatever.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:32:37] Yejin Choi: Absolutely, and it's a little bit similar to, I mean, when we think about what GPT-2 and GPT-3, know, well, they read everything including Reddit and everything, including fake news and everything.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So of course, then it's going to spit out that kind of language and the reason why it's [saying] all these bias stuff, racism and everything is because it's not large enough. It's not the scale that will fix this bias or morality issues or ethical issues. We just need to teach them what is correct and wrong in the way that we teach our children.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"We tell children we shouldn't do this. That's impolite. We shouldn't do that. That's unethical. We're willing to teach all of these to humans. I think we should be more than willing to teach this to machines in the declarative form so that the machine knows what's right and wrong.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:33:36] Sam Charrington: At the same time, it jumps out at me that there's incredible challenges with generating ground truth that you might need to train a model when as humans, we don't agree on absolute terms. As to, for example, whether turning on your blender at 5:00 AM is better or worse than leaving a dish unclean in the sink overnight or something like that.\\n\\n[00:34:10] Yejin Choi: Yeah. Yeah.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:34:11] Sam Charrington: There's no clear hierarchy for many, if not most, of these scenarios. How do you address that kind of ambiguity in your work?\\n\\n[00:34:21] Yejin Choi: Yeah, so that ambiguity is what excites me the most because I realized that humans are weird complex beings who are somehow able to navigate through all that.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='Even though you and I may not agree, which is worse between the two, at least you and I agree that probably not everybody will agree with my decision. So we have this sense of whether \"Don\\'t kill people\". Okay. This one is probably easy for everybody to agree with but even so, of course there\\'s always some counter example somebody can come up with in some culture. Maybe it\\'s totally fine to kill your daughter if the daughter was raped by some other men. I disagree with it but there\\'s such a', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"but there's such a culture that does exist even in actual human societies. It's a challenge but the way that I address that... me and my students addressed that in our work is by incorporating all of that by asking a lot of people.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"If you ask a lot of people, their disagreement naturally arise in their annotations. Also we can even ask them directly. Do you think this is what everyone would agree or is this more discretionary question? So then we get that kind of information and then the AI then learns that for this situation, the answers are more like distributed across different labels. Whereas for this one, it's very skewed onto one thing. Again [inaudible].\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:35:58] Sam Charrington: Do you think as humans, we are good at knowing when other people may disagree with our world view?\\n\\n[00:36:05] Yejin Choi: Yeah, reasonable. It's not perfect. It's not perfect. We never are perfect by the way. Humans are not perfect. Humans are confused all the time.\\n\\n[00:36:16] Sam Charrington: Yeah. Yeah, exactly.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"You recently did a keynote at the Stanford HAI Foundational Models Workshop. I'd like to have you tell us a little bit about your talk there but before we do, tell us a little bit about the foundational models workshop, what was the goal of that session?\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:36:37] Yejin Choi: Yeah. So that workshop was quite impressive. It's giving a lot of attention to basically pre-trained neural models. I think they focused a lot on language models in terms of the speakers who were speaking at that technical session but I think they meant more broadly, any neural models trained on large amount of data that solves as almost like a foundation for other downstream applications.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='So my talk title was David and Goliath: The Art of Leaderboard in the Era of Extreme Scale Neural Models because this becomes a bit of a... as the neural models scale becomes extreme I would say, I do get a lot of extreme questions from students who are journalists, asking me - these are actual questions - asking me whether we will achieve AGI by scaling things up. Maybe nothing matters about scaling things up.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='Another extreme question that I often get is, \"Oh, what are we supposed to do in academia? Should we just all go to these companies where people are scaling things up? Can we do anything impactful from academia?\" So the talk was counter-argument against it because then and again, it\\'s not always the case that the winner stays winner forever.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='The giants, like there\\'s always new innovations coming from the younger generation. I find it really fascinating why is that the case and new startup companies are becoming \"the\" successful companies. This happens all the time. It\\'s not the case that the same company always win all the games and keep innovating.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So I do think that there are a lot of things beyond the scale but one counter argument, easy counter argument that I like to make is that we cannot reached to the moon by making the tallest building in the world one inch taller at a time. We just can't. We have to have a different, entirely different game plan.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So similarly, I don't think the scale alone will do it though scaling laws are real in that it's like denial is almost, you cannot deny. It's like, it's there, it's real, it's futile to deny it. However, we can be more efficient. We can sometimes even win larger models by incorporating different richer learning signals that can include even grounded learning in the 3D environment or grounded learning with images and videos.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='Then we can also do better knowledge integration, symbolic knowledge integration. So that was part of my talk as well. Last but not the least, algorithms used to be at the core of computer science. When I was a PhD student, it felt in some sense more intellectually beautiful because they were just more equations and more algorithms in our papers.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"I think that can come back. It's just that you cannot use the same kinds of algorithms. We need to develop better inference and algorithms for neural networks so they can do reasoning. The neural networks are very bad at. So when talking all year, I was talking mostly about just spitting out one word at a time, which it doesn't feel like hard reasoning or even correct reasoning but in our other work, we also do more of this constraint. I go to the meek inference or reasoning where given logical\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='where given logical constraints, the algorithm can then do this hard constraint satisfaction. That might be harder for humans might be easy for humans depending on the scale of it.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"But we founded that if we do that, we can beat larger scale neuro models with a smaller scale neuro models with the power of algorithms, logical constraints, logical reasoning. So I think that there are a lot of underexplored things there but one could always argue back that well, even the larger models can benefit from the logical algorithms, and that's true.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"If something is already so good, it's just that when something is so good, so big so that it's like a GPT-3 big, then most people cannot actually download the model and use it, or most people don't even have access to it. So there's I think a real need for making smaller models more powerful at the moment. So the talk was about that as well.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:41:46] Sam Charrington: There's reasoning in the context that we've talked about it. Do you think that it requires ultimately some kind of symbolic or algorithmic component or is it possible to do it wholly statistically?\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:42:04] Yejin Choi: I believe in combination of both. I think statistical or neural approaches can handle some aspects of reasoning really, really well but I don't think it can handle what's two plus three, that's five. The factual, real factual, really symbolic reasoning is much harder.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"On a related note, I do not believe the neural network like sequential, just neural method without actual integration of mathematical concepts can learn to do mathematics correctly. So how many days in a week? Seven days. So let's meet a day after this week on... instead of this Tuesday.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='When we do, for example, two days before Christmas, we know what I refer to by that. Neural network may not be able to and all these simple symbolic reasoning is really brittle right now with neuro [inaudible], I think. There has to be some symbolic integration into neural network [inaudible].', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:43:22] Sam Charrington: How effective are the ways that you and others in the industry are doing that now? Where are they most brittle, where are they strongest? Like what are the most interesting things in that integration that does integration points?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:43:42] Yejin Choi: Yeah. So the sort of the things that I personally tried... so we call our algorithm as neurologic decoding because it's a combination of a neural stuff with logic constraints and we take conjunctive and normal forms as the basis of logical forms and then go from there, and we developed this [quick] search algorithm.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"In some sense, the classical search. That was like AI textbook. In all the chapters it's all about search A, start search. So it's a search algorithm and that's one way to handle it but in doing so I realized the following, which is the evaluation benchmarks really thrive where people focus in terms of research.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So if the evaluation benchmarks do not require such a logical reasoning in order to do well on the leaderboard, then why would the people really bother working on it as much? So I think a part of the reason why that's lacking is because in order to do well on the existing leaderboards, oftentimes you have to just focus on scaling things up and then try to learn superiors patterns better instead of doing things more correctly under the hood.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So as we introduce harder tasks that actually require true reasoning, a more correct reasoning, I think we can see more research endeavor into that. People do work on it. It's just that those are not necessarily the winning recipe for some of the existing or popular benchmarks right now.\\n\\n[00:45:25] Sam Charrington: Do you foresee a time in which that becomes the case? Or what do you think is happening in the industry to get there?\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:45:34] Yejin Choi: I think so because I think they will realize that, okay, they solved some NLP leaderboards without really solving NLP. So then people start making new benchmarks and it turns out it's much harder to make really good benchmarks without exam writers' biases. So like the field really prefer the multiple choice questions who are categorical questions as an exam problems for AI because it's easy to grade, otherwise we don't know how to auto grade OpenText reliably. The downside\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"The downside of it is that machines are really good at solving problems correctly for wrong reasons. It's almost a Clever Hans horse situation where the horse ostensibly can do arithmetics. Well, horse cannot, it's just that it learned how to read the body language of the owner correctly. So there's that going on.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"I personally believe that there's a fundamental limit in multiple choice questions because there's always exam writers' bias sneaking in. The fact that machine can solve a multiple choice question does not mean that it can actually do inference in real life. It should be able to do more generative reasoning.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"What I call as a generative reasoning, which is you should be able to come up with your own answer like house window broke, what happened? Then you should be able to come up with your own answer as opposed to an oracle suddenly falls from the sky and provide with the four answers to choose from one of which guaranteed to be true.\\n\\nThis is how AI is currently operating with a lot of NLP tasks but I don't think that that's how it should be.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:47:32] Sam Charrington: You also do some work on language generation and conversational AI. May be going back to our exchange about story generation. Can you talk a little bit about that work?\\n\\n[00:47:46] Yejin Choi: Oh yeah.\\n\\nSo common sense is actually it's a bit of a journey in the past few years because a while ago, no, a few years ago, it took a lot of work.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='So we want the Amazon inaugural Alexa challenge. We meaning most the students, wonderful students. I was tagging along at UDoW, University of Washington. At the beginning of this competition, we thought, \"Oh, we are going to do neural models and reinforcement learning on top and do some magic. We quickly dropped that idea because we realized that it doesn\\'t work reliably for actual, real world conversational systems. You never know what it\\'s going to say.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"We cannot make a single mistake. Can I make ethical mistakes? So that's just not acceptable. But also, in terms of controlling the content, we found that neural networks are just, it's like a child that you never know what it might do. So we decided that it should be more like traditional dialogue system where there's like system diagrams and things are more controlled and templated.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"That's how we won the competition back then. But somehow it was not entirely satisfactory because the reason why we couldn't do that back in a more neural way is in part because neural network really lack this knowledge about people and the social common sense knowledge and reasoning capabilities.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"So that's why we then started to work in investing a lot into social common sense knowledge. As we worked on social common sense knowledge, why not also work on fiscal common sense knowledge. So I also like thinking a lot about storywriting and whether GPT-3 can actually write one or another.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"It's quite interesting when you think about how AI art works these days in that the paintings and drawings are pretty good. It's pretty passable maybe in part because you don't need to worry about this long-term coherence that you have to worry about for language storytelling but with the storytelling, I don't know when, or if at all, this largest [inaudible] neural models will actually write a good novel.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"It's very human only capabilities in my mind did that, the ability to tell a story because of there's so much of inferences and implications and connotations and everything you have to reason about. It's a rosy, grand goal in my mind to do it right but for now I like thinking about the components, the backbone of the story, like a structure of the story in terms of the bare backbone, like there are usually characters and relationships between them and things they evolve over time, therefore, we\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='time, therefore, we have to somehow represent that memory into some structure and then try to be coherent with it. These are all fascinating research questions and I sometimes address some bits of it in papers about. I think we still have a long way to go to make it work.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:51:20] Sam Charrington: So the Alexa challenge task was what?', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='[00:51:25] Yejin Choi: Oh, the grand challenge back then was to have a coherent conversation with humans for 20 minutes. At the beginning, I thought even one minute will be hard. What 20 minutes. So we ended up making a system that sometimes it survive the 10 minutes but not 20. It was just impossible. A [inaudible] was quite clever in scoping that system design though in that it was supposed to be more about contentful conversation about some news or events or movies and music and things like', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='and things like that, as opposed to random chitchat.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='It was okay to intervene conversation with a bit of randomness but it was supposed to be more like content full. So that way it was more factually grounded and people learned something from that conversation, something useful, something fun and trivia, some things like that to keep them entertained.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:52:29] Sam Charrington: Awesome. Awesome. Well, it has been wonderful chatting with you about your work around common sense reasoning. Thanks so much for... actually before we do, I'll cut this out. I'd love to have you share a little bit about what's next and where you see your broad research portfolio going. What are the areas that you see as being most promising?\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:53:00] Yejin Choi: Yeah. So broadly I'm interested in reducing the gap between AI and human intelligence, especially in the way that AI is not able to learn concepts properly, and AI is not able to abstract away conceptual knowledge from its experiences with the raw data.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"The fact that AI is not able to learn interactively with the world making hypothesis of its own and asking for information that it needs on its own. I mean, imagine human learning like AI today, which is just like a force to read the lots of [tests] in a particular order that doesn't make any sense. You're not able to go back and reread any confusing part or ask a question about that part. So I think there's a lot to be done about the learning paradigm, really different learning paradigm so that\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content='paradigm so that more meaningful and correct conceptual knowledge will arise from that learning experience.', metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"I don't think my lab has tried where the common sense transformers is necessarily the right way to do it. I think it's more like a hybrid diversion to make the best use of current deep learning models but not necessarily the ideal model because we're still spoon-feeding too much into neural language models.\\n\\nSo yeah, that's what I would be the most excited to think about.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:54:35] Sam Charrington: Awesome. Awesome. Well, Yejin, thank you so much for taking the time to share a bit about what you're working on. Very interesting stuff.\\n\\n[00:54:43] Yejin Choi: Thank you for having me. Thank you.\\n\\n[00:54:45] Sam Charrington: Thank you.\", metadata={'source': 'content/data/518 - Yejin Choi.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: All right everyone, I'm here with Virginia Smith. Virginia is an Assistant Professor of Machine Learning at Carnegie Mellon University, Virginia. Welcome to the TWIML AI Podcast.\\n\\n[00:00:10] Virginia Smith: Thanks. Thanks so much for having me.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:00:12] Sam Charrington: Hey, I'm looking forward to diving into our conversation. We are going to be focusing on federated learning and some other topics but before we do, I'd love to have you share a little bit about your background and how you came to work in the field.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:00:27] Virginia Smith: Yeah, absolutely. I think for me, I always enjoyed math. I always wanted to take as many math classes as I could but I think one question I had is, \"How can I really put this math to use?\" and just before my senior year in undergrad, I took my first computer science class and absolutely loved it and that\\'s what I wanted to focus then on in my PhD, something at the intersection of computer science and math, and I think machine learning was a really natural fit.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='In my PhD, there was around the time I started a lot of excitement around big data and deep learning was also taking off and so there was a lot of focus on how to make models more accurate and how to make them more efficient and that was what I focused on in my PhD, is techniques for distributed learning and distributed optimization so taking a lot of the machine learning methods we knew and love in the small-scale setting and getting them to work across large data sensors and massive amounts of', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='massive amounts of data.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"Since then, in my research as well as a lot of other researchers, I think we realized that big data is not just big, it's also very complex and there's a lot more to the picture than just efficiency and accuracy so a lot of my recent work has been focusing on other constraints as well, things like robustness, and fairness, and privacy.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='One application that I think really makes these points salient and grounds these ideas is the application of a federated learning where the goal is to go beyond the data center and train across networks of remote devices or across private data silos like across different organizations and I think that this is a really exciting and ongoing area of research.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:02:09] Sam Charrington: Awesome. You think of federated learning as an application that grounds your research. Is there an application of federated learning that you like to think about when you're thinking about your research?\\n\\n[00:02:23] Virginia Smith: I think there's one thing to notice. I guess there's become an important dichotomy in terms of the applications of federated learning.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='There are applications in cross-device federated learning where the goal is to train across a large network of remote devices and then there are also applications in what is known as cross-silo federated learning where the goal might be to train, again, in a privacy preserving way but across a group of 10 organizations or it could be hospitals or financial institutions.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"I've done some work on both types of applications but more of my work tends to be in the cross-device federated learning setting.\\n\\n[00:03:02] Sam Charrington: Okay and the main distinction between those is a one to many set of concerns about privacy versus few to few. Is that a good way to characterize it?\\n\\n[00:03:14] Virginia Smith: Yeah, so there can be differences in terms of what you care about from a privacy point of view. I think a major difference is just the scale.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"In the cross-device setting, you're talking about maybe thousands to millions of devices that you're learning over each of those devices could be really constrained from a computational point of view.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"In the cross-silo setting, it could be, like I said, 10 hospitals that you're training over and you might have more compute power at each of those hospitals but there could be similar concerns about not sharing private information across the organizations or across the devices so in that way, they're fundamentally distributed learning problems that's just different in terms of the scale and then as you mentioned, the privacy characteristics.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:03:58] Sam Charrington: Right and how much of your research is focused on the, or even beyond your research, in terms of where the field is today, the distributed learning aspect of these problems relative to the privacy aspects of these problems?', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"I've done a number of interviews on privacy-preserving machine learning, differential privacy techniques like that and I'm curious if that's the bulk of your research versus are we still trying to figure out better ways to do the core learning itself across devices?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:04:33] Virginia Smith: Yeah, that's a great question. Really, it's both and I think in federated learning, privacy is really a first class citizen so it's one of the main motivations for performing this, distributed learning problem\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\".You don't want to move all of the raw data that you have from these user devices to some central location. There can be some downstream privacy benefits for keeping that raw data local and so privacy is a really important consideration and I think a lot of the exciting work in federated learning is thinking exactly about this, so how do we take the privacy notions that we've thought about in simple or centralized settings and understand them in this distributed learning context but certainly,\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='but certainly, my work focuses on both problems.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:05:15] Sam Charrington: And it sounds like there, from a practical perspective, fairly, tightly intertwined.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:05:21] Virginia Smith: Yes. They can be very related so I think, as I mentioned, privacy helps to motivate why we would want to perform this distributed learning problems, so why we want to keep data on these devices as opposed to moving them but it also makes it difficult to perform the distributed learning because you want to make sure that the information that you do send over the network doesn't reveal any sensitive information.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:05:43] Sam Charrington: One of the areas you\\'ve been focusing on from a research perspective is fairness and robustness? You\\'ve got an ICML paper on that topic. Let\\'s start with what \"Fairness\" means in this context because I think it\\'s different from the type of fairness we think about from an AI ethics perspective.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:06:03] Virginia Smith: Yeah, that's a really great point and I think this goes back to this earlier point I mentioned which is one thing I think is interesting to me about federated learning is it helps to ground these notions in a specific way and certainly, I should say there are multiple notions of fairness that you could consider in federated settings.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"One of the notions that we've been looking at and that we touch on in this work is related to the idea of representation disparity and the idea is basically that if you have a network of heterogeneous devices so different user devices might be generating data that looks slightly different across the network. You could imagine a network of mobile phones. People might be interacting with those phones in slightly different ways and for that reason, that data might look slightly different across the\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='different across the network but you want to train a model that performs ideally equally well across these possibly differing, diverse devices that you have in the network.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='This is related to the idea of representation disparity. We want to, I think, a good way to phrase it is at a high level, you want to ensure some reasonable quality of service across the entire network. You want to train a model that performs reasonably well across all of the different devices.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:07:15] Sam Charrington: And so the premise is that if you apply distributed or federated learning techniques without considering the specific needs of fairness, it's likely that you're going to run into problems where the results aren't fair in that way?\\n\\n[00:07:32] Virginia Smith: Yes.\\n\\n[00:07:33] Sam Charrington: What are the particulars of the failure modes and why do you see them when you're not worried about them?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:07:39] Virginia Smith: What can happen is typically, when we're training a model in a federated network, one of the most common objectives to consider is just traditional, empirical risk minimization and with that objective, typically, you consider it just minimizing an average notion of loss so you're trying to minimize the average error across the different devices in the network and the concern is that if you just look at the average performance, it could be that you perform quite well on\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='quite well on average but at the expense of performing maybe very poorly on a small subset of the devices so you can have situations where if you have a small set of devices that differ in some way, then you can have a model that performs well on many of the devices but could perform catastrophically on some of these devices and this is why you would care about looking at alternatives to improve [inaudible] and encoding this kind of notion of fairness for federated learning.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:08:34] Sam Charrington: And when you're thinking about fairness in this way, is it independent of what's the relationship between the model or the thing that you're trying to optimize across the different devices?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:08:49] Virginia Smith: The issue is that if you're training just one model to perform well across all of these devices and you have differing data coming from these different devices and the data might differ in some meaningful way then there can be limited capacity for one model is to capture all of this diversity and this is where you can have issues with fairness being a concern.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"This can particularly happen because in federated settings, we're thinking about training models that we can deploy often on device that can run very efficiently and perform often real-time machine learning and that naturally limits the types of models that we're able to deploy in these settings and so this is a scenario where even if we have expressive models, there can be a real limit to how just a single model can capture this entire realm of diversity across the network.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:09:42] Sam Charrington: And fairness is just one of many attributes that you're looking to balance when you're training a model, federated or not. Can you talk about some of the trade-offs that you're making, particular your work focuses on a trade-off between fairness and robustness?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:10:03] Virginia Smith: Yeah so robustness is another really important concern in federated settings and the idea here is that because you're using user devices as a computing substrate, there can be practical issues that happen with these devices.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"Someone might turn their phone off or you could potentially have an adversary in the network and so we want to develop models that are robust to things like device failures or possibly to correct a data and what's interesting though is that if you think about the issue that I just talked about with fairness, which is that we want our model to fit well, possibly to diverse or heterogeneous-looking data, this can be directly at odds with this issue of robustness so a common way that people handle\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='that people handle robustness is they look at that diverse data or the outlier data that they\\'re seeing and they get rid of it, right? That could be data coming from a corrupted device or a device where there\\'s been some failure and so an easy way to think about encoding robustness is just to say, \"Let\\'s ignore that information,\" and the reason I\\'m saying this can be at odds with fairness is from a fairness point of view, if that data is actually just coming from a device maybe that\\'s generating', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"that's generating some different looking data, then that's exactly the device that we want to upweight, that we want to ensure that our model fits well too and so this is why these two notions can be at odds in federated learning.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:11:26] Sam Charrington: And so a big part of your research in this paper that I referred to, the ICML paper is looking at the trade-offs and how to ensure fairness while managing robustness. Walk us through the approach that you take.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:11:42] Virginia Smith: Yeah so one of the insights that we have in this work is that if you\\'re training as I mentioned, just a single model across the entire network, there\\'s limited capacity for this one model to be able to both ensure fairness and in short, robustness simultaneously and one of the techniques that we propose to help address both of these constraints is something called \"Multitask Learning\" and the idea is basically that intuitively, if you have data that differs across the', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='differs across the federated network, it makes sense to not just train a single model but possibly to train multiple models, so to personalize the model to the local data and multitask learning is one way of doing personalized federated learning.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"The idea is that you're just solving multiple tasks, you're solving from multiple models simultaneously and this is something that I think, again, it's intuitive but what we've seen is that it's actually quite powerful on how this simple technique, we're not trying to do anything specific regarding fairness or robustness, we're just implementing actually a very simple multitask learning framework.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:12:46] Sam Charrington: And does multitask learning always denote two models as opposed to a single model that's trained to do two things?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:12:55] Virginia Smith: Yeah. Thanks for bringing this up. Multitask learning has many meanings for different applications so we're commonly in deep learning, people might think about multitask learning as learning across is actually a very diverse task, like you're training some NLP models simultaneously with an image classifier. Here, the notion that I'm referring to for multitask learning is that we can view each device as being its own learning task and so the overall learning objective\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='learning objective can be similar between them.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"You could still be training, just a single image classifier but the notion of a task is with respect to the local dataset on the individual device so you're still trying to train an image classifier but now you have multiple different devices that are generating data and you model each of those devices as an individual task.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:13:44] Sam Charrington: Ok. I'm trying to put the pieces together. I was thinking about it in the kind of the way I traditionally think of multitask learning whereas you might have one objective function that's focused on fairness and another that's focused on robustness and another that's focused on whatever your core task is and multitask is the way you are optimizing across these three objectives but it sounds like that's not really what we're talking about here?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:14:11] Virginia Smith: No, yes and that's a good question. What we're showing here and I should say one of the reasons that we look at multitask learning in particular is that this is something that's been shown to improve just the accuracy so forgetting about fairness and robustness, just learning an accurate model in federated settings, multitask learning and other forms of personalized federated learning have been shown to really improve just the raw accuracy and the reason is exactly\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='reason is exactly this point that we mentioned earlier which is that the data might differ across the network and so learning models that are personalized to each of the individual devices can help to improve the overall accuracy but what we show in this work is that there are also important benefits in terms of fairness and robustness and especially when you care about both of these things simultaneously.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"Basically, what's going on is that if you're learning models that are personalized to the individual devices, then those models have more capacity to learn to the heterogeneous data. You can learn models that are more fair to data that looks diverse and you can also separate this tension of having just a single global model that you're learning which helps to deal with issues like robustness.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"You can learn a separate model for all of the corrupted data in the network for example and then that corrupted model doesn't affect the other parts of the network where you've learned other personalized models.\\n\\n[00:15:36] Sam Charrington: Okay and is there something as simple as hyper parameter that you can dial, that you can tune that weights the locally learned model or the model trained on local data versus the centralized?\\n\\n[00:15:52] Virginia Smith: Yes, yeah.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:15:53] Sam Charrington: I'm imagining there's multiple ways to do that. You can tune that model at inference time as well as at training time.\\n\\n[00:16:01] Virginia Smith: Yeah. So we actually, in this work, I think this is a much broader research direction which is looking at all different multitask learning for federated learning or other forms of personalized federated learning but in this work, we actually look at a very simple objective, which is similar to what you're saying.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"Basically, what the objective does, it's a simple form of multitask learning where there's basically two tasks. There's a global model, so there's the model trained across all of the devices and then there's a local model, so the model that's personalized to the local data, and there's a simple hyper parameter that you can tune to adjust how much you want to rely on the global model versus just your own local model that's just fitting to local and I think the tension there is that the whole\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"is that the whole promise of federated learning, the reason that we care about doing this is that ideally, we're getting something from sharing all this information across the network.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='We would hope that the global model is providing some useful information, but we also want to be able to trade off between learning just that one global model and learning more personalized or local behavior on each of these devices and so this is exactly what you can do with this hyper parameter.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:17:10] Sam Charrington: Nice. When you've got this hyper parameter, is the implications of the local data confined to the local model which is trained on the device and it stays on the device and that's how you ensure this separation between the local data and the central data or in what ways are you leveraging the local data and creating the centralized? Are you still sending the data? Are you sending weights? How is the centralized model trained?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:17:42] Virginia Smith: Yeah, so there's two parts of training this multitask objective so there's the global component and then there's the local component. The local component and actually this hyper parameter that I just mentioned is trained completely in a distributed fashion on completely local data so ignoring the information from all of the other devices and you can tune [inaudible], they're just looking at local validation data so that's all happening locally.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"What happens across the network, where you end up sharing information is when you're training the global component of the multitask objective and what you can do here is you can apply basically a bunch of work in federated learning to think about how to train this global component but what you end up sharing is exactly what I think you alluded to, you ended up sharing model updates that are curated based on the local data so basically, you're trying to find one global model by aggregating a\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='by aggregating a bunch of smaller model updates from each of the devices.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:18:38] Sam Charrington: Got it. Very cool and what types of datasets do you evaluate this on and in fact, talk a little bit about evaluation of federated learning in general. What are the standard benchmarks and metrics that you're looking at?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:19:01] Virginia Smith: I think this is a really important problem. Federated learning is very much an ongoing area of research. There's a lot of new applications coming out and I think as such, it's really critical that we have a reasonable set of benchmarks to look at so this is actually some motivation for me and as well as some collaborators at Carnegie Mellon and at Google.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='We came together and we created something called the \"LEAF\" benchmark which can be used for evaluating federated learning on common applications that you would see in practice of federated learning. It includes a suite of open source data sets that you can use for evaluation as well as complimentary metrics that you would care about so you could validate things like looking at the average accuracy across devices or you could look at notions of fairness for example, as well so that\\'s part of the', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"that's part of the benchmark that we develop.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"In terms of evaluating what performance looks like, we're trying to simulate what performance looks like when you're actually running this on say a network of mobile phones. There are a couple of strategies here. So I think one of the most common ones is to train this in something like a data center setting but then simulate what the performance might be if you were running it on a device so you can think about gathering the raw metrics from training this in a data center and then you can scale\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='then you can scale those in various ways depending on what sorts of constraints you want to add to that training process.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"Another one I should mention is that there's also a few, actually, benchmarks that have come up from other groups. One from Google is TensorFlow Federated and the goal is to make this, I think, easier for people to actually run on device so they provide some tools that you could potentially run these techniques on device as well.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:20:46] Sam Charrington: Maybe even more fundamentally, is there a well-accepted metric for fairness in a network or a robustness in a network ala BLEU score for these types of metrics or is that still evolving?', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:21:00] Virginia Smith: Yeah, I think there's still a lot of work to be done to make this more rigorous and to evaluate a lot of different metrics. For fairness, I think there's more of a clear answer here right now and that a lot of the work in fairness has focused on this notion of representation disparity that I mentioned.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"The goal is to try to ensure a more uniform performance across the different devices. You can measure this by looking at say the variance of the test accuracy distribution or you could look at the worst performing accuracy so you could look at like the min and max performance, try to find the worst performing device and make sure that's above some threshold.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"Those are two common metrics for fairness. For robustness, there's a lot of different things you could think about. You could look at robustness to device failures, as I mentioned, you could see what happens when devices drop out of the network, or you could look at all sorts of different attacks and I think a lot of the attacks here mirror what you see in centralized settings so you can look at traditional data or model poisoning attacks which is as applied in the federated setting.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:22:06] Sam Charrington: Got it. Awesome and then separately, you've got another paper at ICML that's focused on federated learning in a more of an unsupervised setting. Can you tell us a little bit about that paper?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:22:20] Virginia Smith: Yeah so the motivation for this paper was actually that I think there were two key motivations. One is that in practice, for a lot of these federated learning applications, you don't have labeled data and I think for that reason, we wanted to spearhead some work in unsupervised federated learning, specifically looking at this idea of clustering in federated networks but a second major motivation for the work is that so far, a lot of the problems I've discussed revolve\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='discussed revolve around this issue that data is diverse in federated networks. You have this issue of heterogeneity that the devices might be generating differing data and this can result in a lot of problems.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='It can break the assumptions that we have for traditional distributed optimization methods, it can result in issues of unfairness. It can make it difficult to provide robustness but what we show in this work is that there, for a certain set of problems, there can actually be benefits of heterogeneity and I think intuitively clustering is one where diversity can be beneficial and what I mean by that is the method that we propose in this work which looks at federated clustering is a simple,', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"is a simple, one-shot clustering scheme where basically what you do is you cluster locally on each of the devices and then you aggregate that clustered information to form one global clustering of the data and intuitively, if you have data that's diverse across the different devices, this can actually make that method more effective so if you have some diversity, if you already have natural clusters that form on the devices, it can be easier to do this in a totally distributed fashion and this\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='fashion and this is what we are making rigorous in this work, is the benefits that might exist of clustering in a federated network specifically when you have heterogeneous data.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:24:14] Sam Charrington: And so meaning the paper's not specifically focused on the techniques but looking at performance bounds as the more theoretical paper? Is that the idea?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:24:26] Virginia Smith: Yeah so it's a bit of both. We do propose this one-shot communication scheme. It's basically just a distributed version of Lloyd's method which is a very common method for K-means clustering but then I think the meta that is, is really analyzing the performance guarantees for that method and showing in particular that this issue of heterogeneity can be beneficial for the analysis.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:24:50] Sam Charrington: Okay and can you summarize the intuition around how this method makes heterogeneity beneficial or unlocks the power of the native heterogeneity in the data?', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:25:04] Virginia Smith: Yeah so I think that the main idea is basically that if you want to do this simple, very communicatio-nefficient type of clustering which makes a lot of sense in federated learning. If you're training across a million devices, it makes sense to try to reduce the communication as much as possible.\\n\\n[00:25:20] Sam Charrington: Yeah.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:25:21] Virginia Smith: This technique that we're looking at is I think a really simple heuristic for how you might want to perform clustering in practice. Basically, you can cluster your data locally on each device, send it to some central server, and then you can aggregate those local clusters into one global clustering and the reason I'm saying that heterogeneity can be beneficial for this process is that in clustering, the goal is basically to split your data into separate sections, to\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"sections, to split it into these separate clusters and if your data is heterogeneous, in some way, it's already been distributed based on these clusters so you would imagine that some devices might only have data from a small subset of the total clusters and given that, then it helps to make this process more decoupled.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"It makes it easier to distribute the clustering across the devices and this is the way that heterogeneity can benefit this analysis. Specifically, if we look at this idea that each of the devices only has data from a small number of clusters, it's an intuitive way to think about how the data might be heterogeneous.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"There's a small number of clusters that belong to each one of the devices, basically and what we show them is just that by performing this one-shot clustering scheme with this heterogeneity assumption, you can show that the results are basically better than if you were performing it on totally randomly IID partitioned data.\\n\\n[00:26:44] Sam Charrington: Okay. How do you characterize the heterogeneity of your data in this? What's the assumption you're making?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:26:53] Virginia Smith: Yeah so in this paper, we're making this assumption that each device contains data from a small number of the underlying clusters. Say that all of your data is coming from I don't know, a hundred different clusters, then the assumption could be that every device contains data from only three of those clusters and this is one notion of heterogeneity but it makes sense , in the clustering context. If your goal is to perform clustering, it makes sense to think about\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"sense to think about heterogeneity in terms of the underlying clusters. This is the notion that we look at, it's basically that there's a small number of clusters that generate each of the local data sets at each of the devices.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:27:31] Sam Charrington: Is there a lot of prior work that has gone into this idea of thinking like local IID versus global IID in federated environments?', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:27:43] Virginia Smith: I would say that there's a lot of work thinking about this issue of heterogeneity in federated settings so this is really, I think, a defining characteristic of federated learning compared to something like the data center setting and the reason is that in the data center, the idea is that even though you're still solving a distributed learning problem, you own and can access all of that data and you can re-partition it any way you want to.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"The major difference in the federated setting is that each of these devices, say a mobile phone, you're generating data on that phone and then you're not moving that data or re-partitioning it across the network in any way and what this means is that on the data center, even though you were still distributing your data across different machines, you could partition that data in an IID manner and an independent and [inaudible] distributed manner across the machines.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"In the federated setting, you're getting the data as is. Different devices might be generating different data and that results in this issue of non-IID or heterogeneous data across the network.\\n\\nI think I mentioned this earlier but there's been work in thinking about how this affects fairness and robustness but another major issue is that this can affect some of the convergence guarantees that we have for communication-efficient optimization methods in federated settings.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"One of the main assumptions that's typically made when you're performing distributed computing is that the data is IID distributed across the nodes and so this actually breaks a fundamental assumption in some of the common methods and analysis that are used for distributed learning.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:29:18] Sam Charrington: Yeah and I guess I drew a parallel between one of these devices or a subset of devices with heterogeneous data and what I thought that was like local IID. Do you see that within one of these heterogeneous segments there is an IID property and do you rely on that or do you assume that IID is just broken and it's replaced with this local notion of heterogeneity?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:29:43] Virginia Smith: Yeah, so I think a good way to frame it would be that each device is generating data in an IID way but according to its own separate distribution and the distributions can differ across the devices but each device might be generating data in an IID fashion just according to its own unique distribution.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"I think one of the motivations for something like multitask learning would be that the distributions between different devices might be similar so it makes sense to train them simultaneously and to learn about how these different devices might differ from one another but they differ in meaningful ways so it's also [inaudible] not to just train one model.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:30:22] Sam Charrington: We talked a little bit about applications of this work and federated learning. Generally, when you're looking at the unsupervised setting, what are some specific applications there? Is it something along the lines of you have an army of mobile devices and you're trying to segment them by type or something like that?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='[00:30:44] Virginia Smith: Yeah so actually one, this relates to this idea of multitask learning and personalized learning more generally. A simple way to perform multitask learning is just to first cluster your devices into clusters so if you knew that there was a natural clustering between the devices, then you could learn models specific to each of those clusters.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='This would provide you this one-shot clustering scheme that we look at provides you a simple way to do multitask learning. You can just do this clustering procedure and then you can learn models that are personalized to the individual clusters in the network.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='But beyond that, I mean clustering is obviously widely used for a lot of applications and machine learning just as an important pre-processing tool to understand and analyze the underlying data distributions that you have and so this could also just be used as maybe a pre-processing step to get a sense of what the data looks like in the network.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:31:40] Sam Charrington: Does your first point suggests a hierarchical model tiering where you've got this centralized model then you've got this intermediate type of model that's based on clusters and then you've got a local device model, ala the first conversation about robustness and fairness and instead of your one Lambda parameter, now you've got two that you're balancing across these different models?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:32:03] Virginia Smith: Yeah. You know that's an interesting point. We haven't looked at that but I think that's a very natural way that you could think about applying these things. Yeah, you could have maybe multitask learning happening within each of the clusters as well and I think, and this is something that we haven't looked at as well but I think it makes sense.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"Another benefit of these multitask objectives or things like clustering is that you could also help to reduce communication in a meaningful way so you could, only in this scenario that you're describing, maybe you could have this nice, hierarchical structure where you only actually communicate within a small cluster than the network as opposed to sending everything to this one central location.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:32:38] Sam Charrington: Right. Awesome, so what are some of the future research directions that you're looking at and excited about in your work?\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:32:45] Virginia Smith: One direction that I think we started at and then I just want to circle back to is the idea of privacy. This is something that is really important in federated settings and in particular, the common notion of privacy that's considered is that we want to be able to train models across these devices without necessarily being able to know that any one device participated in the training procedure so a common tool to address this is through techniques like differential\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='like differential privacy.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"Some recent work that I've been looking at I think is really important is to think about how privacy then connects with issues of fairness and robustness and personalization so a lot of the other topics that I touched on and in particular, one area we've been looking at recently is defining notions of privacy for multitask learning so for these personalized objectives, there's a real lack of work understanding how to make those models differentially private and I think that's a really important\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='a really important area of work to ensure that we can simultaneously address all of these constraints, not just fairness, and robustness, and efficiency, and accuracy but also the constraints of privacy.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:33:52] Sam Charrington: Awesome. Well Virginia, thanks so much for taking the time to chat. It's been great learning a bit about your research and what you've been up to.\\n\\n[00:33:59] Virginia Smith: Yeah, thank you so much. Thanks again for the opportunity.\\n\\nThank you.\\n\\n[00:34:06] Sam Charrington: All right everyone, that's our show for today.\\n\\nTo learn more about today's guest or the topics mentioned in this interview, visit TWIMLAI.com.\", metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content='Of course, if you like what you hear on the podcast, please subscribe, rate, and review the show on your favorite podcatcher.\\n\\nThanks so much for listening and catch you next time.', metadata={'source': 'content/data/504 - Virginia Smith.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: All right, everyone. I'm here with Alison Gopnik. Alison is a professor at the University of California at Berkeley. Alison, welcome to the TWIML AI Podcast.\\n\\n[00:00:10] Alison Gopnik: Very happy to be here.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:00:11] Sam Charrington: I'm really looking forward to our conversation. We will be focusing in on a presentation that you'll be delivering at this year's NeurIPS conference, focused on causal learning in children and how that relates to some of the things that we're doing in AI and deep learning.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"Before we dive into that though, I'd love to have you share a little bit about your background. You come at things from a psychology perspective. Tell us a little bit about your background and how you came to that field.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:00:38] Alison Gopnik: Yeah. So, I actually started out my career in philosophy and I'm still in affiliate in philosophy. So, I have sort of three different hats at Berkeley. I'm in the psychology department, an affiliate in philosophy, and then part of the BAIR, the Berkeley AI research group.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"The big question that I've really wanted to answer my whole career is this: how is it that we can know so much about the world around us from so little information? All we have are the photons in the back of our retinas and the disturbances of air at our ears. And yet, people can figure out that the world is full of objects and people and thoughts and ideas, and quarks, and black holes. How is that possible?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='And of course, that\\'s the big problem of epistemology and philosophy, which is where I started out, \"How could you possibly do that?\" And it\\'s the big problem of machine learning. It\\'s the sort of central problem of machine learning: how could we get representations from data? A way of putting this is we seem to have these very powerful, abstract, structured representations of the world around us that let us make great generalizations and predictions. And yet, the data that we\\'re getting doesn\\'t', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"getting doesn't seem concrete and particular, and doesn't seem to have those characteristics of being abstracted unstructured. So, the question is, how do we get here from there?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"Well, very early in my career, I realized, look, the people who are doing that most effectively are actually young children. They're the ones who are going out into the world, taking what they see and hear and the actions they perform and figuring out what the world is like. So, if we want to answer that question, either as philosophers or as people in AI, the people we should look to--the people who are really solving that problem--are young children.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And basically, that's what I've been doing for my whole career: is trying to figure out how is it that young children, two, three, four-year-olds, who don't have PhDs in computer science, aren't philosophers, nevertheless, seem to be solving these problems that have really stumped the smartest minds in philosophy and AI?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"About 20 years ago, I started actually collaborating with people in both philosophy of science and in computer science to try and figure out, could we say something computationally? What kinds of representations and algorithms could the kids be using that let them learn as much as they do? And that's basically been the project ever since.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And I think it's interesting that there's been, just in the past few years, there's been this real, explosion of interest within AI in trying to look at development and look at children and use that as a clue to solve some of these really tough problems. And I think it's because, so much of the new work has depended on the idea of designing systems that learn rather than trying to build things in, in the first place.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And if you're interested in systems that learn, kids are really wonderful. Probably the best example we have of creatures that are really, really good at learning very accurately from small amounts of data. So, that's the big overarching picture about what I've done.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:03:37] Sam Charrington: Fantastic. It sounds like you think about the problem of learning and children, broadly, at the level of these broad representations. But your talk at NeurIPS is focused on a particular aspect of that, and that is the way that children infer causal relationships and structure in the world. Tell us a little bit about your talk and your research in that area.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:04:03] Alison Gopnik: Yeah. So, if you're asking this question: how do we get these big, abstract, powerful representations of the world? One of the most important--not the only one--but certainly, one of the most important kinds of ways we have of representing and thinking about the world is thinking about causality, thinking about what makes what happen.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='first line of work that I did with children was what\\'s come to be called the theory-theory. And that\\'s the idea that children are building everyday theories of the world that are a lot like the way that scientists build theories of the world. And that\\'s become one of the most prevalent theories about how children solve this problem. They do something like build everyday theories of the world around them. But of course, then the question is, \"Well, how do they do that?\" Right? You say that', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"Right? You say that they're doing something like scientists, how do scientists build theories of the world around them?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='Back in the \\'00s, there was a whole bunch of very exciting work showing that you could build causal pictures, causal representations of the world from data. And that\\'s not the only thing scientists are doing. It\\'s not the only thing involved in theory formation, but it\\'s a really important thing in theory formation, because if you have a causal model, if you have a theory, if you have a representation, then you can solve these out-of-distribution, generalization problems. You can say, \"Okay,', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='You can say, \"Okay, well, if we do this to the vaccine, even if it\\'s something we\\'ve never done before, we can predict what will happen, because we have a causal model of how the vaccine works.\"', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:05:27] Sam Charrington: Yeah.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:05:27] Alison Gopnik: And the advantage of thinking about causal models, they're an example of something that lets you generalize really broadly. And it isn't just letting you generalize about a specific area, like the way that having a representation of everyday physics or a representation of the visual system could help you to generalize. Causality really covers everything. It covers the way that you interact with other people. It covers the way that objects work. It covers things that\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"covers things that you've never seen before.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"So, if you had a way of figuring out what makes what happen; if you had a way of figuring out causal structure, you'd have a really, really powerful tool for going out into the world and solving new problems and making new predictions. One thing that's really important about causality-- and a lot of people think of it as being the thing that makes causality different from say, just correlation, of the sort that typical deep learning programs have done-- is that causality lets you intervene, is\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"you intervene, is the word that people use. It lets you decide what to do and think about what the consequences of that are. Causality let's you make counterfactual inferences.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='If I know that smoking causes lung cancer, for instance...if I think that that\\'s right, then I\\'ll know that even though smoking is correlated with yellow fingers, washing your fingers isn\\'t going to help change the cancer rate. But not smoking--getting people to not smoke is going to change the cancer rate. It also means that I can say, do some counterfactuals. So, I can say, \"Well, look, if we had had anti-smoking programs earlier, we would have saved more people from cancer.\" So, that ability', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='So, that ability to do interventions and counterfactuals is a very powerful aspect of causality and causal representations.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And back in the '00s, people like, Clark Glymour and Peter Spirtes at CMU and notably, probably most famously, Judea Pearl at UCLA started developing these formal models for how those kinds of causal representations could work, computationally. So, causal Bayes nets, graphical or probabilistic graphical models were the kinds of representations that they had. And back in the '00s, we started trying to see, are children doing something like inferring causal Bayes nets from data? And amazingly,\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"data? And amazingly, much to everyone's surprise, it turns out that even if you're looking at two, three, and four-year-olds, they're really good at doing that. You can give them a pattern of data, of conditional probabilities and they'll pull out the right causal consequences from that data. So, they seem to be doing something that looks like very effective causal inference.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:08:02] Sam Charrington: Going back to the theory-theory, what were the alternatives to the theory-theory before that theory? And how did you demonstrate that the theory-theory was predictive and had merit?', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:08:17] Alison Gopnik: Yeah. Right, that's a great question. In fact, I think people in an ML and AI should be very familiar with what the alternatives were, because they're the alternatives that we have in ML too. So, one alternative --again, going back to really, Plato and Aristotle is, look, it just looks as if we have all this abstract structure and representations. Really, it's just, you've looked at a whole bunch of data and you pulled out the statistics of the data and that's letting\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='and that\\'s letting you make predictions. And that was one thing that...what\\'s sometimes called the empiricist option was, \"Okay. Maybe it\\'s not the children have these abstract representations. Maybe they\\'re just following the data and it just looks like they have the abstract representation because they have a whole lot of data and a whole lot of observations.\"', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='And then, the other option, which again, is very active in AI now is, \"Well, look, maybe they aren\\'t actually learning the representations. Maybe they\\'re just built in.\" So, work that\\'s being done in AI now suggests that you might have built in constraints, inductive constraints that are like assumptions about how the world works, assumptions about how physics, or assumptions about how people work. And if we just build those in the first place, then you can help to solve the problem.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"So, those were the two options that were, and still are, on the table. And I think, those of us who actually look at young children learning, there are probably elements of both of those that are right, but it doesn't look like either of those is what's happening because from the time we can test--and this is where the great methological and experimental advances in developmental psychology kick in--even very little babies already seem to have these abstract, powerful representations of the\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"of the world. That's very different from what a previous generation thought about babies.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"But at the same time, even three and four-year-olds--this is work that we did back in the '80s--are really changing what they think about the world based on their experience. So, they seem to have abstract representations and be learning and changing those representations from the time they're very little.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And theory of mind, for example, which is something that people are thinking about in AI as well: that ability to understand what's going on in someone else's mind; that was the work that we did back in the '80s that I think really clearly showed that children have this succession of everyday theories of the world. And then, in the more recent work about causal inference, what we could show is not just that they will have an abstract theory and then another one based on the data, but we can\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='the data, but we can actually say something about what the representations look like and how the representations change.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:10:51] Sam Charrington: Does the theory-theory imply that children are taking an active role in recognizing that a theory is a theory and testing the bounds of that theory in experimentation?', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:11:03] Alison Gopnik: Yeah, exactly. So, that\\'s the thing that is the new work that we\\'re really doing now. So, we showed, over an extended period, that children could do this. They could get statistics, they could infer causal structure. And you might wonder, how on Earth could you do this with two-year-olds, right? I mean, if you asked most grownups, \"Does this pattern with conditional dependencies indicate a causal chain or a common effect?\" They would not know what you were talking', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='you were talking about.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"The way we did it is we have little machines. One of them is called the blicket detector, that you'll see in my talk. It's a little box that lights up when you put things on it, plays music sometimes and doesn't other times. So, it's a new causal system. And the kids' challenge is to figure out how it works, figure out which things are blickets--blickets will make it go--which things are blickets. And then, they have to make it go themselves. So, without actually asking about causal structure,\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"causal structure, we can see what kinds of inferences they're making and we can control what kind of data we give them. So, we can give them different patterns of data. And then, we can see what they do. We can see what kinds of inferences they make.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And as I said, to a remarkable degree, the kids are making the right kinds of inferences. If they were little Bayesian hypothesis testers--again, to get back to the theory-theory, you give them two hypotheses and they're picking the ones with the best posterior probability. But the big question is--so that's really impressive, but then, we still have this question about how are they doing that? What's happening that's letting them solve that problem? Because, of course, the big issue with\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"the big issue with Bayesian reasoning and with probabilistic generative models, in general, is if they're interesting at all, the search space is enormous. So, if you think about even a Bayes net with four or five causes, you very quickly have a very, very big space of possibilities. And the question is, how do you limit that? How do you search through that space? How do you solve that problem?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"An idea that we've had and a lot of people in AI have had now is that active learning--and to get back to your question--active learning, experimentation, that's the way that scientists solve that problem. You're not just stuck in your mainframe with data pouring over you; you can actually decide which kinds of data you want, depending on what kind of hypothesis you're testing.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='And for causal work, again, because of this intervention quality of causation, you can specify pretty clearly, \"Here\\'s the kind of experiment you should do. Here\\'s what you should do. Here\\'s how you should wiggle X to see if Y works.\" And if you think about little kids, that\\'s their entire life, right? It\\'s a kind of nice convergence.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"I just spent a sabbatical at Mila in Montral where Yoshua Bengio and his colleagues are doing fantastic work just about this question about causal inference and causal models. And at the same time, I was visiting my one-year-old grandson. And if you watch my one-year-old grandson, basically, all he does is do experiments. He will occasionally eat if his mom gives him some food. And other than that, what he's doing constantly is doing experiments. And what all the rest of us are doing is trying\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='are doing is trying to keep him from killing himself by doing experiments.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='And it\\'s funny, we just sort of take for granted, \"Oh, okay. Look, I\\'m looking at this one-year-old and look what he does. He takes the spoon and then he bangs it on the pot and then he turns the pot over and he sees if he can stick the spoon in the light socket,\" and so on and so forth. We just take that for granted. But why would they be doing that, right? I mean, that\\'s a lot of physical energy going on to just go out and try things in the world. But if you think of them as being these active', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"being these active causal inference engines, that's exactly what they should be doing.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"What we're doing now is we're in collaboration with some people at Mila and at Berkeley and actually at Google DeepMind as well; what we've done is to set up these environments in which you can find out about causal structure by doing experiments. We have our kind of virtual version of our blicket detector. And what we can do is see what do kids do when you just let them loose in this kind of environment? And how does that compare to various kinds of causal learning algorithms you might have?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"If you think about it like a classic RL algorithm, for example, it's not going to do the kinds of things that are the best experiments, because the classic RL algorithm is just going to try and find the outcome and maximize it. And what you need for experiments is to try lots of different things, change what you do based on what happened before. But some of the things--again, like my colleagues, Deepak Pathak and Pulkit Agrawal and others coming out of Berkeley have these curiosity-based\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='curiosity-based algorithms that seem to be closer to what the kids are doing.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And I think if you combine the curiosity-based idea, the idea that what you're trying to do is get a system that will make predictions and frustrate them and explore, and the causal model's idea, that could be a very powerful mechanism for solving some of these search problems.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:16:05] Sam Charrington: To what degree does your work begin to articulate, explore the structure or the complexity of causal relationships that children are able to deal with at various ages? And what does that tell us about our ML models?', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:16:22] Alison Gopnik: Yeah so, the first pass, both with Bayes nets and with our work was just pretty simple causal relationships. So, here\\'s one variable and another variable and does variable X cause variable Y? And you can see the experiments you\\'d do to try and find that out. And then, what what Pearl and Glymour and colleagues had done was to look at more complicated things like, \"Is it a causal chain or is it a common effect structure or common cause structure?\"', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"But starting sort of in the late '00s, we started collaborating with people like the cognitive scientist, Tom Griffiths, who's at, Princeton, Chris Lucas, who was a student of mine who is now an Edinburgh, to try and see if we could also make inferences about more abstract features of causal systems. So, for instance, could I infer not just is this blicket detector--did this block make the detector go or not? But is the detector deterministic or stochastic? Or does the detector work with\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='detector work with conjunctive logic? You need two things to make it go in combination. Or does it have a disjunctive logic? Each cause is separate.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And what we've shown is that kids are quite good at --even again, three and four-year-olds--are quite good at making inferences about those more abstract features of the system as well. And to get back to machine learning, the more abstract the representations are, the more powerful your generalizations are going to be. So, the kids seem to be quite good at even making those more abstract inferences. And something that's really interesting is that the kids are actually better at doing that than\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='at doing that than adults are.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:17:56] Sam Charrington: In what sense?', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:17:57] Alison Gopnik: Well, here's the thing--and this is another point about children and childhood in general. If you give the adult a structure that's really common, that they have a strong prior for, then they're good at making the inference. But how about if it's something that's kind of weird and unusual? So, it's an abstract feature that isn't as obvious and you don't have a stronger prior for. When you do that, the kids are actually better than the adults. And in a sense, the kids'\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"a sense, the kids' lack of knowledge, lack of previous knowledge is really an advantage when you want to explore the space more widely.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"I think that leads to another big point that I've made that I'll be making in my talk, which is that actually just being--this gets back to my one-year-old--just being a kid, just the fact that you have this period of childhood before adulthood, that in and of itself, may be something that humans use to solve this problem. And the argument that I've made is, again, think about that search problem. One of the reasons the search problem is so challenging is because there are always these\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='are always these explore/exploit trade-offs, right?', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"So, one of the things that we learned at the very beginning of computer science was that explore/ exploit trade-offs are a bear and there isn't any simple or optimal way of resolving them. But one idea that people often have is...when you look at the actual algorithms that are trying to deal with explore/exploit tensions is start out exploring, and in particular, start out with these very wide, high-temperature, bouncy, noisy kinds of searches that get through a whole bunch of the space. And\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"of the space. And then, once you've done that, narrow in and exploit. The idea is that that keeps you from getting stuck in local optima. It keeps you from settling on a particular option too quickly.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='And what I\\'ve argued is you could think about human life history, as they call it a biology, human development as being evolution\\'s way of...so, one of the ideas is often a simulated annealing kind of idea. So, you start out looking really widely with a really high temperature, and then you cool off. And my slogan is that childhood is evolution\\'s way of solving the explore/exploit tension and doing simulated annealing. So, if you say, \"Who looks like they\\'re bouncy and random and noisy and', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='random and noisy and trying lots of things that are not very effective versus who looks like they\\'re narrowing in using a lot of their prior knowledge to do something effectively?\" You\\'ll see the first, that\\'s what a one-year-old looks as opposed to what an adult looks like.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"So, part of the idea is that if we actually built in a developmental sequence, we let AIs be children for a while, we might also get some clues about how to learn more effectively. And this kind of trade-off that see where the children need a lot of care, they need a lot of people around them looking after them, but that gives them this chance to go out and explore, that might be a trade-off that's relevant for AI as well.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:20:56] Sam Charrington: So, one thought that brings to mind for me is in some ways, could you say that the natural machine learning cycle kind of resembles this childhood/adulthood, in the sense that training is like childhood, and inference, once the model is built and fixed, then that's kind of adulthood?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:21:19] Alison Gopnik: Something like that, I think, is right. Yeah, I think the idea is that you have a period of learning and then you have a period of actually using what you've learned to go out and make inferences. But the kind of learning that the children are doing seems to be much more wide-ranging than the kind of learning that a typical machine learning system is doing.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='And something that I think is really interesting is when you actually look at the practicalities and talk to people about, \"Well, how do you solve these explore/exploit problems?\" Annealing shows up again and again, and often in multiple cycles where you\\'ll heat things up, cool things down, heat things up, cool things down. But there isn\\'t a general theory about how to do that, as far as I can tell, or about why that works. And again, looking at the kids might give us some clues about how does', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='clues about how does annealing work in the wild when you see it in children?', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"One of the things that I think is really cool about this idea is if you think about explore/exploit tradeoffs, things that look like bugs from the exploit perspective might actually be features from the explore perspective. So, for instance, having a system that's noisy that has a lot of variability is not good if what you want is to make inferences and act effectively. But it is good if what you want is to be able to learn as much as possible.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"So, many of these things about kids that have seemed like defects, like the fact that they're curious all the time and that they're kind of unpredictable, that they are variable, that they're noisy. Those might actually be advantages from the perspective of learning. And I think we don't have a good theoretical account of how that all works. And thinking about the kids could help.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:22:58] Sam Charrington: What would you say are the closest ways that we're approximating that in the machine learning world? Reinforcement learning, some of the reinforcement learning techniques?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:23:08] Alison Gopnik: People like Yoshua Bengio and his colleagues and others are trying to now--and I think this is going to be the wave of the future, is to try and design hybrid systems that can use some of the power of machine learning, but then can also have some of the structure and generalization of a causal system. So, Yoshua has these flow nets that are trying to do that. They're trying to add a layer of further structure on top of classic machine learning system.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And RL is interesting from this perspective too, because you could argue that--and people have argued that reinforcement learning in the psychological sense is the most primitive form of causal learning. As opposed to just picking out correlations, what happens in reinforcement learning is that you do make an intervention and you see what the outcomes are. And it's important that you're actively going out and making interventions and seeing outcomes. But typically, in RL, the outcome of that\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"the outcome of that isn't a model, as much as just the fact that you're more likely to make those inferences or those policies later on. So, something like model-based RL ends up looking a lot like causal inference. It ends up looking a lot like causal structure. And that feels like that's a relevant outcome.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"But I think it's important that the objective functions for a system like that would have to be things like information gain or like knowledge or like curiosity, rather than being things like how well you're scoring on some measure. And there's really elegant work in our labs and others that show for instance, that if you look at the kids playing around, they seem to be acting in a way that will get them information. Then, information gain seems to be sort of an objective function that describes\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"that describes what it is that they're doing.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:24:59] Sam Charrington: What's an example of that?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:25:00] Alison Gopnik: Well, there's beautiful work by my colleague, Celeste Kidd. And she looked at really young babies, like 10-month-olds. And what they did was they showed the babies' different sequences of events that had different amounts of information in the technical information theoretic sense. And what they discovered was that there was this kind of sweet spot. They just measured how long the babies looked at each of these events and they discovered there was this sort of sweet\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"this sort of sweet spot. If something was too random, too far removed from where you were now, the babies wouldn't look, but they also wouldn't look at things that didn't give them very much new information. There was this kind of sweet spot of just where the information gain was going to really help you to make progress. And the babies looked the most at those events.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And we've been thinking about that too. One of the problems with just using information gain...this is something that comes up in a lot of these curiosity-based RL kind of algorithms, is what's called the TV problem. The problem is if you just use technical information gain, then if you just put someone in front of a TV with random static at it, you're getting lots of information in the information theoretic point, but you're not getting anything that's actually going to be very useful.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"So, I think one of the real interesting frontiers is this balance between noise and structure, right? So, the kids are noisy, but they're not just completely noisy. They're not just acting like random agents. They're doing things that make sense, given the kinds of problems they're trying to solve, the kinds of causal structures that they're trying to infer. And how you get that balance between introducing noisiness and variability, and then, also having interventions and experiments that are\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"experiments that are relevant to the problems you're trying to solve, that's something that kids seem to be really remarkably good at doing. And we don't quite know how to characterize that computationally.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:26:58] Sam Charrington: I had cut you off to ask a question earlier and you were about to mention some additional points from your talk. What were those?', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:27:06] Alison Gopnik: Yeah, what we've been doing now...one thing that we've been doing is looking at how children are using active learning to figure out the causal structure of the world in these online environments. Another thing that we're doing is trying to see if--I mentioned that we'd done work showing that children could get these more abstract--what are sometimes called over hypotheses about causal structure. But one thing that we're doing now is trying to see if kids can do things\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='kids can do things like actually decide what the right causal variables are.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='So, a big problem...it\\'s easy to say, \"Okay, look, I\\'ll tell you, here\\'s variable X and here\\'s variable Y,\" and then you can see whether they\\'re dependent and see if there\\'s a causal relationship between them. But how do you decide which variables to look at in the first place? And this is a big problem for ML as well, where it turns out that in classic adversarial examples for something like image net, it turns out, well, wait a minute, no, the system is actually not even dividing up the world', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"up the world in the right way. It's paying attention to fine details of the texture instead of paying attention to the objects. It might look as if it's making the right kinds of inferences, but it isn't really, because it just hasn't divided up the world in a way that makes sense from the perspective of different variables.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='If you\\'re a scientist, there\\'s all sorts of classic examples like it turns out that if you\\'re looking at the relationship between cholesterol and heart disease, \"Oh, there\\'s actually two different kinds of cholesterol. One of them makes heart disease more likely one of them doesn\\'t.\" So, if you didn\\'t have the right measures, if you just looked at cholesterol overall, you wouldn\\'t see the relationship. And then, it turns out that you can.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='And it turns out that kids are actually very good--we have some really beautiful experiments where kids are actually good at picking out, \"Oh, okay. This is the variable. This is the object. Or this is the property that is the one that I should be looking at for purposes of trying to do causal inference.\"\\n\\n[00:29:07] Sam Charrington: How would you', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:29:08] Alison Gopnik: Yeah. So, this is my brilliant graduate student, [Mary Algodoo]. So, what we do is we set up a situation where the kids have to figure out their little Shelley, the turtle wants to grow cactuses. He likes some cactuses. He likes the ones with round things on them, but not the spiky ones. And we're trying to decide how can we help him grow his cactuses? And there's two different things we can do. We could put the seeds in different colored flower pots, or we could have\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"or we could have different colored water accounts that are watering the seeds. And we're trying to figure out how do we make sure that Shelly gets the cactuses that he does?\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='So, we\\'ve set up, \"Here\\'s these two potential variables. It could be the watering cans. It could be the pots.\" And what we can show is that if we show children that the watering cans make a difference and the parts don\\'t, and now we give them a new case. This is a new cactus, a new watering can, a new pot, they\\'ll say, \"Okay, the watering can is the thing I should be paying attention to. I should be playing with that watering can, I should be changing it. We should be doing things to that', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='doing things to that watering can, because I\\'ve already figured out that the pot really isn\\'t relevant to these differences.\"', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='So, in philosophy, they talk about this as causality being difference-making; the causal thing is the thing that makes a difference. And the kids already seem to be saying, \"Okay, which things in my world are the things that make a difference? Which are the things that I can control and change and make a difference?\"', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='And again, if you think about an AI system, if it was paying attention to--think about RL. Part of the problem with RL is it\\'s just paying attention to everything in the image, right? And if it could say, \"Oh, no, these are the things that I should be varying.\" Think about the classic example where you see a robot being trained with RL and it\\'s doing all this ridiculous, stupid stuff that isn\\'t going to make any impact at all before it kind of stumbles on the thing that might work. If you could', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='work. If you could start out having that robot say, \"Oh, okay. I know these are the things that are going to make a difference and these things aren\\'t,\" it would be much better off. And if it could learn that, that would be even better.', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:31:22] Sam Charrington: Yeah, I'm curious. Does your research venture into the role of biases learned by children in the process of their exploration?\\n\\n[00:31:40] Alison Gopnik: Yeah, one of the things that I mentioned before is--in fact, some of the first work that I did was about the fact that children aren't just using these causal inferences to draw conclusions about blicket machines. They're using them a lot to draw inferences about other people.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"And actually, something that we haven't published yet, we're just in the middle of doing it.... For example, suppose kids see that there's a bunch of kids who are playing together. And kids who have a particular kind of funny glasses are being welcomed into the group and kids who have a funny hat are being shunned, for instance. So, they just would be seeing those patterns. Are they going to conclude that there's a difference between the people who have the glasses and the hats? That's a nice\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"hats? That's a nice example of variable selection, right? Kids start out not thinking that this difference is going to be important, but if they see that people are being treated differently, they might very well end up concluding--and in fact, we have some evidence that they do conclude that those are different groups. Those are people who should be treated differently, for example.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"So, I think it's quite plausible that part of what's happening is the kids are paying attention to these social differences and then, they end up having various kinds of biases as a result. And it's an interesting question about would it--it seems plausible that an AI might very well reproduce that and we might be worried about how we could counter that both for the children and for the AIs.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:33:26] Sam Charrington: So, what are the main takeaways that you want to leave the folks that are hearing your talk at the causal inference and machine learning workshop?', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:33:36] Alison Gopnik: I think there's two. One of them is...this may be a little preaching to the choir, is that causal inference is really important. It's a really powerful technique. Causal representations give us lots of advantages and we sort made some progress, computationally, on causal inferences and representations. That's exactly the technique we'd need to solve some of the limitations of our current systems.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='But then, in a way, the even more important idea is that looking at little kids--which is not something that typically, people in AI have done...that feels like, \"Oh, wait a minute. The world of people who are sitting in little chairs and playing with three-year-olds is completely different from the world of computer scientists.\" And I think it\\'s wonderful that computer scientists have realized, \"Oh, wait a minute. These little kids who we weren\\'t paying any attention to, we thought they were', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='we thought they were just...mushy stuff that wasn\\'t like what we do in AI. But those kids might really have the clue to designing new systems.\" I think that\\'s the really big point that I want to make. And I think back and forth, by looking at kids who are such great learners, we can figure out how to make more effective AI. But also, by looking at AI, we can figure out what\\'s going on in those kids\\' brains that makes them such effective learners. I think that\\'s really, really promising, exciting', metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"promising, exciting line of research and one that we're starting to do and I hope we'll continue to do.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:35:09] Sam Charrington: That's awesome. So, AI researchers, play with kids.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:35:12] Alison Gopnik: Exactly. I think this might be an example as well, where the diversity issues are really relevant, right? I think part of the reason, to be frank, why kids haven't played a bigger role in AI is because kids are kind of girl stuff, right? They're things that people who are off raising families are paying a lot of attention to. And either people who were doing AI and the people who are raising the families haven't necessarily been the same people. And I think it's a kind\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"I think it's a kind of tribute to the way that we have a much wider, more diverse group of people being involved in AI, including more women, more people who are raising families. That's a nice example where that actually turns out to contribute to something that's really basic to the science.\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content=\"[00:36:00] Sam Charrington: Yeah. Yeah. Awesome. Awesome. Well, Alison, thanks so much for joining us and sharing a bit about your talk and what you've been up to on the research front.\\n\\n[00:36:09] Alison Gopnik: That's great. Thanks for having\", metadata={'source': 'content/data/548 - Alison Gopnik.txt'}), Document(page_content='[00:00:00] Sam Charrington: Alright everyone, I am here with Luna Dong. Luna is a Senior Principal Scientist with Amazon, working on Product Knowledge Graphs. Luna, welcome to the TWIML AI Podcast.\\n\\n[00:00:11] Luna Dong: Thank you. Nice to meet you, Sam.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:00:13] Sam Charrington: It's great to meet you, and I'm looking forward to our chat. Let's get started by having you introduce yourself to our audience. Tell us a little bit about your background and how you came to work in machine learning.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:00:24] Luna Dong: Sure. Yeah. I\\'m Luna and I work for Amazon, and the question regarding how I came to machine learning, this is an interesting question, and that reminded me, my advisor, when I was a PhD student at UDaB, I often heard him saying, \"I\\'m from the AI community and I came to database down the back door.\" and then now, as you can imagine, I got my PhD from the database field, and that\\'s the field where I\\'m active for a long time, and then now, I\\'m coming to machine learning from', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='learning from the back door as well, so my advisor and I, we make a circle.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"Yeah. A little bit more about how I came to machine learning, so my PhD topic is about data integration. Basically, how we can seamlessly collect the data from many, many different data sources, and integrate them together, and then starting from 2012, so that's the time Google launched Knowledge Graph, and starting from then, Knowledge Graph has been a very popular concept, and big companies, universities, they put a lot of effort into it.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='If you think about a Knowledge Graph, you put all of the data, from different sources, and put it into this knowledge graph. Since then, I have been working on Knowledge Graph for the past, about nine years for now, and when you build a knowledge graph, you really need technology from all different fields.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='This includes natural language processing, so you need to understand texts. This includes image processing, you also want to get knowledge from images. This includes Data Mining, you want to mine the data from the text, from the graphs, and also, this includes, certainly, database. You want to integrate the data, you want to clean up the data, you want to have high quality data.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"In a sense, to build a great knowledge graph, you need all of the technologies, and that's how I came to machine learning field, because machine learning is the core for all of these fields.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:02:42] Sam Charrington: Interesting. When you describe the work you are doing on your PhD, it made me think of this challenge that we've been chasing after for the past, I don't know, 10, 20, maybe even more years, that I think of as like Enterprise Information Integration. We're going to create either--\\n\\n[00:02:59] Luna Dong: [inaudible].\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:03:00] Sam Charrington: Some layer on top of all of the data to make it more easily accessible, or some centralized thing that sits on top of all of the information within an organization. It's interesting to think of a knowledge graph as playing that role for many organizations.\\n\\n[00:03:19] Luna Dong: That's true.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:03:20] Sam Charrington: When you think of knowledge graphs, and in particular, product knowledge graphs, what are all of the things that go into making a robust knowledge graph?', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:03:31] Luna Dong: Yeah, this is a great question. Knowledge Graph is basically trying to mimic how human beings look at the real world. Before we are able to read and write, we already understand the real world. To the little kids, those are Mom, Daddy, doggy, my house, my home, that's another house, which is next to my house, and before any language thing, there are all of these entities, and the relationships between the entities, that's how human beings understand the real world, and the\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='real world, and the knowledge graph is trying to capture that.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"What is a good knowledge graph? It certainly describes all of the entities and the relationships, and then I would say there are three key features for a knowledge graph.\\n\\nThe first feature is, because it is entities and their relationships, it's structured data, so it is not just large paragraphs of texts. It describes the entities, the properties of the entities, the relationships between the entities. That's the first thing, it is structured.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"The second thing is it is really high-quality data. That means it's very rich data. You ideally want to know everything about the world, and it is clean data. There is no mistake, and you can fully trust a knowledge graph as an authority, and also it is canonicalised, so for me as an example, my official name is Xin Dong, and people know me by Luna, that doesn't matter, that's the same person.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"Over years, how I look might deform slightly, but that doesn't matter, that's the same person. I moved from company to companies for my job, that doesn't matter, that's still the same person. In the knowledge graph, there will be one entity who represent me, not five different entities, so it's canonicalised, so that's the second big feature for knowledge graph, it is rich, clean, and canonicalised high-quality data.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='The third one is the data are connected. You connect the data about business, about movies, about music, about universities, about products, you connect all of them into one single knowledge graph, and there, you know, \"Hey, this movie star and that song artist, that\\'s actually the same person.\" You know, \"This t-shirt, with Darth Vader, and that\\'s a character from that movie Star Wars\" and everything is connected, so we can reason about it, so that\\'s the third thing about knowledge graph, so', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"knowledge graph, so these are all important features to build a great knowledge graph, and because this is high criteria standard, that's also why we need to explore all different technologies, such that we can build a great knowledge graph.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:06:50] Sam Charrington: When you say high-quality and clean data, I think of curated, and that often has the connotation of human curation. I imagine that this is one of the areas where you might want to apply machine learning to improve your ability to deliver a knowledge graph, at least at the scale of a product database, or even a smaller one like movies and other types of knowledge graphs.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:07:17] Luna Dong: Yeah. That's a great point. There are so many products, and also there are so many entities in the world, actually, so just using product domain as an example, we have billions of products and every day, we will have changes to millions of products, and if we want to manually curate everything, it's just impossible, and also not to talk about individual products, let's have a guess how many different product types there are. It's not hundreds, it's not thousands, it is\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"not thousands, it is close to millions, depending on what is the granularity we want to model, and with all of this many different product types, each type has its unique product properties, and also so many different products, curation is impossible, so that's why machine learning plays a critical role to scale up.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:08:15] Sam Charrington: Is that curation element the only place where machine learning comes in, in constructing a knowledge graph, or are there other areas where you might want to use ML?', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:08:24] Luna Dong: Yeah, that's a good question. Curation is one place where machine learning plays an important role. Another important role is now we have this huge knowledge graph, how are we going to put them into real applications? We want to help people to easily search for the knowledge, and that's where search, natural language processing, all of this machine learning techniques' being critical.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"Certainly, we want to answer questions using our knowledge graph, that's where it is important, and also we want to use the structured reach knowledge to do recommendations, to also explain why we make such recommendations, and that's another place where machine learning plays an important role.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:09:15] Sam Charrington: Nice, so you talked a little bit about the high-level challenges of knowledge-based, particularly as it applies to products. Can we maybe take a step back and have you share a bit about Amazon's efforts to build out a product knowledge graph? How long has this been going on and what are some of the major steps and milestones along the way? Was the product in existence when you started at Amazon, or were you part of the team that helped create it?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:09:46] Luna Dong: I'm part of the team that initiated this effort, so I joined Amazon four years ago.\\n\\n[00:09:57] Sam Charrington: Okay?\\n\\n[00:09:57] Luna Dong: Four plus years, and that's the time we started this project. The effort is covering multiple different, you can consider it as areas of applications. Amazon is a huge company, and one kind of product knowledge graph we are building is media knowledge graph.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"Everything you can consider about like books, music, movies, and possibly even podcast, this is a media product, and that's where we apply some techniques to collect knowledge, and I will tell you what is unique about it, but before that, let me tell you another kind of products, that's retail products, and everything you put in the electronics, furniture, so the clothes, and what you put into your kitchen, your bathroom, those products, those are retail products, and that require a different\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"require a different set of techniques, and that in addition to all of this, web is a huge source of data of knowledge, and so one big pillar of this project is web knowledge extraction, and that's where we are able to get external information.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='For example, the information provided by the brand, brand websites, and so that\\'s another part of this project, \"How can we collect the data from the web?\" and they use that to support the knowledge, product knowledge graph, as well as help Alexa. Yeah, so let me say a little bit more why I separate media products and retail products.\\n\\n[00:11:51] Sam Charrington: Okay.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:11:51] Luna Dong: Although they are all products, but the data behind them are very different, and for media, the publishers for the music, the movies, the books, they are very well-trained and good at providing the meta information, so who is the director of this movie, who is the singer of this song, when is this movie released, what is the language, et cetera, et cetera, and there are a lot of decent information from different sources, and our job is to integrate the data from those', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"the data from those different sources, different publishers, and make them seamless, so I recall that this is also related to where I was from, I'm from the data integration community, database community.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"For retail, it is different. The retailers, they are not well-trained to generate all of this structured information. Instead, everything is in the product title, the product descriptions, and also a whole bunch of bullets. It's not a structured information, so for the retail products, we have one extra step where we need to pull the structured information out of the text, out of the images, and also we need to remove all of the noises that are provided for various reasons.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"That's why a retail product graph is giving us extra challenges.\\n\\n[00:13:24] Sam Charrington: Okay. You said what I was thinking and that information extraction, that's a rich domain of research and practice in and of itself, extracting information from, and particularly, unstructured sources like blocks of texts and images.\\n\\n[00:13:42] Luna Dong: Yes.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:13:43] Sam Charrington: It's an area that we've been working at for a long time. Are there synergies when you're looking at the problem in conjunction with the knowledge graph problem, or do you take off the shelf extraction techniques, and then apply them in a vacuum and then you have some bundle of structured information that you then integrate into your knowledge graph?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:14:05] Luna Dong: Sure, so this is a very nice question. In a sense, I would say, information extraction, at the very beginning, that's possibly 30 years ago, it started with extracting two kinds of information.\\n\\nOne is the S relationship, so for example, this person is an artist, things like that, and then another big set of information they are extracting is event information.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"From the news articles, what are the events, who, where, when, what, how, et cetera, and at the time when knowledge graph is getting popular in the industry, that's the time we see a boost for information extraction so in addition to that two kinds of set of information we extract, now, people are interested in extracting relationships between the entities.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"That's where people look at all of the articles, all of them, also something we call the semi-structured websites, for example, if you go to Rotten Tomato, you go to IMDb, you see the data is not big text, but data in some format, in the web pages, we call it semi-structured data.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='People start extracting information from those data sources, and they try to say, \"Hey, this is the relationship between this movie and this person, and this is a particular property of this product\", so it is helping each other in terms of how the two fields are growing.\\n\\n[00:15:57] Sam Charrington: When you\\'re taking on a new extraction project, are you also utilizing the existing knowledge graph to help you with the extraction, or are you extracting the information in a vacuum?', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:16:13] Luna Dong: We want to use as much existing knowledge as possible. When we extract the knowledge, we need to train models and the training data basically come from two sources. One source is certainly manual labels. It's very painful to manually label everything for different relationships, from different sources, and also for different entity types.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='Then naturally, another big source is existing knowledge. We call it seed knowledge and we apply weak learning. We use the seed knowledge to automatically generate the training data that will help us to train the model, and that is the most scalable way, because really just a manual manually collecting training data, this is very hard.\\n\\nOn the other hand, this is just like how human beings learn. The more you know, the faster you learn, and the more knowledgeable you will be.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:17:20] Sam Charrington: When you're talking about building a training dataset for this extraction problem, at what level of the problem are we talking about applying machine learning? For example, you've talked about extracting entities from texts, that's one that is a well-known problem, the named entity extraction. Likewise, we've talked about extracting text from images, I've seen some work on trying to extract structure data from webpages in a way that's more robust to those pages\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='to those pages changing than the usual X path or HTML parsing, are you applying machine learning into all of these or to a subset of them?', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:18:08] Luna Dong: Everything. Let me tell you the whole workflow.\\n\\n[00:18:12] Sam Charrington: Okay.\\n\\n[00:18:13] Luna Dong: We start with knowledge extraction where we extract the knowledge from product descriptions from the web, and for the web, it includes both texts and the semi-structured data, and also something called web tables. Basically you have tabular information, a table on your webpage, and for a product, we extracted from texts and from images.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='These are all like machine learning methods developed by an LP community developed from computer vision community, and after we extract all of the knowledge, we try to integrate them together.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"We tried to decide, as I mentioned, this Luna Dong, and that Xin Dong are the same person. We tried to decide, so is Director F and the director actually the same relationship, even though different websites, different data sources, college, differently, but that's the same relationship, so for this integration, we also use machine learning, and these are techniques developed by the database community, data mining community, as well as the NLP community.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='After that, we put everything together and we tried to decide if something is wrong, so we decided if something is wrong by looking for inconsistencies. For example, if most of the colors are like red, blue, et cetera, and then suddenly, we see something like a vanilla flavor, and we know, \"Hey, this is not a color\" so that\\'s one inconsistency. Another thing is we might look at the values from different products, neighborhood products. For example, for ice cream, and their flavor will mainly be', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"will mainly be chocolate, coffee, mint, vanilla, and then suddenly we see spicy, and if that's not from India, we will guess this is unlikely to be correct.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='We also look at inconsistency from different data sources, and I\\'m always amazed, how different data sources gave us different information about even something like a very popular, famous movie stars and singers, and we need to decide, \"Oh, was she born on February 28th or March 28th? Which one is the correct one?\" So that\\'s called data fusion, and all of this, again, is using techniques developed by the database community, the machine learning community for anomaly detection, for example, and', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='for example, and also from the data mining community as well, how to identify the inconsistent information and claim something is wrong and to remove it from the knowledge graph.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='One more thing for that is we learned embeddings, the representations for every entity and the relationship, that also helps us identify mistakes, and in addition, the embeddings can help us in downstream applications for search, for recommendation, and also for question answering, so that is a field by data mining community, by recommendation community, by the search and NLP communities, so you find machine learning plays an important role for every single step in this pipeline.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"I often joke with my colleagues, with my students, so our goal is to build the most authoritative and the richest knowledge graph, and we would apply whatever technologies, we will adjust it, we will invent new technologies to achieve that goal, and if mechanical engineering is the way to help us build this knowledge graph, we will learn that. But actually, it turns out machine learning is really the key technique to do this. It's not like one single technique, but it is machine learning\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='is machine learning technologies invented by many different fields.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:22:40] Sam Charrington: Sure. When you apply that last step where you're identifying anomalies or out of distribution data, however you want to think of it, does that then percolate up to a human-in-the-loop, or do you have automated resolution techniques for addressing that kind of anomaly?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:23:03] Luna Dong: Yeah,human-in-the-loop is always needed, and for the data business, human-in-the-loop is important because we really want very high quality of the data. For machine learning techniques, if our goal is something like 90% precision, so basically when we make 10 predictions, nine are correct, this is achievable still using machine learning.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='But the when we want to get to 99%, without human-in-the-loop, is almost impossible, so the question here is really, how to make a smart choice about where people will play a role, and where machine will play a role. Human beings can help in various ways. For example, they have to provide some menu annotations to help create the training data.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"Even if we applied a distance supervision, weak learning to collect the training data automatically, that data, still, regionally, oftentimes, comes from human input so in the product graph domain, a lot of data come originally from the retailers. That's one part, and later on, as we do train the model, make the predictions, we need humans-in-the-loop to tell us what is correct and what is incorrect, that's another big thing.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='Then in this process, From time to time, we need to check what is correct, what is concerning, and if there is any sort of domain knowledge, that can definitely speed it up, and certainly, at this moment, we are trying to apply AutoML as much as possible to reduce the human work.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='Talking about human-in-the-loop, one place I got most inspired by human-in-the-loop is in Amazon Fulfillment Center. It\\'s like a park, and there is a central system that will decide, \"Okay, I need to count the number of items in this bin for products\" \"I need to send this to those places so we can ship it out\" \"We need to double check whether something seems to be wrong here\" and it seems a central system knows everything about what in these to achieve, and it does the best to combine human', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='to combine human powers and the machine powers, and similarly, for machine learning system, eventually, it will be a seamless integration of human power and the machine power.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='We can best the leverage that machine intelligence and the human intelligence in the way that we can get the best knowledge.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:26:06] Sam Charrington: You mentioned when you talked about the very front-end of that process and pulling in the information from the web, is that targeted in the sense of you have some set of products and you have maybe a URL, a set of URLs where you know information about those products might exist and you're crawling those specifically, or do you start with a funnel applied to the big internet and identify pages that may be relevant broadly? How do you think about that funneling for that\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='funneling for that part of the process for a system at this scale?', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:26:43] Luna Dong: Yeah, so this is a huge question to ask, actually, because eventually, it is about how we balance the results, and also the resources we need. I can use product as a simple example, but the same idea may or may not apply to other domains. For products, the brand websites, manufacturer websites, they provide a lot of information, and then it makes a lot of sense to figure out what are the different brands for the products, major brands, especially, and then, what are the', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='then, what are the websites for this manufacturers and brands, and then do targeted crawling.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"But one could imagine, let's say if our goal is to collect all of the knowledge for music and for movies, if we only do targeted crawling, we might misinformation for torso and especially long tail music and the movies, so that's where targeted prowling may not be the best way.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:27:51] Sam Charrington: It sounds like there's another part of the process where you're just crawling the entire web, and then you've got to relate it to the existing knowledge graph to see if a given page is even relevant to something that you care about?\\n\\n[00:28:05] Luna Dong: Yeah. In a sense, yes, and that's also what Google does, because Google, in a sense, has access to the whole web, and it's a natural way to basically extract a knowledge from all of the websites.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:28:23] Sam Charrington: That suggests that targeted versus not isn\\'t really binary, right? You\\'ve got targeted--\\n\\n[00:28:28] Luna Dong: It\\'s not.\\n\\n[00:28:28] Sam Charrington: In the sense of \"I\\'ve got URLs associated with a product\" or another level higher, there\\'s \"I\\'ve got brands that are associated with a product at a level higher. I could just Google this product and see what comes back, and then crawl that.\\n\\n[00:28:42] Luna Dong: True.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:28:42] Sam Charrington: Then at the highest level, it's just crawl everything and then try to find relationships.\\n\\n[00:28:46] Luna Dong: Yeah. It's definitely not binary, so there are a lot of different factors to consider, and also, for different companies, it is also like a different position. Taking Google as an example, it has access to the whole web, and that's a little different for Amazon.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:29:08] Sam Charrington: You mentioned that you use embeddings, you create an embedding for the, and I'm not sure I'm being very precise here, either the product, the information that you get back, but at some point, you're applying embeddings, and the example that came into mind was your earlier example about the ice cream flavors,--\\n\\n[00:29:28] Luna Dong: yes.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:29:29] Sam Charrington: It prompted this idea of conditional embeddings, and is that a thing like, can you look at an embedding space and identify the distance of some set of flavors conditioned on ice cream.\\n\\n[00:29:43] Luna Dong: True.\\n\\n[00:29:44] Sam Charrington: Is that a thing? What does that--\\n\\n[00:29:46] Luna Dong: Exactly.\\n\\n[00:29:46] Sam Charrington: [Inaudible] than-- Okay.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:29:47] Luna Dong: Yeah. That\\'s very good insight. So basically, if we look at, I mean, spicy is a valid flavor, but we look at the products where spicy is a flavor, and we look at the type of those products,. It\\'s unlikely to be ice cream, and so when we learn the embeddings, it will capture all of this subtle relationship in a nice way but implicit way, so instead of saying, \"Hey, ice cream should not have this five different flavors\", the embedding will basically say, \"For the spicy', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='say, \"For the spicy flavor, it mainly applies to products of these types\" and that will help us to identify mistakes saying, \"Oh, this is a spicy ice cream. Some things seems to be wrong, or at least the neural\".', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:30:40] Sam Charrington: Yeah. I'm trying to think of how you create an embedding space that does that. Usually you would think of the embedding space is being characterized by chocolate, vanilla, strawberry being clustered here, American ice cream, Indian ice cream being someplace distant, but those will all be similar, and how do you create a space so that Indian ice cream and spicy are close, and the regular ice cream or American ice cream and it's flavor close?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:31:13] Luna Dong: I would say there are a lot of core technologies in this, and there is a domain for knowledge graph embedding, and the idea behind it is actually simple but useful, so we can look at the entity, relationship entity as a triple, so it could be considered as subject-predicate-object, or subject-verb-object, and then, when we put all of these triples together, and then look at all of the triples related to the spicy flavor, that's how we learned the embedding from those\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='embedding from those triples.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:31:56] Sam Charrington: Okay.\\n\\n[00:31:56] Luna Dong: A note to that, this embedding actually propagate, so when we look at all of the products that are related to this spicy flavor, the products itself already carry the information about their product types, so that's already encoded into their embedding, and then all of this things are propagated into this spicy flavor.\\n\\n[00:32:22] Sam Charrington: What's an example of a triple in this analogy that we're talking about with ice cream?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:32:28] Luna Dong: Yeah, so it is [some_product: {has: 'flavor, spicy'}].\\n\\n[00:32:33] Sam Charrington: Okay. Interesting. Yeah, it's more of a graph type of a metaphor, seems more intuitive for the kinds of relationship you're talking about relative to--\\n\\n[00:32:43] Luna Dong: I know.\\n\\n[00:32:43] Sam Charrington: Embedding.\\n\\n[00:32:44] Luna Dong: Yeah.\\n\\n[00:32:45] Sam Charrington: But it's interesting, all the different things that you can do with embeddings, including this.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:32:52] Luna Dong: Yes. Yeah. Recently, I would say in the past five years, this graph neural network has been getting a lot of attention and a lot of research, a lot of progress, and that's one of the most effective techniques for knowledge graph, because knowledge graph is a graph.\\n\\n[00:33:14] Sam Charrington: Yeah.\\n\\n[00:33:14] Luna Dong: Then, using all of this graph neural net, you will be able to learn embedding for every note in the graph, and then propagate the information.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:33:25] Sam Charrington: The graph that you're building, is this a research topic, do these power the Amazon.com that we go to today? Is it one knowledge graph for all of products, or is it some aggregation or ensemble even beneath the product level? How are these actualized within the Amazon business today?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:33:47] Luna Dong: Certainly, there are a lot of research and science investment going on that enables these techniques, but it's actually a production system, and we generate the structured knowledge for a lot of products, and we use that to support, I would say, three major kinds of applications.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='One is search, so as a simple example, if you search for shampoo, and then you might say, \"Okay, I want those products for male\", and then we have this search navigation and you could click a button to say \"I\\'m more interested in shampoos for male\", and so that\\'s for a search. It also helps us to understand the customer intent very well from the queries, and then try to match it to the essence.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='That\\'s the first type. The second type is recommendations, and using the knowledge, we can hopefully tell you, for example, \"This is a product that you are viewing, and here are all of the other products that are mostly similar, but have maybe slightly different things like the model is different, the memory is different, and there are more accessories, so on and so forth\", so recommendation is the second thing, both search and recommendation is a way to help people discover products.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='The next thing is more of a displaying information about the products, so now, for many, many products at Amazon, when you look at the detail page, you can see the structured information about particular properties of the products, and that is this structured knowledge.\\n\\nAlso, you can see comparison tables, and we are experimenting how we can generate better comparisons using the structured knowledge.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:35:51] Sam Charrington: Thinking about knowledge graphs and the things you're doing at large scale, how would you scale that down for someone who wanted to start exploring this area and maybe do something at the personal level, or the much, much smaller business than Amazon level?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:36:10] Luna Dong: Yeah, that's a great question. I think it's providing the tooling and generic technologies. Before I worked on the product domain, I didn't realize how different the product domain could be from the normal, like Google knowledge graph, Bing knowledge graph. Similarly, when people talk about medical information, biology, I also see their unique challenges. If we will be able to have a set of tools to help people to get knowledge for particular domains, that will help small\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='that will help small businesses.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"At this moment, the well-known knowledge graphs are mostly from big companies. I think, I'm hoping we will be able to develop is those services or tooling which will help small businesses to build their knowledge graphs, and in that domain, as I said, these generic techniques, that will be the key.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:37:26] Sam Charrington: Are there things that come to mind? When you describe a knowledge graph, a lot of what you think of in terms of relationships, you can start as simple as a relational database and relate different products or entities, and you've got different attributes and things like that, but there's certainly a lot of other things you might want to do.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"Is that the natural starting place, or are there knowledge graph tools for someone that wants to build the graph, not necessarily subscribe to someone else's graph?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:37:59] Luna Dong: I think there are, I would say, three levels. The first level is how to provide the technology to store the knowledge graph. As you said, relational database, it actually has exactly the same expressive power as graphs. In other words, anything that we can describe in the graph, we can store it in relational databases and the vice versa, and in addition, for AWS, there are all of this graph database tools as well, and so that's the first layer, how to store it.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='The second layer, I would say, is the tools to help people to really build their graph. For example, web extraction tools or these linkage tools. One, I have two different databases about movies, how do I know this two movies are the same movie, how do I know these two people are the same, and I see such tools at different levels.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='Some of them are provided from AWS as well, but we need to integrate them to be a big tool set that will cover all of the different techniques I mentioned in this knowledge graph pipeline.\\n\\n[00:39:20] Sam Charrington: Yeah.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:39:20] Luna Dong: I would say there is actually a third level. I think, at this moment, each company owns their own knowledge graph, and there is actually some common knowledge that belong to human beings, and that would be a good set to start with for building small, specialized knowledge graphs.\\n\\nIf one day we could have those knowledge as a service provided by different small business owners, small companies, that will be good as well.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:39:56] Sam Charrington: Are you aware of any efforts to standardize some interface between knowledge graphs, federated knowledge graphs, so that amazon's could hook into Googles, could hook into my little companies, and give one API to broader view of the world or not?\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:40:18] Luna Dong: Yeah. I'm aware of such efforts from the research community. I think there is one called open knowledge. I know a few people like from Schema.org, and this is possibly even getting funding from the government, about trying to hook up different knowledge graphs.\\n\\n[00:40:40] Sam Charrington: Yeah.\\n\\n[00:40:40] Luna Dong: I don't see that much of an appetite among the companies, and I mean, I can definitely understand the reason behind it.\\n\\n[00:40:50] Sam Charrington: Sure.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:40:51] Luna Dong: It's huge efforts to build such a knowledge graph.\\n\\n[00:40:54] Sam Charrington: Sure, and the data's valuable, and they're not sure they want to share it just yet.\\n\\n[00:40:58] Luna Dong: True.\\n\\n[00:40:58] Sam Charrington: Whatever goes into creating [Inaudible].\\n\\n[00:41:00] Luna Dong: Exactly, yeah. Data is valuable, and I mean, in a sense, we shouldn't get the data for free because otherwise, people wouldn't have the motivation to work on data.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content=\"[00:41:12] Sam Charrington: Well Luna, thanks so much for taking the time to share with us a bit about what you've been working on and talk about knowledge graphs.\\n\\n[00:41:20] Luna Dong: Thank you very much. I appreciate all of this insightful questions.\\n\\n[00:41:25] Sam Charrington: Thank you.\\n\\nAlright everyone, that's our show for today.\\n\\nTo learn more about today's guest, or the topics mentioned in this interview, visit TWIMLAI.com.\", metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='Of course, if you like what you hear on the podcast, please subscribe, rate, and review the show on your favorite podcatcher.\\n\\nThanks so much for listening, and catch you next time.', metadata={'source': 'content/data/457 - Luna Dong.txt'}), Document(page_content='[00:00:00] Interviewer: All right everyone. I am on the line with Abeba Birhane. Abeba is a PhD student at University College Dublin. Abeba, welcome to the TWIML AI podcast.\\n\\n[00:00:12] Ababa: Thank you so much for having me, Sam.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:00:15] Interviewer: Uh, I'm really excited about this conversation. We had an opportunity to meet in person, uh, after a long while interacting on Twitter at the most recent NeurIPS conference in particular, the Black in AI workshop where you not only presented your paper algorithmic injustices toward, uh, relational ethics, uh, but you won best paper there. And so I'm looking forward to digging into that and, uh, some other topics.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"But before we do that, I would love to hear you kind of share a little bit about your background. And I will mention for folks that are hearing the sirens in the background. While I mentioned that you are from University College Dublin, you happen to be in New York now at the AIES conference in association with AAAI. And, uh, as folks might know, it's hard to avoid sirens and construction in New York city. So, uh, just consider that background a mood- mood ambiance background sounds.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:01:22] Ababa: Thank you.\\n\\n[00:01:22] Interviewer: Uh, so [laughing] your background.\\n\\n[00:01:24] Ababa: Yes. Yes, yeah.\\n\\n[00:01:25] Interviewer: How did you get started working in AI ethics?', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:01:28] Ababa: So my background is, uh, in cognitive science and particularly, um, a part of cognitive science called embodied cognitive science, which is ... which has the roots, you know, uh, w- ... in cybernetics, in systems thinking. The idea is to focus on- on- on the, on the social, on the cultural, on the historical and kind of to view cognition in continuity with the world with- with historical backgrounds in all that in ... as opposed to, you know, your- your traditional approach to', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='approach to cognition. Which, uh, just trades cognition as something located in the brain or something formalizable, something that can be, uh, computed.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"So, yeah, so that's my background. Even, uh, during my masters I- I- I lean towards, you know, the- the AI side of, um, cognitive science. The more I, uh, delve into it, the more I ... much more attracted to- to- to the ethics side to, uh, you know, injustice to the social issues. And, uh, so the more the PhD goes on, the more I find myself in- in the- the- the ethics side.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:02:49] Interviewer: Was there a particular point that you realized that you were really excited about the ethics part in particular or did it just evolve for you?', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:02:59] Ababa: I think it just evolved. So when I started out, I ... at the end of my masters and as at the start of the PhD, my idea is that, you know, we have this new, relatively new school, uh, way of thinking, which is embodied cog side, which I quite like very much because it emphasizes, you know, ambiguity's and messiness and, uh, contingencies as opposed to, you know, drawing krill bou- ... krill ... clean boundaries. And, um, so the idea is yes, I like the idea of redefining\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='idea of redefining cognition as something relational, something inherently social and something that is continually impacted, and influenced by as a people in the technologies we use.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='So the technology aspect, the technology end was my interest. So, uh, initially the idea is yes, technology is ... constitutes aspect of, aspect of our cognition. You have the- the famous, um, 1998 thesis by Andy Clark and David Chalmers state standard mind where they claimed, you know, the iPhone is an extension of your mind. Uh, so you- you can think of it that way. And, um, I was kind of advancing the same line of thought, but the more I delved into it, the more I saw yes, uh, digital', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"saw yes, uh, digital technology whether it's, uh, you know, ubiquitous computing such as face recognition systems on the street, uh, or your phone, uh, whatever. Yes, it does impact and it does continually shape and reshape our cognition and what it means to exist in the world.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"But what became more and more clear to me is that not everybody's impacted equally. Eh, the more, um, privileged you are, the- the- the more in control of, uh, you are asked to, you know, what can influence you and, uh, what you can avoid. So that's where I become more and more involved with the ethics of, um, computation and its, its, uh, impact on cognition.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:05:23] Interviewer: The notion of privilege is something that flows throughout the work that you've presented at, uh, Black in AI, the algorithmic injustice is paper in this idea of this construct of relational ethics. What is relational ethics, and what are you getting at with it?\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:05:45] Ababa: Yeah. So relational ethics is actually not a new thing. Uh a lot of people have theorized about it and have written about it. But the- the way I'm approaching it, the way I'm using it is, uh, it's ... I guess it kind of Springs from, uh, this frustration that for many folk who talk about AI ethics or- or fairness or justice, uh, most of it comes down to, you know, constructing this needs formulation of fairness, or a mathematical calculation of, uh, who should be included and,\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='be included and, uh, who should be excluded, what kind of data do we need? That sort of stuff.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"So for me, relational ethics is kind of let's, let's, um, leave that for a little bit and let's zoom out and see the bigger picture. And instead of using technology to solve the problems that emerge from technology itself, so which- which means centering technology, let's instead center the people that are ... people, especially people that are disproportionally impacted by, you know, the- the limitations or the problems that arise with the development and implementation of technology.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"So, uh, there is a robust, uh, research in ... you can call it AI fairness or algorithmic justice. And the pattern is that the more you are at the, at the bottom of the intersectional level, that means the farther away from ... you are from, you know, your stereotypical white, cisgender domain. Uh, the more ... the- the bigger the negative impacts are on you, whether it's, uh, classification or categorization or whether, it's being, uh, scaled and scored for, uh, by hiring algorithms or looking\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='or looking for housing or anything like that.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"Uh, the- the more you move away from that stereotypical category, you know, the status quo, the more, the heavy the- the impact is on you. So the idea of relational ethics is kind of to- to- to think from that perspective, to- to take that as a starting point. So these are the groups, or these are the individuals that are, um, much more likely to be impacted. So in order to put them at- at advantage or in order to protect their welfare, what do we need to do? So that it's ... the idea is to\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='... the idea is to start from there and then ask further question, instead of, you know, saying, eh, here we have this technology, or we have these set of, uh, algorithms or calculations how do we, uh, apply them or how do we then use them to- to, you know, for a better or a fair outcome?', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:08:52] Interviewer: And sometimes the answer you at is that a particular technology shouldn't exist in a given form.\\n\\n[00:09:01] Ababa: Yeah.\\n\\n[00:09:02] Interviewer: Right?\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:09:02] Ababa: Exactly. Exactly. So I think one of the- the downsides of, um, obsessively working on and some matrices or some, uh, equations on fairness is that you forgot ... you forget to ask in the first place, do we ... should we even do this in the first place? And I think, uh, some people have articulated this really well. Uh, you can think of this in terms of the, you know, face recognition systems that are becoming very normalized in common, especially in the States.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='Do- do you feed your face recognition algorithm with, uh, diverse data in order so that it recognizes everybody equally or do you stop and think, do we actually need face recognition systems in the first place? Do you know what I mean?', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:09:57] Interviewer: Yeah, yeah. And that\\'s a question that, you know, honestly I have trouble with in a lot of ways because I think there are certainly problematic uses of facial recognition. But often the question is posed or the assertion is made that, you know, we shouldn\\'t use the technology or we should, you know, I guess, you know, it\\'s not uncommon to- to hear people kind of take this position of, \"Hey, we can\\'t put the genie back in the bottle.\"', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"And you know, I think on some levels I get that, that, you know, maybe that's a cop out, but in other ways it's like pragmatic. How do you balance the idealism that I think is probably core to the approach you're trying to take with, uh, pragmatism that recognizes what is already happening and- and the way technology tends to develop and evolve?\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:10:56] Ababa: I guess my, um, approach, at least in- in the paper I presented, uh, at NeurIPS is that, um, if your starting point really is the welfare of, uh, you know, the most disadvantaged, then I don't know how that- that clashes out with pragmatism or, uh, even with the- the whole idea of fairness, uh, because for most approaches to fairness, whether it's explicitly laid out or whether it's implicitly implied, the idea is, it's very utilitarian, uh, in a sense. You have-\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:11:37] Interviewer: Mm-hmm [affirmative].', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:11:38] Ababa: ... uh, you- you- you aspire to- to arrive at, you know, the- the greatest happiness for the greatest number of people. So, which really doesn't work for- for if you are, if you are from a disadvantaged group or if you are a minority because you will never ... you- you are not a ma- ... you are a minority, you are not a- a majority in the first place. So any solutions that aspire to please the majority will always have, uh, negative consequences and it just doesn't work.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"So that's, that's the- the struggle with, uh ... when you want to prioritize the needs in the welfare of the least privileged and, uh, on the other hand, some form of pragmatism or what's best for the majority or, you know, the- the greater ... the whole society. That's a tension that's probably ... that would always exist probably.\\n\\n[00:12:40] Interviewer: And so that's at the heart of the, this idea of relational. Uh, in a sense it's pragmatic relative to who?\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:12:49] Ababa: Exactly. But also you have other- other face recognition might still be still right. Still open to so much controversy. Uh, but you have other examples such as, uh, you know, Facebook recently got a patent for, um, socioeconomic group classification of their users.\\n\\n[00:13:12] Interviewer: Hmm, mm-hmm [affirmative].', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:13:13] Ababa: And, um, they haven't said much about how ... where they're going to apply it or how they are going to use it. But, you know, tools like that you can see it's, it's insidious and anything it's very, very unlikely. Anything positive or anything good will come out of it. Specially for users, for people, uh, whose socioeconomic, uh, status is, uh, you know, from- from, um, a really poor background. So that idea of, I guess relational ethics as- as well as questioning, do we need\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"do we need these tools in the first place. It's also thinking about, you know, the bigger picture of what automation, whether it's, uh, job applications or, uh, whether it's, uh, housing, or whether it's insurance, it's what it is, it's doing to- to society and, uh, what kind of values are we prioritizing and embracing in the process.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"So it's kind of thinking of ethics more of ... more as- as a habit, as kind of constantly thinking of what kind of society we want to live in as opposed to thinking of I have this piece of a tool or this piece of, piece of equipment and how do, how do I make it fair or how do I to [tweach 00:14:46] with it, or work it to- to find that balance.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:14:51] Interviewer: You mentioned earlier the, you know that a lot of fairness is thinking about data bias and accommodating for data bias. You know, setting aside the issue of whether the thing that you're trying to address, you know, as something that should be done at all that, you know, the issue of data bias is kind of just one small piece of the overall fairness puzzle. How do you think broadly about kind of the different aspects of AI fairness and AI ethics? Do you have a\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='Do you have a categorization or framework or, you know, way of thinking about it that you found helpful?', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:15:37] Ababa: Yeah, so thi- this is actually at the heart of the whole, uh, relational ethics trying to- to reframe the whole idea of what ethics is. So, because as you said, a lot of people working on AI ethics really are about, you know, whether it's explainability or calculating fairness or justice, it's really is usually lost in the fine grain details. So, um, it's not something implementable that I provide, but it's about kind of really zooming out and thinking, um, you know, what- what\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='you know, what- what are we doing? What are we prioritizing? How are we defining bias? How are we defining ethics? How are we approaching, um, these concepts in general?', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"And, um, one of the- the aspects that I've re- ... that as part of the paper that I emphasized is, I guess it's the nature, the inherent nature of machine learning, which is that we are continually predicting whether it's, uh, health issues, whether it's the socioeconomic issues, whether it's who is, who is going to be, you know, the best employee. It's all about making predictions based on whatever data we get our hands on.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='So the idea of relational thinking is kind of rethinking the whole idea of predicting, uh, as something we need to- to pause ... to stop and pause and think. Instead of continually predicting how about we- we kind of take it is the end first analyze, and think about the patterns that we are getting, trying to understand the- the reality and things as they are. A- as opposed to using whatever data we have as, uh, if it is for our prediction or as input into- into, uh, our- our predicting tool.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"So the ... one of the examples I give is, uh, Cathy O'Neil in weapons of mass destruction also mentions this is if you take, uh, algorithms used in- in policing in the Lego system, instead of say, reci- recidivism algorithms instead of, uh, striving to predict who is likely to reoffend or who is likely to commit crime or what area should be polished more.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"We use our tools or we- we develop our tools in a way that lend themselves for us to understand why are these group of, uh, these demographic or this group of people coming up as higher risks. What can we do? How do we rehabilitate say prisoners, instead of how do we catch them when they reoffend? So it's really switching mentality. It's thinking about how do we make the- the society or the better ... the world a better place. How do we, uh, help people get back on their foot, rather than how do\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='rather than how do we, you know, rather than playing your catch up, rather than how do we catch them again.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"But so thinking of, kind of prioritizing, understanding, you know, questioning, uh, why do we find these patterns that we are finding and how do we improve that really kind of aligns with this relational thinking I've been, I've been talking about as opposed to, you know, uh, creating and building these, uh, predictive tools.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:19:22] Interviewer: Yeah. And I thought it was interesting that there's multiple levels to this idea of prioritizing understanding. There's, you know, as individuals working in these areas, we should prioritize our understanding of the people involved in the- the scenarios, uh, that we're involved in and how the people are interacting and- and effected, in these various scenarios. But also you're also suggesting that we should prioritize, you know, the tools that we build to enhance our\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='build to enhance our understanding as opposed to, you know, just spitting out more and more predictions.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:20:01] Ababa: Yeah. Yeah, exactly. I haven't, I haven't yet seen many tools that aim to understand. So much of what I come across is always predictive tools. And I think prioritizing, understanding really will- will, contribute to, you know, the larger, great- greater- greatness of society. Again, this is not something you can formulate or you can, uh, come up with a set of, uh, steps that you can implement. It's-\\n\\n[00:20:34] Interviewer: Mm-hmm [affirmative].\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:20:34] Ababa: ... it's more of, uh, kind of changing your habits, de- developing a different set of habits. It's something you continually keep in the back of your mind. Uh, whether, uh, you are an ethicist, an engineer or a data scientist. Uh, so it's, it's, it's really, really zooming out in looking at the, the, the larger picture. Uh, but also it's, it's not to oppose that we should, uh, throw out all, uh, implementable tools, uh, we have, uh, on uh, whether it's fairness or- or, uh,\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='fairness or- or, uh, accountability or explaina- explainability.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"Um, it's just that we have to also look at the- the larger picture. And I guess another aspect of relational ethics is, uh, you might have these implementable tools ... You might have this set of tools to ... for, uh, to make your system, uh, better. Uh, but the idea is, if you think of these concepts such as, uh, fairness, uh, or- or ethics or even your own set of solutions as something that are continually changing. So this is at the, at the ... I guess this goes back to at the start I was\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='at the start I was talking about how the idea of embodied cognitive science, uh, uh, at its core, uh, comes from, uh, systems thinking and- and cybernetics in the social sciences.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"And at the, at the heart of it is that, uh, not only can you, uh, define a cognition in isolation from others or in, uh, in- in isolation from the tools you use or in isolation from the environment. Uh, it's also that, uh, whatever your definition of cognition or whatever your understanding of the person has to account for the nature of reality, which is that, uh, it's never stable. It's never fixable. It's constantly changing. So ... and it's very contextual.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='So, uh, you are some, a certain type of a personality at the moment with certain expected norms. Talking to me on the, on the, um, on here, but some other time in some different contexts, in some different environments you are also slightly different person. So the- the underlying idea is what- whatever concepts we are dealing with, whatever solutions we have, they cannot claim to- to finalize things. They cannot stabilize this continually moving nature of being. And whatever is ethical in this', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='is ethical in this context might not be ethical in other contexts.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"So I think relational ethics is, uh, helps you leave whatever solution you have somewhat partially open so that you can reiterate, so you can revise and change with whatever new evidence or new data comes up your way, uh, the next day or the next year. So at this treating of things as moving and changing really is fundamental. It's, it, uh, helps us realize our solution now is only for now within a limited context within unlimited, uh, you know, e- e- e environment. And, uh, I think that's a\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"uh, I think that's a really, uh, important thing we can, uh, all pay attention to.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:24:11] Interviewer: The example you gave a who is Sam in these different contexts makes me think a little bit about in linguistics, the idea of code switching. And I may speak in- in a particular way when I'm on the podcast and then when I'm at home, I may speak in a slightly different way. And when I'm out, you know, in the neighborhood I might sli- ... to speak in a slightly different way. And I haven't seen much in, you know, machine learning or NLP that tries to capture that or take, uh,\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='that or take, uh, account of that. Do you have some examples of ... well, examples of how you might envision machine learning systems, you know, if they were to follow-', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:24:54] Ababa: Yeah.\\n\\n[00:24:54] Interviewer: ... uh, this aspect of relational?\\n\\n[00:24:56] Ababa: Yeah. So this is, this is really difficult and, um, I guess at the heart of, um, a lot of, a lot of issues and- and ... So when- when you can assume things are stable and, uh, somewhat, you know, uh, you can grasp them with whatever tools or language you have, it's much easier to- to construct theories or to con-, to construct some sort of tool. Uh, which is why-\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:25:29] Interviewer: I mean the- the stability, uh, you know, translates, uh, the, you know, everything's coming from, uh, identical distribution, which is at the foundation of most of what we do in machine learning.\\n\\n[00:25:43] Ababa: Yeah. Again, I'm, I'm not really a computer scientist. I, as I said at the beginning, I'm a cognitive scientist-\\n\\n[00:25:49] Interviewer: Mm-hmm [affirmative].\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:25:50] Ababa: ... and I think about cognition in persons. And I don't know any, uh, NLP tools or, uh, machine learning approaches that account for, uh, this continual change and contexts. Uh, but also even within the cognitive science, uh, movement, especially embodied cognitive science, which is trying to push the importance of, uh, these, uh, change, uh, uh, you know, language and- and context is one of the things it struggles with is because it's difficult to formalize and, and- and- and\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='and, and- and- and make up ... uh, uh, provide something conclusive. But when you are underlying change, uh, it ends up dealing a lot of theorizing as opposed to producing something- something you can model or something you- you can, you can formalize.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"Uh so I guess it's, it's, um, an existing tension. Again, it's much better to think of it as a habit and to- to acknowledge this, uh, continual changing nature of things. Uh, in a sense that acknowledgement makes you aware that, uh, your tool or your solution or your theory is only as good as the- the ... it's the specification and the contexts. And, uh, and that's acknowledgment further encourages you to live, uh, not to conclude your- your solution or your tool as something finalizable that\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='finalizable that will, something that will be good all the times for all contexts, but something that you have to leave a little open, partially open, something that needs to revision continually.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:27:48] Interviewer: Mm-hmm [affirmative].\\n\\n[00:27:50] Ababa: So that's again, for me, uh, I ... what ... for me at the moment, the- the best one can do is, uh, acknowledge this, this change in context and- and, um, live this, eh, part openness and, uh, uh, embrace reiteration and- and revision.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:28:11] Interviewer: One of the other ideas in the paper is that there were ... or at least I, you know, I interpret it as that along the lines of the idea of prioritizing understanding over prediction. Uh, one of the ideas in the paper is that, you know, when we predict, it's often based on these very reductive, uh, labels that we're applying to things. The examples you gave are, you know, successful versus not, criminal versus not. And you kind of point out that that is inherently\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='that is inherently problematic, and in many cases.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:28:46] Ababa: Exactly. You can also look at a lot of algorithms within trying to categorize or identify gender identities. And I think that's one of the- the most obvious cases where the harm of doing so, the harm of categorization, uh, becomes very starkly clear. Uh, because usually stereotypically and in most societies you would categorize, uh, genders as a, as a, you know, uh, male or female. Sometimes you might have, uh, uh, bisexuals, uh, but as we know, gender identities are much more,\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"are much more, more than just those categories. And not only, uh, they are larger in number at that ... those categories. But we all know that they are fluid. As someone that was, um, bisexual or, uh, trans ... take a trans person, for example, uh, people change their, uh, sexuality in gender identities. How do you then ... it's then it's becomes easy to see how difficult it is for whatever algorithmic tools we're developing to- to account for that change.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"Uh, but also as we, uh, develop that tool and categori- ... kind of come up with these categories. In a sense, we are disadvantaging and excluding anybody that doesn't belong in those categories that we have created. This is where, again, the most vulnerable are, uh, you know, impacted the most. Yeah. So it's, it's, it's problematic in that regard.\\n\\n[00:30:37] Interviewer: I'm curious what kind of reaction you've seen to the paper.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:30:41] Ababa: So at NeurIPS, it was overwhelmingly positive. I- I, uh, it was my first time in NeurIPS and um, I went in thinking, \"Oh, this is, you know, a machine learning AI conference. I\\'m just, you know, the outlier cognitive scientists ethics/ethicist.\"\\n\\n[00:30:59] Interviewer: [laughs].', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='[00:31:00] Ababa: So I went in feeling I\\'m not going to fit very well. Uh, but it was really, really positive. And I was, I w- ... even when I was, when the announcement that, uh, my paper had won, the best paper, uh, came, I just ... I- I just could not believe it. You know, as- as a grad student, you go to conferences, you present a poster or whatever, and some parts of you sometimes, you know, deep down you think, \"Oh, I might win. You know, I might have a chance for a best poster or', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='for a best poster or something like that.\"', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:31:33] Interviewer: Mm-hmm [affirmative].\\n\\n[00:31:34] Ababa: Uh, but I went into NeurIPS, like, there is no chance. I'm just gonna relax-\\n\\n[00:31:38] Interviewer: [laughs].\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:31:38] Ababa: ... enjoy the dinner. It was a dinner party and I was really shocked. And, uh, so it's, it's been really positive. Uh, I have presented similar ideas previously to very exclusively kind of very, um, software engineer, um, machine learning, deep learning researchers, and people really are not interested in my ideas because people want something implementable, something they can code into- into, you know, something formal, something they can use. So what I'm asking is a\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"what I'm asking is a reframing, a rethinking and- and in a sense the changing of habits.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"And, uh, it's almost like an activism. It's like asking what kind of society do you wanna live in? So for some people, uh, that's really, um, difficult and something they would rather not get involved in. But the more I interact with people, uh but ... and also on Twitter, it's, it's, I'm really, really encouraging. People seem to, um, to like what I have to say. So I'm happy. [laughs].\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:32:52] Interviewer: Really quickly before we wind down, you are in New York to present a more recent paper, I believe it's more recent paper that you-\\n\\n[00:33:01] Ababa: Yeah.\\n\\n[00:33:01] Interviewer: ... have worked on, uh, on robot rights. Can you talk a little bit about that paper?\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:33:07] Ababa: Yes. It's unfortunate that the- the title has robots rights because it really is not about robots rights. [laughing]. Uh, it's robots rights? Uh, let's talk about human welfare instead. So this paper, I worked on it with my colleague, uh, [Yelly Vandyke 00:33:28] from University of Twente. Uh, he's also, uh, he- he also comes from a- a distributed cognition embodied cognitive science background. And we talk about this a lot on Twitter. And, uh, we are constantly getting caught\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"getting caught up in this Twitter debates whether, uh, you know, machines can be sentient or, uh, whether sh- ... robots should be given rights, blah, blah. It goes on, and it's the same kind of pattern of interactions over and over and over again.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"And, um, I think about five, four- four or five months ago, I asked him on Twitter, how about we write a paper on this? And, uh, writing the paper came really, really easy because we have the same background, we think alike, so the idea of the paper is ... it has, uh, in a sense, uh, it's two fold. Uh, the first one is kind of philosophical. Uh, so we lay out, uh, how robots are not the type of beings that can either be granted or denied rights. Uh, we lean on a lot of, uh, you know, embodied\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='you know, embodied cogsci as I was saying earlier, that this notion of cognition as inherently social, inherently relational. People inherently, you know, value Laden, constantly striving to make meaning of the world.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"Uh, so we use that post Cartesian, uh, approach to- to get at the heart of how philosophically speaking robots or any machine learning tools or any machines at all are not the same beings as humans or even animals. And- and then the se-, the second part, uh, where we get adds, the urgent questions that AI ethics really needs to focus because sometimes, not sometimes, most times it's really frustrating to hear, uh, robot ethics classified as part of AI ethics. And for me personally, it comes\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"personally, it comes across as worrying about future may happen, may not happen, may become sentient. Uh, a lot of it is really contemptate ... contemplation, uh, and- and thinking ahead about the future. And it's ... all that's contemplation and philosophy musing taking so much of the AI, takes the space is just unfair.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"So, um, a lot of the second part of our paper deals with how the very idea of AI itself, whether it's, you know, computer vision, whether it's autonomous systems, uh, it's never autonomous. There is always humans in the loop. And, uh, not only that, it's not possible without the- the exploitive human labor, uh, whether it's, uh, tagging road data for that's going to be part of, uh, an autonomous system or as some sort of image recognition. Even when you do, uh, recaptures, you are in a sense a\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='you are in a sense a kind of a being. You- you- you are putting in your own f- ... and labor into making machines better.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='Uh, so that the argument we made ... we make there is that AI systems are never autonomous and they never will be. Uh, but in- in the argument of whether they are autonomous or not, we lose sight of the people who are underpaid such as, you know, the mechanical Turk, uh, or micro workers. They are, they never enter into- into the debates.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"We also touch upon, uh, you know, how the robot system such as, you know, Roomba, uh, or whatever are invading private spaces as they roam around our houses and how that should be more, uh, urgent and crucial as opposed to some stereotypical, uh, humanoid such as Rob, uh, what's her name? Sophia. And uh, yeah. And we- we get a little bit on algorithmic injustice as well. How the, the least privileged, uh, the- the most disenfranchised are the most impacted and how that should be the focus of AI\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content='be the focus of AI ethics as opposed to, you know, hypothetical sentient beings.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:37:54] Interviewer: Hmm.\\n\\n[00:37:54] Ababa: So that's the, that's the core of the paper and yeah,\\n\\n[00:37:58] Interviewer: And there's been quite a bit of discussion about this one, uh, on Twitter. And in fact, we're not gonna be able to get into it very deeply, but I would encourage folks, uh, to take their reactions to Twitter. Is it fair to say that this one has been more controversial than the previous one?\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:38:15] Ababa: It- ii appears, it appears to be so. And, uh, to be honest, when we wrote it, we wrote it as ... Oh, when we have those never ending conversations about rights again on Twitter, instead of repeating the conversation, we'll just have a paper to point to. Uh, but it has, uh, provoked lot of very strong reaction from people both defending rights for robots in both, uh, thinking it's really idiotic, to ha- ... to even discuss a rights for robots.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:38:47] Interviewer: Mm-hmm [affirmative].\\n\\n[00:38:48] Ababa: Uh, so apparently it's controversial. [laughs].\\n\\n[00:38:51] Interviewer: Interesting. People love their robots, I guess.\\n\\n[00:38:57] Ababa: Yeah, I guess. [laughing]. Yeah.\\n\\n[00:38:59] Interviewer: Well, Abeba, it has been so great to have a chance to chat with you in more detail about what you're up to. Thanks so much for taking the time to share with us.\\n\\n[00:39:09] Ababa: Thank you so much. Uh, it's been great. Thank you.\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: Welcome to the TWIML AI Podcast. I'm your host, Sam Charrington. Thanks so much for joining us. If this is your first time, I invite you to hit subscribe in Apple podcasts, Spotify, YouTube, or wherever else you might be listening to this.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"All right, everyone, it's time for us to explore the best of machine learning in our annual AI rewind 2021 series. Today I have the pleasure of being joined by Georgia Gkioxari. Georgia is a Research Scientist at Metta AI, and we're here to talk about all things computer vision.\\n\\nGeorgia first joined us on the show last year for episode 408 where we talked about her work with PyTorch 3D. Georgia, it is so wonderful to see you again and welcome back to the TWIML AI Podcast.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:01:03] Georgia Gkioxari: Thank you. Thank you for having me again. It's an exciting episode and I'm glad to be back for it. So Sam said I'm a Research Scientist at Facebook, AI research, and I work on a lot of things on computer vision. with a focus and a passion for recognition. I feel that we're going to cover a lot of that today and see what exciting work has happened in the last year and what is a headless.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:01:29] Sam Charrington: Awesome. Awesome. Well, this year has been a big year for the company that you work at. It's not Facebook anymore. It's Metta. So there's that. It's been a big year for computer vision as well. Looking forward to digging into that. I figured we would start by just talking a little bit about broad brush strokes. What's your feel for how we did in 2021 with computer vision? What were the main accomplishments and sentiments in the field?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:02:02] Georgia Gkioxari: Yeah. I mean, this is a fantastic question, first of all, and of course subjective. So I'm going to try to give my input and discuss exactly why I'm mentioning these works. But as you said, Sam, it's been, I think, a very good year with exciting new work. New work that has actually been very impactful in that it shifted the field in many directions. So I'm going to mention maybe three highlights that I have noticed being extremely important in the last year.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"First I'm going to start perhaps with graphics, which is not exactly within computer vision, but very nicely tied to it. The explosion of NeRFs. So NeRF, which stands for neural radiance fields, have had a tremendous impact in computer vision, 3D and graphics. It's a wonderful work, simple that has unlocked something that graphics people have actually been working for quite a while. The innovation there has been a lot with introducing implicit functions and volumetric rendering. The goal is to\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"The goal is to reconstruct for realistically a scene from a few images. Well, a few is actually a little under estimated. It's like it's actually a hundred or 200 images, so it's still a lot of images, but the effect is that you can put a realistically... synthesize the scene from any viewpoint given this 200 images.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:03:34] Sam Charrington: I just wanted to jump in and make sure I'm understanding that the idea is that you've got some 3D scene and you're not building it up from a CAD system or a graphics tool or something like that. Rather you collect just pictures of the scene from various angles and through the NeRF process, you're able to create a 3D model of the scene?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:03:57] Georgia Gkioxari: So let's say you have a scene with say your room right there. So what you will do is that you will go around and collect many images. It actually works well when it's 360 view.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So let's say you have a little scene at the center of the room and you just take pictures around it. Of course, it's going to be your own picture. So they're going to be from discreet set of viewpoints. So what NeRF will do is that it will take these images. It will try to extract the camera poses. This is going to happen offline. So with the systems I call map, which has now been very well established and having posed images of that scene, it will try to reconstruct a 3D representation. Now\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"representation. Now that 3D representation is not explicit. So you can't really, it's not a mesh or a voxel. It's an implicit representation.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='All it does is that it allows you to shoot rays and then project those rays back from a novel viewpoint. So now you are building the system that cannot only understand the scene from the discrete viewpoints that you collected with your photo, with your camera, but it will allow you to reconstruct the scene from novel viewpoints outside of the existing ones. It does that by maintaining the photo realism and the detail of the scene that you are capturing.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:05:15] Sam Charrington: So the 'N' in NeRF is for 'neural'. Is it a deep learning based technique?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:05:22] Georgia Gkioxari: Yeah. So the authors there use a sequence of linear, like actually perceptive. So it's an NLP. So you have a little neural network that maps a 3D point XYZ and a direction to color RGB and density. The density is the occupancy basically whether we know that point is occupied by the scene or not, or it's empty space. So this is all that it's doing. With this information, you're able to collect that on a ray. So a ray is a collection of 3D points and render that from a\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='render that from a novel viewpoint.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:05:57] Sam Charrington: Got it. So is this the technique that originated it this past year in 2021, or is it a technique that found its voice from prior years?', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:06:07] Georgia Gkioxari: Yeah. So I think that the work came out in 2020. Of course, this is something that we need all to realize that that thing actually comes to life out of nowhere. So, of course, it's based on previous work. Of course, it's motivated by previous works. I think that with this work has actually innovated as this, this using this implicit functions along with volumetric rendering.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='It has since actually created a huge impact because of course it was the first paper came 2020, but there is a lot of things to fix. How can you do those with fewer views? How can you do this faster? How can you do this way by consuming less memory? So it has actually created a lot of followup works and step-by-step improving this method, even as we speak. Like tons of papers coming out, even on a daily basis.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:06:58] Sam Charrington: Are we seeing its impact primarily in terms of academic papers or is it something that we've already seen implemented in different applications?\\n\\n[00:07:09] Georgia Gkioxari: So I think for now, I definitely believe that it is mostly focused on for research, especially while the community tries to improve it, make it more user-friendly, but also have a consumer's memory or [aim] faster.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"But I do believe that we will see NeRF will revolutionize the rendering. So any applications that now involved rendering, I believe will move into NeRF very fast. I'm talking about Hollywood - visual effects, making movies. I'm talking about the gaming industry, like video games. I think they will also move towards something like a neural representation for rendering. The reason for that is I think very simple. So the method is simple. It does require a little bit of our expertise. So we might\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='So we might actually see a shift of what knowledge you will need in order to make this happen. But it is a lot easier to adapt to your scene, so you need to do less work if you want to move to different scenes faster.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='So I do think that it will actually have a tremendous impact, not now, but in five years, maybe if we do this podcast again, we can revisit that question.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:08:18] Sam Charrington: When I think of rendering, one of the things that I think about is in the case of games like rendering, like from light sources and things like that. Is the idea that this NeRF method solves this particular problem of reconstructing the scene from images or that techniques that were developed for that problem also have implication and the broader, more broadly in graphics and in rendering like point source rendering, that kind of thing.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:08:48] Georgia Gkioxari: I think they do. I think they definitely are. Actually we're seeing the impact of NeRF expanding very much so that initial application though, we've seen and we're now seeing how they can incorporate even dynamic scenes like moving scenes. We are also seeing how to change lighting, how to change materials. We're also seeing how you can hallucinate with them. The field is ever expanding. This is why it's an exciting field to be in.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I'm sure graphics people are very thrilled because there's a lot of work to do so, yeah. I feel that we haven't even seen the full impact of NeRF yet and what they can do. What we know is the representation is powerful. We know the volumetric rendering is impactful. The combination of these two areas I think will lead to a lot more.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:09:32] Sam Charrington: Awesome. So that is an innovation happening on the graphics side. I think your next point is maybe closer to home for machine learning and computer vision. It's a big one that has a lot of people talking and it involves transformers, not the robots, of course, but the transformer networks that we all know and love.\\n\\nWhat are you seeing there?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:09:57] Georgia Gkioxari: Yeah. I mean, this has definitely been a highlight for 2021 computer vision. We have seen transformers have finally coming into computer vision. Transformers is actually not a natural language processing NLP. Researchers have been working with transformers for a few years now but they have finally made it into computer vision.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"It has been an exciting times because we now or seeing this line of work where we are slowly replacing the CNNs with transformers and for various recognition tasks. In particular, we've also seen what is exciting about transformers of computer vision is their impact when it comes to working with extremely large scale data.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So it's still quite unknown to us. So their transformers work well in the low data regime. This is something that is, the answer is not out yet, but we definitely know that for large data. We're talking hundreds of millions of images and more transformers are quite impacted.\\n\\n[00:10:55] Sam Charrington: Is the idea that transformers can create more robust representations based on lots of data than convolutional networks?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:11:04] Georgia Gkioxari: Yes. So again, we don't quite know in like theory behind these things, it's always unclear, but the main highlight is that so CNNs, which is the predominant sort of tools that we used before to represent our visual inputs, how to inductive biases. This comes from exactly the structure of convolutions and the image grid.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='Now transformers take a completely different approach. They actually treat images like a sequence of tokens. So this can be patches of images. So like small neighborhoods off the image, and the only inductive bias that comes into transformers is through. Serialization, as you would say the image and the pose embedding that comes in when we are processing these inputs.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"But other than that, everything, all operations are global with our attention's being cast into these are presentations. So there is no other inductive devices in these networks whatsoever. So that means that they have the potential to be a lot more powerful because you're constraining them. But in order to achieve that you need more data.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So it has a much closer to actually having a true functional approximators like we, you know what we say, like MLP is, are great function approximators but with CNN's that was a little bit taken away because of that particular structure, not transformers are bringing this back to life, which is exciting, exciting, and has proven also to work for images.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:12:31] Sam Charrington: How would you characterize where we are? Are we in just demonstrating that it's possible to make it work stage or have transformers in computer vision demonstrated state-of-the-art results or better results on known tasks or tasks that we were doing pretty well on, or allowing us to perform tasks that we weren't able to perform while with CNN?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:13:00] Georgia Gkioxari: I love that question and I hope that my answer's not going to anger people, but it's a great question. I wish we asked that actually more often. So before I answer that, I'm just going to go a little bit to the NLP world and say why I think transformers have had tremendous success. I think it's partly due to two reasons.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"First is that in NLP, you can actually get a lot of data and that's what works. Like bird have shown where you can crawl the web and you get all sources of text data. There's a lot of that out there. Now you show how it can be anything, any texts whatsoever, whatever content and you feed that to the beast called transformers and it builds our presentation. So that's fantastic, and a first grade milestone.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='Then the second one is that they have all these fantastic tasks, diverse tasks, like question-answer, and text generation. Their tasks are endless and they are very different from each other. They have shown that even in those very diverse tasks, having a global representation coming from self-supervised learning with a lot of data helps all of these tests significantly.\\n\\nNow Nvision in computer vision, things are not quite like that.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:14:15] Sam Charrington: Folks that follow computer vision probably have a sense for where this is going.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:14:20] Georgia Gkioxari: Correct. So, we are in an awkward phase where we want us to replicate that line of work from NLP. We're very much inspired and looking up to them, but we don't have exactly... First of all, we don't have a big data set. Our biggest data set is something like, I'm talking about public data set here. Some like ImageNet, which is 1 million images and imagery has been a fantastic data to serve the community for 10 years. But the problem with ImageNet is that first of\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"is that first of all, it's been around for quite a while. It's a frozen data set, so nothing changes. So as we develop new ideas on a data set that is constant and frozen in time, we tend to.. Sometimes our ideas overfitting on that data set. A lot of the gains that we see in images are actually transfer. That makes sense. We've been dealing with this data for a while.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Now. I would actually say that maybe we've trained more models on pixels on ImageNet but I'm not going to get there. Then the other question, of course, is what are our downstream tasks that we're showing that performance in? This is another sore point for us. Computer vision people, we're also seeing a little bit of sad state where we know we have our object detection and maybe our segmentation, but they're all essentially classification tasks. We don't have the richness in output and in task\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"output and in task the NLP has. Our pre-training classification, our downstream tasks classification. So it's really hard to tell if we're actually making progress or not. So this is something I think that is for the community to think about.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:15:55] Sam Charrington: I guess a couple of reactions to that. One is maybe the second one informs the first but there's classification. But then is the idea that all of the complex problems that we think of like no bounding boxes and all these other things just boil down to classification. So at the end of the day, it's all classification, even if it looks more complex.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:16:20] Georgia Gkioxari: Correct. That's absolutely true. Our most complex tasks, I would say maybe as object texture, because it involves you're predicting intermedia boxes. Then on top of that, you want to predict, classify the object type, or maybe predict other 2D properties by classifying the pixels within those boxes. But even that is [classed] as a classification problem.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:16:40] Sam Charrington: What about things like VQA - visual question answering? Is that more, do you think of that more of an NLP task than a vision task or...?', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:16:49] Georgia Gkioxari: Yeah, it's again, I'm clear. The only thing I have to say there is that, and this was also a point made by collect a great paper that came out last year is that even there, the data sets are very small and we really can't tell how effective these methods are because we really don't have a good sense of these tasks.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I mentioned CLIP, which is a prime example that showed that all the gains for transformers came when they download it, that huge data set of there's like, I think it was 250 million image text pairs. We don't exactly know the source where the data set is from, but we know it's from the web and they were only able to show that amazing property of capturing jointly images and texts when training on such a huge data set.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So this is what we aspire to get to. Training on such large images. Of course, that comes with a lot of other questions about, are we doing our due diligence and making sure that this is a good data set in terms of ethics, in terms of content? Are we making sure that it's a unbiased data set? and so forth, which brings of course new challenges, but I feel we need to move to that scale or otherwise we're going to be stuck in our little ImageNet standard regime, which is not a good state to be in.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:18:07] Sam Charrington: Yeah. Yeah. I think the data set side of that was my second question and that was we hear about and see new image, data sets, all the time. They tend to be specialized and fairly small. On the other side, just like NLP had access to the web; vision has access to the web.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='There are tons of images on the web. Do you think that in order to get beyond ImageNet and classification, we need to define unsupervised problems or semi-supervised problems beyond just simple label, supervised learning types of arms. Is that the big one of the big barriers?', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:18:49] Georgia Gkioxari: Yeah, I think that's definitely one big barrier. The problem with vision and actually with all data sensors that collecting a large scale data to back crawling the web and just releasing it is almost impossible. Maybe for a good reason, as in you have to make sure that you have consent from the creators of the images to actually release them. You also want to make sure that we are now entering the stage within AI where it's no longer opportunistic. We need to be very\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"We need to be very cognizant of the data. So we're using the models we're putting out there. Maybe they can have potential harm.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"These are all aspects of our work and we're responsible for it. It's not like someone else is responsible. So there is actually collecting and releasing a large dataset. It's a huge responsibility that comes in a lot of work, and that might be a roadblock to seeing larger data sets coming out.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I don't have a solution to that problem, but I feel that if there is motivation to go there, I think we'll make that happen. I think that we also need, and this is maybe my own personal opinion, we need to rethink the problem that we're solving. These pretext tasks that are commonly referred to as the task that you try to solve either in self supervised learning for example, in Burt, it was masking words and filling them in. We've seen recently a work from actually my lab and coming and\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"lab and coming and colleagues where they do the same thing, but they mask out patches of the image and they try to fill them in. This is a great task, but it is still constrained to be on predicting pixels. We need to enrich these pretexts tasks if we want to maybe solve for richer tasks, downstream tasks, moving beyond classification. I don't think that having a simple pretext task will solve complicated tasks down the line. Like maybe 3D reasoning or 3D understanding, which is a field that\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"is a field that I've been working on.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I do think that there is limitation and transferring that. So we need to account for that. So I think it's a good first step. I think that we just need to broaden our horizons a little bit in what problems are solving, how are we solving on, how are we thinking about building our presentations, either self supervised learning or through supervised learning with labels. Move out of this image to single object label, let's say, and here's where CLIP was fantastic because that's exactly the point\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"exactly the point where text is richer, contains richer information than just a label. That's what they showed. They showed that that creates a great representation if you're trying to jointly capture text with images.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:21:25] Sam Charrington: Yeah. Why don't you take a few moments to more deeply introduce CLIP and why you think it was so exciting?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:21:31] Georgia Gkioxari: Oh, sure. Yeah, absolutely. CLIP is this work from the open AI team and basically their premise that there's a lot of technical content that, I will not maybe will not spend time describing here, but big picture is that they want it to build a presentation, a richer presentation, moving beyond your classical images to object labels type of training to get to those representations.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='So they know that text contains a lot of information and they also know that images are important visual descriptors of these texts. So it makes sense to combine them and build a joinder presentation and see what you can learn by reasoning about these two different modalities together. So that was the first innovation, just thinking along those lines of pairing images with [richer] descriptors, not just single words.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Then the second innovation is that they did this by optimizing by contrastive learning, instead of prediction. One way to do this is to build a presentation where you're taking an image, we'll send part and maybe predict the sentence or output. We know that has been how things have been done predominantly in the field but there is difficulty there because the task is actually difficult and predicting in order for you to predict the right sentences, you need a big capacity model. So what is a lot\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So what is a lot more friendly? It turns out also friendly for optimization and robust is to actually embed these two modalities, the sentence and the image, and embed them with separate neural networks. Then train them so that the embeddings of the sentence of the image actually are close. So by minimizing a similarity, I think in this case, I think they use the co-sign similarity, if I'm not mistaken.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"The pair, the sentence and the image that correspond together should be close in that embedding space. Any other pairs coming from the whole dataset should be far in the embedding space. So this is what they did. Of course there's a lot of technical details on how to make that work, how to train that. Of course there's the corpus is huge. Then they showed that you can actually get really richer presentations through this way. This is why it's exciting for a person like me, even though I'm not an\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"though I'm not an NLP, is that it shows exactly that though we need to move beyond our single label regime into richer, either richer outputs or either in text scripture space or maybe also in 3D space. That's another modality that I think is important to start thinking about. I actually think that after, well, I would say the CLIP is definitely my favorite paper of the last two years.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:24:18] Sam Charrington: Oh, wow. So far CLIP and NeRF there's sounds like several papers that have evolved the NeRF method or some of the other favorite papers in vision this year?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:24:34] Georgia Gkioxari: I feel that. I want to say that I have enjoyed a lot of the followup work after clip. I'm going to mention this awesome paper that came out recently from Breonna Hanukkah. If I'm pronouncing her name right from Chicago, where she is trying to, if the team there they're using the Clippers presentation and they're trying to build 3D models with texture that look like the sentence.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"For example, like I think they have lawyer as one potential like sentence. Then they transform a human mesh to look like a lawyer, like a mean face. I call it like a suit wearing. So that was like a really, I have enjoyed seeing all these fun applications coming up after a clip that just it's not just about benchmark and we're not beating numbers, but fun things that you can do with these representations.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Then of course, I think that a highlight in computer vision beyond that was are definitely the transformers like world of ViT, which was the first approach to make transformers work for images, swin transformers from Microsoft that showed how you can actually go beyond ImageNet and make that work for other computer vision tasks where the innovation there is they're trying to do things at multiple scales and multiple resolutions in order to capture the variety of the objects in images. I think\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='in images. I think that I would highlight these works. Yeah.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:26:02] Sam Charrington: You mentioned this analogy to the Burt task, Maurier that close completion and texts.\\n\\nAnd you mentioned patch, completion and images. Is that the fundamental premise of the way that transformers are being applied and computer vision? Is that what the ViT papers about?', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:26:28] Georgia Gkioxari: So the ViT paper is a purely supervised approach. So you know where you are, you're taking an image, you're breaking it down into 16 or 16 patches. Then you feed that through a transformer network, a transformer network, an encoder purely to get to clot for classification. So it's supervised like on ImageNet or bigger. I think they also showed results in their internal Google data set, but it's for classification supervised learning.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='We have also seen a lot of use of transformers for self supervise learning. This is where the patch completion comes in that I mentioned. This is how to use transformers for supervised learning, which is actually a big topic in computer vision today. So these are the two modes.\\n\\n[00:27:13] Sam Charrington: Got it. Got it. Got it. Got it.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"You mentioned that the way folks we're evolving that we started with those initial paper that demonstrated that the transformers could work and envision, and there've been subsequent papers. Is there a clear next thing that has to happen in order for it to be the breakout success that it was in NLP, or is it more, just lots of problems and the community rallying around those problems and making progress paper by paper.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I'm going to come out and say it. I think we need to rethink everything that we're doing. Yes. I think that it will entail us breaking away from boring regime or add with ImageNet. We need to move beyond that. We need to stop worrying less. I'm sick of seeing papers that aren't just table after table after table with one percentage point of performance. Sorry, I don't want to be like bitter or mean, but who cares to some degree, right?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I mean, benchmarks are not there for us to beat them to death and burn TPU hours, and melt the ice and Antarctic in order to get 1% on them, like on these data sets. Benchmarks are there for us to test ideas quickly, see if they work and then move beyond that. So I think we'll need to break out of that desire that we have to produce more papers with more tables and more numbers that are not substantial. I would need to rethink a lot. We need to be more creative in what we're solving, how are we\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"solving, how are we solving it? How we're using these data sets? Even simple data sets with single labels can be used in very creative ways.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Of course we need to also move beyond that. I think video is a fantastic data source that we need to start exploring better. Video right now, computer vision is predominantly used for classification. Isn't that bizarre, like video. So you're taking this video that has so much information that there's so many things going on and you say running, it's so sad.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"There's more things to it, and we need to start flooring it's right there and it's right in the pixel. We have, we know maybe we have ideas, how to do it. It might take a little longer together and not meet the next CBPR deadline. But I do think that we need to rethink, reevaluate and maybe get more creative in how we're working with these datasets.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"It's interesting that this dataset that has in so many ways embodied the success and the moment that we're experiencing, right? The ImageNet moment and machine learning, deep learning, computer vision, all of that. It's almost like it's a victim of its own success in a very strange way.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:30:17] Georgia Gkioxari: I think that it's always important to step away from our everyday and see where we're at. ImageNet was a dataset and this is no attack to the data. Dataset is fantastic. It's an attack to us right outside to us.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So ImageNet came out 10 years ago at a time when we actually didn't have even either good tools nor good datasets. It also came out at the time when we had this explosion of the industry, like the Google and the Facebook that we're seeing a huge amount of user data being uploaded. Immediate needs to address specific problems. Like they wanted to see, to make sure that they don't have the images don't contain violence, pornography, chaplain, geograph. All these things that you need to understand\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='need to understand and incontinence immediately. Of course also business purposes down the line, how does cater to users better by understanding their content and what they post and stuff like that.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So ImageNet the fantastic purpose of the time because we actually needed to build our content understanding research to get to that point and image. That was a fantastic fit. It found itself even in the progress there found itself a spot and then the street and, it's being used and now industry has been its own internal data sets to make that happen because based on the nature of their user data, but in research, we're still kind of stuck with that paradigm. But now we're 10 years later. Now the\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"years later. Now the needs for what we meet to get to we're moving past content and understanding. My company just announced, they want to build metaverse. Metaverse is this extremely complicated task, extremely like hard milestone to get to. Definitely you can't accomplish it by classification. Let me tell you, so these are new needs, right? It sets a completely different environment and what we need to be working in and working on. I'm not saying that we should be working on making metaverse\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='on making metaverse haven, but it dictates what are the interesting problems, AR/VR.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"That's another great topic that we hadn't really been discussing 10 years ago, but now we are there. So you have more problems because we live in a completely different time,\\n\\n[00:32:42] Sam Charrington: Is it clear to you what types of problems and approaches we need and computer vision and machine learning broadly to enable a metaverse like vision?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:32:59] Georgia Gkioxari: Oh, interesting. Yeah. I mean, I think that it will, I think maybe mainly things. I think what is exciting about metaverse or the metaverse types of project is that it's definitely going to be a combination of software and hardware that builds a new potential collaboration in these completely different domains of science.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I feel that we could be discussing this for hours and hours, but it definitely will evolve as moving into the 3D space, us being able to understand in 3D space as being able to generate content in 3D. So I think we're going to be moving towards, definitely towards 3D, definitely towards dynamic capturing just objects and scenes while they're moving and changing and time. I think that it will also involve different modalities. So we need, it's not only going to be a matter of RGB streams. It will\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"RGB streams. It will sound will come into play. I think that depth maybe from depth sensors will come into play. This is a different modality. So I think it's going to be a combination of having to put in together a lot of work from different domains.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:34:12] Sam Charrington: Yeah. That last point you raised is something that I also wanted to bring up in that is. And maybe CLIP is an example of this. One thing that I've heard a lot about this year is interest in multimodal types of problems. Whether it's text and images, texts and video, audio and images.\\n\\nAre you seeing that as well? Are there any interesting things that are on your radar?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:34:43] Georgia Gkioxari: Yeah, and I want to say, it's completely true and it makes sense, right? I mean, these are all modalities that come from or derived from the same underlying world, the text and the audio, everything describes that world that we are so desperate to understand and here, I would say that the reason it always seem like a lot of work coming out is again, thanks to transformers. I think this is another benefit of transformers, not just the gain in performance that we can\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"that we can debate, or it might not be substantial, but it's definitely the fact that it has unified how we are building models to consume these different modalities before audio had completely different line of work, completely different architectures. Video also had its completely different architectures images, completely different architecture texts, completely different. It was even hard to read papers from like I was having a hard time actually reading papers from NLP because I couldn't\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"because I couldn't really understand the underlying structures of the network and all that stuff.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Now I have no problem getting papers from NLP or from any speech and audio processing papers. So transformers are great because they have just unified all these and as a result, it's really easy to also do joint research now with these modalities. It's much easier to actually build without having the necessary skillset or expertise or anything to do research in that domain.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='These two advances, I think, will lead to a lot more work there, hopefully. I think it makes sense. I think this is a direction that we should definitely keep pursuing.\\n\\n[00:36:26] Sam Charrington: You mentioned in the contexts of metaverse as well, as in the context of NeRF, the problem of 3D understanding, this is one of your home problems spend a lot of time thinking about this.\\n\\nCan you talk a little bit about where we are relative to that problem and what that community is thinking about?', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:36:49] Georgia Gkioxari: Yeah. Well, as I said before, I think 3D is going to be the center of emphasis in the coming years from different perspectives for sure. I think NerRFs and graphics see 3D from a different perspective, but it will also come into play when it comes to large scale learning.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='I think that we are still not pursuing that as much as we should because it\\'s a harder task you\\'re dealing with. The modality is different. 3D data are more complicated than 2D images. There is definitely a large data set missing in that field right now. Like a data set where you can say, \"Oh, this is a data set where I could do some large scale reading, learning.\"', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Do you think that this is changing and we're run reasonably, this is changing in my view and why I'm excited as hardware like I know this is not product placement, but this is iPhone 13 and it actually has, I don't know if you guys see, but the camera sensors in the back are tremendous. Part of the sensors is a lighter camera which captures depth. So that means that now you are walking around your pocket, holding this sensor that you would never imagined that you would actually be carrying. Some\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='be carrying. Some of you might not even know. that this is what you actually have in your pocket. All of a sudden we can now capture RGB-D data in the wild.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So I do have a reason to believe that maybe two, three years from now, we might no longer be talking about RGB data. That's what we might be talking about. RGB-D dataset. This is all thanks to hardware. So I do think that this is going to open up a huge new exciting direction for us.\\n\\n[00:38:27] Sam Charrington: This is maybe a basic question but is there an image format that includes RGB-D like the iPhone 13 and whatever spit out RGB-D images, or are they two separate streams?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:38:46] Georgia Gkioxari: Great question because I was looking into this the other day, so right now it's very obscure how the various companies are handling that and whether they're releasing them. So this is actually a twofold question. First, we know the camera captures it. We know it's just not another channel for your store. The question is how, whether we can host that. So can you have users upload that let's say somewhere and store this data and then watch format.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So this is still obscure. There's definitely a lot of apps that allow you to extract that information, which is also why I've been playing around with them a lot. I'm not going to name them but if you look around a little bit, you'll find them in apps store. They extract that information. They actually store it.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I am extremely confident that perhaps Apple or other companies will soon do that by default. The reason for that is actually very simple. It's not just all to satisfy Georgia 'cause she needs to know we did it. Actually, depth is very important to create a lot of effects with your images which a lot of us care about like the Instagrams and whatever to get the lakes but there's a lot of focus, things like that. Dynamic focus, this 3D photos effect to give your images a little bit of a 3D aspect.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"bit of a 3D aspect. I think that's an app already that fit in from the Facebook app. Yeah. Like exactly. Just give it a little bit of interesting perspective. So we know that we want a store that because there is also business progress behind it. So I do think that we're going to see it become more commercially available. Hopefully fingers crossed. I hope somebody hears. Is it Apple?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:40:39] Sam Charrington: Yeah. We've talked about needing new types of problems in computer vision broadly. Does 3D create new types of problems, like all the old problem formulations transfer like 3D object classification, 3D detection, but are there fundamentally new problems that 3D gives rise to?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:41:08] Georgia Gkioxari: Yeah. I think that there's two maybe aspects to this. One is whether 3D can help you build better underlying presentations. So this is one. Exactly like we train our presentations again with our static 2D datasets. Can we build better presentations through 3D, similar to CLIP where you don't text, maybe a different modality? Can you do better there? Then yes, the next thing is tasks. This is where this new era that we live in today with a focus on ARBR versus,\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='on ARBR versus, whatever versus those are, they create these new tasks of challenges for us. You do have your regular object understanding in 3D. NeRF also requires a 3D understanding to work.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So you also have your graphics related tasks there. Of course it's our responsibility to build a better suit of tasks in 3D as well to measure performance better. But there is a lot of tasks that will require 3D and without 3D, they're just not going to be solved at all.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:42:12] Sam Charrington: Yeah. Obviously, most of the images that we're looking at that are 2d images are representations of 3D scenes. Is there any evidence that solving 3D, whatever that means, gets us to 2D and where maybe we're spending too much time on 2D and if we figured out 3D, we would get 2D for free.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:42:34] Georgia Gkioxari: Yeah. I mean, absolutely. Right. I mean, I think that I would only be satisfied and hopeful that by learning 3D visual presentations that you are already solving for 2D, I mean, 2D is just like a simple flattening over that space. So absolutely.\\n\\n[00:42:52] Sam Charrington: I'm asking a more specific question than... Yeah, that stands to reason but I'm wondering, are there specific problems that we've solved in 3D and then...\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:43:08] Georgia Gkioxari: We found that 2D improves 2D. Of course, there is the pure 3D tasks which would not be solved by any means in 2D, but I feel that in this more image content understanding setting that we haven't seen this so far and there isn't this thing, we don't have data sets to see this. I think video is a fantastic, actually first data. So to data format, to attack going there, but video comes with so many other challenges that we just haven't seen enough research. I think we\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='research. I think we should, I think that we should overcome this.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:43:46] Sam Charrington: Yeah. So we've talked quite a lot about the research side of things. Have you seen anything interesting happening and either the commercial side of things or in terms of tools and open source projects, meaning, less papers and more concrete realizations of some of the things that we've talked about.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:44:09] Georgia Gkioxari: Yeah, that's a fantastic question. I think that we have definitely seen it's an exciting time. I feel for startups and product driven work because there's a lot of stuff that it's already working. I always go back and forth about the self-driving car industry. I have an idea that they are actually doing a lot of progress, which of course we don't know because they don't really publish any of the stuff, which makes sense.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"But I have a feeling that that is moving, even though people were less hopeful or something, but judging from the amount of startups and the amount of great people that I see join them. I am only to believe that there's stuff happening there that is quite important. I don't know if you have the same sense.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:44:56] Sam Charrington: Yeah. I feel similarly in the sense that there, there are definitely waves of enthusiasm about the space and it ebbs and flows. One of the comments that you made earlier created this model for me of early progress in computer vision was driven by content moderation and maybe you call it internet one data or whatever, two data. The next phase, a lot of focus on computer vision as there's been a lot of this work on autonomous vehicles that flows into the computer vision\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"the computer vision community. So maybe the next big problem is metaverse maybe those are like the three big problems that have driven computer vision. That's not like a data-based assessment.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:45:47] Georgia Gkioxari: Correct. I absolutely agree with them. Yeah.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:45:50] Sam Charrington: Yeah. So that whole space, I think, is one that historically, and I think I feel the same now about it. It's like I've tended to be a bit more conservative than some folks and is mostly, is less about the exciting things happening in computer vision and more about, well, two things: One, the predominance and importance of edge cases in the real world. Then to the whole regulatory legal insurance, like all the other crap, I think, will limit our ability to get to a\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"ability to get to a world where you walk outside or drive around and most of the vehicles you see are autonomous. I still think that that's a work away.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:46:44] Georgia Gkioxari: Right. I mean, actually I believe that we will solve the first one first, like covering all the edge cases. Then I think getting beyond the regulatory part of the things, I think that's like an impossible. It's just impossible, I don't know. Politics is hard. Yeah.\\n\\n[00:47:00] Sam Charrington: People are hard.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:47:03] Georgia Gkioxari: People are hard. Yeah. Yeah, definitely. I mean, I have the same sense. I've also been very conservative about it also as a computer vision scientist.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Would I ever drive a car that I know... When you know too much it's difficult, but yeah, but I am mostly judging it by just seeing all of these like wonderful, amazing, brilliant people that are just joining and creating startups in that field. So it makes me want to think that maybe there is really a progress happening there that I don't really have a deeper insight into things. I do know though that there's, in that similar space, but there's tons of robotics startups. Vision is definitely one\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"is definitely one component, but we're moving a little bit away from just purely vision now, but the vision is definitely important, especially for pick and place and all these other robotic tasks, but we're seeing a tremendous amount of startups in that space.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='Again, made possible by the fact that we now have companies that make commercially available robots for relatively cheap prices. So you can actually very fast prototype and test various robotic driven applications.\\n\\n[00:48:19] Sam Charrington: Are there any particular that come to mind?', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:48:22] Georgia Gkioxari: I mean, yeah, there is definitely the by peer to be, whoever comes to mind, which is actually very big. I have blanking on the name of fortunately. Yeah, co-variant definitely, I think they also have a like a vision component to things. Then there is one that I recently found that I was very excited about, which was a drone, it's a startup for drones that they release it underwater to capture coral and the reefs, yeah. Map the ocean, but also understand the\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"also understand the progression of how like the damage that's being done and map that and alert people so that just proactive, trying to make sure. I found a wonderful use case of that technology, Yeah, I think that some of these startups that I've hugging phase thing is a very up and coming one does well, relying on open source libraries, making projects available fast for people to get to work on.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"So it has definitely open source component to it.They also have a scientific component where they're trying to bring people together. Well, I want to give a shout out also to Tim Ned with her new research organization that she announced a few weeks ago. That's, we need those diverse types of research organizations as well, not just within industry or academia, but also more independent. I'm very excited for her and for that initiative.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:50:02] Sam Charrington: Yeah, that's maybe a segue to talking about ethics and responsible AI, and the intersection with computer vision. You've alluded to the importance of that several times in our discussion already. I'm curious if you would expand on your thoughts there and where you see the big challenges and opportunities.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:50:27] Georgia Gkioxari: Yeah, I think this is such a hard question because it, I feel that it requires exactly like all these expertise that we've been building and software, and how to make models work. We need exactly that same amount of energy and effort and emphasis to be put in ethics as well. It shouldn't be a side project or something that by two people. A thousand people or no, it should actually be a substantial effort. Try to understand, because we have a lot of work to do and\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"of work to do and even understanding the issues, let alone being proactive about knowing. Especially now in this era of huge data sets, and crawling the web, we need to be extra careful in what we put out and I feel it's our responsibility.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"I think that Tim that has been and impactful in this field where she is educated. Basically she's educating us how to do this. I think that's her contribution and it's a fantastic one. But we need more.\\n\\n[00:51:33] Sam Charrington: I would love to spend a few minutes having you look into your crystal ball and share what you see for computer vision, sprinkled a little bit of this throughout the conversation, but in looking forward, where do you think the most exciting opportunities by?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:51:54] Georgia Gkioxari: If I was, coming out of school or I was, I wanted to see what is the most, what should I be working on right now? I would say that right now, computer vision is definitely it's route is defined by the applications that we are more excited about creating. Then you experience this.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"We want to create for people. So AR/VR, 3D, I think the metaverse related topics are definitely a huge direction there. I would also look into, I think another major field is hardware and computer vision. So how can we make computer vision fast where things can train. Faster and more energy efficient, especially as we're moving through this transformer models that are huge. With a lot of parameters that require a lot of energy. So I think this tandem hardware and computer vision or deep learning\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"or deep learning research, I think that's very exciting. Yeah, I think that these are definitely two directions I would passionately pursue and very interested in with the second one.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Definitely being, not just something that will happen in the next two, three years, but definitely very important, especially when we talk about climate change, and all these issues that we're faced with.\\n\\n[00:53:12] Sam Charrington: Is there a particular research or company or hardware type that you are following that you find interesting?\\n\\nIt sounds like you don't see the GPU is the final word and acceleration for computer.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content='[00:53:28] Georgia Gkioxari: No. I think that Nvidia is definitely on top of it. I feel that they will make that technology will definitely improve. Google has their own TPU is like their own processing units. I do think that the rule might see a revolution with maybe super computers, maybe different types of computing who knows. This is hard to tell, hard to predict.', metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:53:56] Sam Charrington: I guess I'm curious about other predictions specific to computer vision you might have and, you know, are there areas that you think we'll see, like the big paper drop. Is there something tha tfeels really, really close that we'll see a big drop in the next year or so?\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:54:21] Georgia Gkioxari: I think about it immediately thinking ahead. The biggest paper drop for me will happen if someone actually replicates that bird moment and CV just going on to you, a big one as we discussed before, just a huge, huge dataset and showing not just a couple of points and improvement but just a revolution, a little like line of improvements across many tasks.\\n\\nI think that's what's going to happen. I'm not like, we'll see if that's next year or two years, who knows.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:54:56] Sam Charrington: But it feels within reach.\\n\\n[00:54:59] Georgia Gkioxari: It feels within reach. I'm not sure if it's going to be. I do really think that we're currently a little bit, it feels like being before the image in that moment in 2012 where, that just completely changed the field.\\n\\nI feel that we are ready and we definitely need that paradigm shift. Definitely. I'm excited. I want it to happen. I hope it happens.\\n\\n[00:55:26] Sam Charrington: Awesome. Awesome.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"Well, Georgia, it has been wonderful to reconnect and appreciate all of your insights and thoughts and to what's been going on in computer vision and not just what's been going on over the past year, but what we have to look forward to. Thanks so much for taking the time to chat about it.\\n\\n[00:55:49] Georgia Gkioxari: Thank you. Thank you. I hope it was informative and find that and let's see. Let's see what's ahead of us.\\n\\n[00:55:57] Sam Charrington: Fantastic. Thanks so much, Georgia.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"All right, everyone. That's our show for today to learn more about today's guests or the topics mentioned in this interview, visit twimlai.com. Of course, if you like what you hear on the podcast, please subscribe, rate, and review the show on your favorite podcast.\\n\\nThanks so much for listening and catch you next time.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: All right, everyone. Welcome to another episode of AI Rewind 2021. Today we are joined by Zachary Lipton, an Assistant Professor in the Machine Learning Department and Operations Group at Carnegie Mellon University, to talk through all things machine learning and deep learning.\\n\\nZach last joined us on the show for the 2019 edition of Rewind. I'm super excited to have him back once again. Zach, welcome back to the TWIML AI podcast.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:00:28] Zack Lipton: Cool, thanks for having me, Sam. Great to see you again.\\n\\n[00:00:31] Sam Charrington: It is great to see you again. I think the last time we physically had the opportunity to hang out was also 2019 in Vancouver. I think that's probably a story shared by a lot of folks in our field. That was the last opportunity that folks had to hang out in person. How have the last couple of years been for you?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:00:54] Zack Lipton: Oh man, it's been eventful. I'm not going to pretend it's all been smooth, but some things are nice. Like my students are great. And I think how I've been...I think it's not been easy for everyone. Like some people got sick, some people lost someone, some people didn't get to see their family for a couple of years. On the other hand, I feel like it's a weird thing where people have managed to be startlingly productive or at least maybe--I don't want to shame anyone who\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"to shame anyone who doesn't feel productive. I feel like from just my feeling on my lab, I feel like people are... maybe just CMU culture aside, I feel like people have been really locked in at research. But I think there's a kind of emotional wear and tear of just not seeing anyone. Especially some folks are living by themselves, and then when they're in quarantine it's not seeing another human for six months. I think for others of us, it's catching up now. So, it's been a little bit wild but\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='little bit wild but interesting on the research side. We got a puppy, so interesting, personally.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:02:05] Sam Charrington: Nice, nice. so as I mentioned in the lead up, we are here to review the year in ML and deep learning. This is the the third Rewind that we'll publish. The first couple were in NLP and computer vision. Or computer vision and NLP, in the order that they were published. And so far, a couple of key themes have emerged one which was common in those first couple of episodes is this idea that, as John Bohannon put it, NLP eating machine learning, like in the same way, we\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='in the same way, we would say, AI eating the software or what have you. The idea that computer vision is adopting transformers and things like that.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"I don't know if we're going to talk about any of that in this conversation, but you have echoed one of the other observations that John made in that NLP conversation. And it is that at a particular point, there's kind of a slowing down of the field and a little bit of a respite from that kind of breakneck pace of change that we were experiencing for awhile. So, maybe that is a place for you to jump in and riff for a bit.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[00:03:36] Zack Lipton: Yeah, happy to riff. Just [in case] maybe I\\'m [choking] or contrarian or something. I\\'ll start by pushing it back. One thing that\\'s interesting, that phrase of NLP eating ML is kind of cute because it\\'s...well among other things, like in some sense, the line for the longest time, for the last seven years, it\\'s been \"machine learning eating NLP\" in that if you look at the set of people going into NLP-oriented, like grad [part], there was a point where NLP sat really close', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='NLP sat really close to to--NLP and computational linguistics are like two sides of a coin. And they sat not so far from their philosophers of linguistics or whatever.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And now, you have a moment for the last however many years, where the medium person in NLP knows absolutely nothing about language. Has nothing interesting to say about language that could ingest as easily.... It's not to say nobody or that there isn't anyone with something interesting, observations, interesting experiments that are hitting on both sides, but to say that the center of gravity of the field has moved to this way, there's almost no L in NLP. It's just sort of a set of tools where\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='a set of tools where if the commercial demand was more on music than on NLP, you would use conceivably the same set of models, because all they care about is just a sequence of tokens, a very generic sort of approach.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And so, in some sense, it's just been like deep learning eating NLP has been the story for awhile. And I think that this version of NLP eating ML is--I guess one, they don't really mean ML, but really more just other application areas.\\n\\n[00:05:32] Sam Charrington: Yeah.\\n\\n[00:05:32] Zack Lipton: I think...\\n\\n[00:05:33] Sam Charrington: They don't really mean NLP as much as the thing that ate NLP, which is transformers.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:05:40] Zack Lipton: Right. Whatever is that new organism that displaced the NLP is now coming across. But right, it's more like there was a discipline of computer vision where you had people that--the typical person who was in there knew something about the physics of light and optics and was doing this sort of...that was the angle. They were a real expert on the modality of vision and the person in NLP knew something about language. And I think they both got eaten by deep learning in such a\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='learning in such a way that, over the last seven years, ideas that would hit on one side could very easily port across to the other.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And for most of that history I think...hard to say precisely why, if there's some reason or if it's just the order in which things happen, because those breakthrough ImageNet results that really caught people's attention were envisioned first. But I think for most of that history, it's been very one dimensional, very one directional of, I think, things going mostly in the direction of computer vision to NLP. And I think, if anything, this is not really NLP eating vision, but it's just notable\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"it's just notable that maybe one of the bigger things happening in vision is crossing in the other direction, contrary to that pattern.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"But yeah, broadly on the things slowing down pattern...I've been noting this and writing about this for, I don't know, maybe four years now. But I think there's definitely a moment where if we were to look through the history and say like 2012 ImageNet, 2014 Sequence to Sequence models, 2015 AlphaGo, 2016, '17 big advances in the perceptual quality of generative models, 2017 transformers, 2018 BERT; there was a kind of change that...I don't think these are necessarily all profound in the sense\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='in the sense of some big intellectual move, but they are qualitative changes in capabilities.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='So, there\\'s a big move in the sense of, \"What set of problems do I think are best tackled with these tools and what sort of performance can I expect from them?\" And a big difference, in the sense of if I\\'m a practitioner in the field and somebody hits me with a typical industry problem, what\\'s my go-to tool? And if we look at 2021--and now we\\'re saying, \"Well, if someone hits you with a classification task, what are you going to do?\" I\\'m probably just going to use a ResNet from 2014, 2015. If', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"from 2014, 2015. If somebody hits you with NLP tasks, like basically fine-tuning a BERT or a BERT-like RoBERTa, ALBERT, whatever. It's some--I don't know if you know, it's some San Diego insider thing.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='Anyway, there\\'s this moment where...I think, that in some sense, I think it\\'s okay in that researchers now need to start looking somewhere else other than just, \"What if I tweaked the architecture a little bit?\" As I was telling you when we were riffing before, is that I think that research is--there is some aspects of people groping around in the dark, looking for a way in. It\\'s almost like they\\'re swinging at a pinata with a blindfold on and trying to find, \"Where is there an angle that--where', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='an angle that--where is there something big?\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='I think you want to have a lot of researchers in that mindset of, \"I\\'m looking for the blind spot. I\\'m looking for the big prize that other people aren\\'t looking for.\" And look, every now and then someone really lands a mark and the pinata rips open and a bunch of candy falls on the floor. And then, everybody rushes on and there\\'s some period of time where nobody\\'s worried about--nobody even knows where the bat is. Everybody\\'s just picking candy off the floor.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='I think we saw that period of people finding all these...you didn\\'t need a big intellectual breakthrough to have an impactful breakthrough in all those years. And I think we\\'re getting to the point where there is some amount of stagnation because most of the good candy has been picked up and people are looking at the old grimy, moldy stuff like, \"Maybe there\\'s still something in there.\" It\\'s like the sloppy seconds on the research pinata.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[00:10:17] Sam Charrington: So, when you look at--with that analogy in mind, where should research be swinging the bat? This is a crystal ball kind of question, but what does your intuition tell you where opportunities might be?', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[00:10:36] Zack Lipton: Well, I always look for, what is it that we actually care about? When people are selling a story, an aspirational story like about...I\\'m not a mathematician person. I\\'m not just like, \"What\\'s a hard problem? Let\\'s just solve for that reason.\" I got into it too late. I back into it from like, \"What\\'s the dream?\" And if you look at the dream people are selling people, even people with existing companies right now, the claim they\\'re making. If you looked at IBM Watson, which', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='at IBM Watson, which went up in flames. If you look at the claims they were making like, \"What are we going to do for you?\" It\\'s like, \"You\\'re going to make better decisions. You\\'re going to provide personalized healthcare. You\\'re going to help people to have better health outcomes than they otherwise would have without our AI\" If you look at this kind of stuff, what are people selling? What are people hoping to actually achieve? And then you look at what are people actually doing? I always look', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"doing? I always look back and forth between those. And so, what's the missing part? If you actually want to realize the dream of what people just seem to want, what's gone? What's not even being addressed in a mature way?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And so, I think, one thing that sort of jumps out is that everybody's premise, everyone says these things are good. It's always based on some notion of accuracy or the return of an RL system as evaluated on some fixed static environment. And then we look at what are people actually doing? They're taking some model trained in some context on some set of data and deploying that crap in some different environment, which is changing in unpredictable ways. And where the whole environment, it's not\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"it's not just changing in a kind of benign or passive way. Often, it's changing in direct response.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='Think about Google search, right? You deploy Google...every single time they tweak their algorithm, what\\'s the first thing that happens? All the message boards light up and all the SEO goons are like, \"Oh, SEO changed the algorithm, now you need to add this keyword. You need to do this.\" And I think that ML doesn\\'t address that kind. So, when I say ML doesn\\'t, I don\\'t mean nothing that we aspire to in ML, but I mean the main thing. The main thing that practitioners do, their toolkit, the mature', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='toolkit, the mature one, the like, \"I know how to use PyTorch and train ResNets and ResNeXt and whatever,\" that world, it\\'s completely set in the environment of, \"I train a model, I evaluate on a sort of IAD hold out set.\" Or even if you evaluate on some kind of challenge set, it\\'s not like with any coherent principle for why you should expect this model to do well on that challenge set, or why you should think to performance on that challenge set\\'s representative of what you should encounter in', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='should encounter in the world.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"So, I think performing in a dynamic world, making decisions and not just predictions--because everybody's saying, ultimately, if you think you're going to make money off of this, or you think you're going to affect some kind of societaly beneficial outcome by using AI; if you think you're going to do anything, then ultimately, the claim is at some point what you're hoping to do is guide some kind of decision or automate some kind of decision, right? You're actually hoping to have an outcome, not\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='have an outcome, not to just be a passive observer to the world and make accurate predictions about what would happen were you not to take any action at all.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And this kind of setting of actually providing guidance for what you should do in the world...it\\'s a thing that yeah, there are people working on causal inference. There are people who are trying to bring reinforcement learning closer to the real world by maybe incorporating some ideas in causal inference, like to think about confounding that might exist in the data to be able to build models in an off policy kind of way, so that you\\'re not just saying, \"I\\'m just gonna deploy some randomly', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='deploy some randomly acting system in an important application and have it suck for 2 million years until it learns.\" But they\\'re relatively mature and then they get relatively little attention. If you were to look at--not to beat up on our buddies in the press, but to say, \"What is Cade going to write a big article about it in the New York times?\" It\\'s not typically the slog of scientific advances and making robust machine learning or off policy RL or something like this. It\\'s the \"There\\'s a', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='It\\'s the \"There\\'s a big neural network that has 9 trillion parameters and a $1 billion dollar investment from Microsoft...\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And so I think, decision-making, robustness and dynamic environments and actually addressing certain societal desiderata, people have noticed the problems that arise in terms of the ways an AI system can affect. Whether it's unethical sort of outcomes, if you plug them naively into certain decision-making systems. But the sort of field of actually developing systems that could, in some coherent way, align with societal desiderata is quite primitive, right? So, there's a recognition that there is\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"that there is a problem, but we're very early stages on getting towards solutions.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"So, I think that to me, these are the areas I think are more interesting in that if you can squeeze half a point out on all the NLP benchmarks by making a slight variation on BERT, you'll get a lot of citations that everyone will use it. And they should, and it is useful, but it's, I feel like not...it's a slight change in degree, it's not a change in kind. And so, I think, when I look at the field, I think the luxury of being in academia, the reason of being in academia is to think that I don't\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='think that I don\\'t have to just think, \"How do I do Epsilon better than someone at the same crap we\\'re all doing tomorrow?\" But what actually is something that addresses some problem that nobody\\'s even engaging with intellectually, right now.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:16:30] Sam Charrington: It it sounds like your answer then to the word of swinging the bat is in getting closer to real-world problems that folks are having. You mentioned a lot of different elements. I heard some aspects of domain generalization in there. I heard aspects of even user interface, like how you're presenting the information, heard aspects of fairness in there. But broadly it sounds like you're also calling into question, kind of the simplification that often happens in research\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='happens in research of problems that remove them from all of the constraints and fuzziness of the real world.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:17:17] Zack Lipton: Yeah, and it's tricky, right? Because everybody's...\\n\\n[00:17:24] Sam Charrington: Everybody thinks they're doing that?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:17:26] Zack Lipton: It's more like everybody's got to choose to focus on something. And to focus on the thing they want to focus on, they got to compromise on something else. And it's not that one thing is right or wrong. Like I don't think it's wrong that there's people out there building bigger language models. I don't think that's fundamentally wrong. I think you gotta...maybe use your brain to think about what kind of claims I can make about these things or how should they be used in the\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='they be used in the real world? But I think look, it\\'s interesting to turn that knob and say, \"What if I make this bigger? What happens?\" There\\'s plenty of work to be done. One kind of tradeoff that you often have is that if I want to get close to what real data looks like, and I want to get close to things I can actually do in a bunch of domains, often all that\\'s available is...there\\'s a way that predictive modeling in the status quo, is closer to the real world in that it touches real data and', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"real data and it gets within its narrow aspiration of just predict well on the IID data, under a naive assumption about how the world doesn't change; it's able to do that on really complex, high-dimensional real-world data.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='On the other hand, what you give up when you focus only on just that problem is any kind of consideration of...I think, people are just only thinking about \"How do I get better at building predictive models?\" is they\\'re getting close to dealing with real data, but they\\'re asking a very narrow set of questions about it. Which is like, \"How do I get higher accuracy?\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='Then on the other side, you have folks say, for example, trying to get out fundamental questions about what sort of causal queries I can make. And very often, in order to flesh out those questions now--and then they\\'re taking on a more ambitious set of kinds of queries that I can ask, but in order to make progress on understanding the fundamental form of those questions, this often starts with, \"Well, I got toanalyze fundamentally, if one of these questions is even answerable from the data sets', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='from the data sets that I have.\" In order to maybe get some of that analysis to go through, I have to make some simplifying assumptions about the form of the data. Like I assume that the whole world is linear and it\\'s not high-dimensional and it\\'s not whatever.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"So, you have plenty of people who are doing work that's really more ambitious and expansive on the front of the kinds of questions I can ask. But they're making really simplifying assumptions in terms of the sorts of data I have and the number of variables I have and not worried about that but that's the compromise. And then there's other folks building predictive models and trying to get close to do something that works on real data, but be naive about the kind of questions you can ask and not\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='you can ask and not worry too much about just how limited is what you could do with those predictions and their power to guide decisions in the real world?', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And then, I think once you have that kind of tension of okay, everybody\\'s looking at something and not looking at something else, I think the question you have as a research community is, \"Are you over-leveraged somewhere?\" I think oftentimes, there\\'s a naive form of a criticism, which is like, \"Oh, this thing sucks. And this thing is good.\" But there\\'s a more mature version of it, which is like, \"We\\'re way over-leveraged on this thing and paying way too much attention to this thing and', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='to this thing and neglecting these other things.\" So, it\\'s more a matter of moving the needle. It\\'s not that nobody should be building a bigger language model or tinkering with architectures, but it\\'s sort of like, \"Okay, we\\'re at a point where we\\'re not getting nearly as much juice per squeeze doing that. Why do we have 99% of the community engaged in this? And why do we have so many papers that are being submitted that most of which are not actually contributing anything, either as an idea or', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='either as an idea or as a result.\" And so yeah, I think we\\'re sitting on some funny terrain like that.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:21:49] Sam Charrington: So, were there notable papers or research advances that you think poked at some of these issues that you're raising or you think are swinging the bat in the right direction?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:22:04] Zack Lipton: Yeah. I there's this very weird climate now, which is, I think for a lot of these questions you have...a growing recognition there are problems, but then you have a subset of people that are just kind of taking advantage of the way in which the peer review system is overtaxed and scattered and just using the language of those problems, but not actually addressing them.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And I think you see this in all of these things. I think you see this in the fairness literature, I think you see it in the robustness literature, I think you see it in causal literature; in that, people submitting papers that sound like they\\'re addressing causal problems, they\\'re not actually. People just saying, \"This model is robust,\" in a way where--by the way, you can never just say a model is robust. If you state nothing about the ways in which the environment\\'s allowed to change...there\\'s', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='to change...there\\'s no such thing as general robustness, right? Because I can post two different assumptions about the world where in one of them, when the environment changes and this is what I should be doing. And the other one, when it changes, that\\'s what I should be doing. I have no way of discerning which world I\\'m in, right? Our class would be like, \"Do I live in the label shift assumption?\" If I make that assumption like the distribution of categories is changing, but the class', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='but the class conditional distribution, \"What does COVID versus not COVID looked like?\" is what\\'s not changing, but the prevalence is changing. First, do I assume that the covariate distribution is changing, but that the label, the conditional, the probability of the label, given the inputs is different? I might have no way of discerning whether I\\'m in world A or world B. But one thing is the...the robust model in this setting should do this and the robust model in that setting should do that.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='So, you have a set of people that are just doing the deep learning thing. Which prediction lets you get away with it like, \"Let me throw spaghetti at the wall,\" because I get to evaluate on the holdout data and how well I\\'m doing is identified. So, I don\\'t have to be able to state in terms of any principle. If it gets to a causal effect, you don\\'t get to observe the causal effect.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"So, if what you're doing doesn't actually identify the causal effect, you could call it a causal, you could just use the language of causality in a deep learning favor, but it's not actually addressing causality in any kind of sound way, and fool the reviewer, but not necessarily be doing it.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And so, I tend to think that a lot of these other problems are more foundational. Like they're not problems where we know how to evaluate systems, let's have people try stuff and whatever. They're problems where... I'll give you an example. Like in the...distribution shift world there's, I think, a handful of things people are doing that are a little bit more interesting or sound or actually giving a path forward. There's a group at Stanford, some of Percy's students, Shiori and Pang Wei among\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"and Pang Wei among them, put together this really expansive benchmark called WILDS. It's a collection across a whole lot of different application domains of a whole lot of different settings where you have some kind of subpopulation shift or some other kind of distribution shift. And it provides a sort of unified resource for a whole bunch of settings.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='Again, you still need to have some kind of--you can\\'t just use the dataset and say, \"Oh, I tried this thing in this one domain and it generalized well to these two others, therefore it\\'s robust.\" But at least it gives you some unified resource for asking a question. If you compare it to the world where basically people are just saying, \"I have pictures of MNIST images and then MNIST images on funky backgrounds,\" I think it\\'s a big advance towards a nice sanity check and putting people in touch', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='people in touch with the sorts of problems that are arising in the real world.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='There\\'s one formulation of these domain adaptation settings, is that there\\'s a version called domain generalization. And here it\\'s sort of saying, \"I have a bunch of different environments that I\\'ve collected data from and now I want to generalize well to target environments.\" Possibly using the fact that I can look at the different source environments that I\\'ve had and they\\'re actually marked out as different environments, I could try to see something like what\\'s stable versus unstable across', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='unstable across environments? And there have been some interesting papers.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='By the way, before we met, I picked some of my students to be like, \"What do you think are some of the interesting papers?\" So, I want give some credit to my students who are now like the extension of my memory. So,my student, [Sarah], pointed out is a lot of interesting work where you have a whole lot of methods that are proposed, but it turns out that if you set up a really rigorous baseline...and there\\'s some papers. Some from CMU, from our friend Elan Rosenfeld and his advisor, Andrej', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='his advisor, Andrej Risteski. Some from David Lopez-Paz at a FAIR. But where they\\'ve shown things that for a lot of these setups, it\\'s really, really hard to beat really stupid baselines like, \"Just dump the data together and just do ERM on it,\" like, \"Just train on all the data together and don\\'t use the environmental labels in any sophisticated way.\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"In our own lab, my student, [Sarah] has been making a lot of progress on these distribution shift problems and we have some results that we've been excited about. Like, among other things, working out when you're presented with--you've trained on data from...you have some classes you've seen before, and then suddenly at test time you have some data that shows up from some additional class that you never saw before; can you actually, on the fly look at this previously seen data from some classes\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='from some classes and now additional data from some unknown class and identify like, \"Oh, I can say precisely what fraction of the new data is from some previously unseen class,\" and even develop a classifier that can now start predicting it? So I can say, \"Oh, I think these samples have this probability of belonging to that class.\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='So, you\\'d imagine that in the context, like a model monitoring pipeline, you\\'d eventually live in that world where if the world changes in some way, the model could come back to you and say, \"Hey, I think with high probability of at least 20% of your new data actually belongs to some new class that you\\'ve never seen before. And here are some examples that I think belong to that class.\" And then, you could take some kind of corrective action if you think that the model\\'s wrong. So, that\\'s that\\'s', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"So, that's that's on the robustness side.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='On the causality side--and I got some of these tips of my student, Shantanu, on some of the work that we\\'ve been talking about and going over. I think...causality research is really exciting because it actually gets to the question we care about, which is like, \"What would happen if I did this versus what would have happened if I were just a passive observer, watching the decisions get made as they always are?\" And causal inference gives a philosophically coherent way for answering those kinds', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"those kinds of questions. But the danger is that those answers are almost always predicated on some pretty strong assumptions...like I can learn the parameters of my cause and model, but the structure of the causal model is given a priori and I know it exactly. And there's no one observed confounding that can make all my results invalid.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And so, there's a lot of interesting things happening. Among them, there's some folks like Carlos Cinelli, who just started a faculty job in the statistics department at UW, has been doing a lot of interesting work on sensitivity analysis. So, if there's measurement error or if there's some omitted variable bias or something. Like frameworks for being able to say just how much would there have to be for me to change my causal conclusion.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='So, getting towards I\\'m not just saying, \"Oh, if I\\'m nailing all these ridiculously precise assumptions about how the world is, then this is the answer to your causal query.\" But saying, \"This is how far off those assumptions would have to be for me to have to totally change my mind.\" Eric Tchetgen Tchetgen is a researcher at Wharton, a statistician who does a lot of exciting work in his area. And Shantanu hit me to a paper that he\\'s doing, which addresses a specific problem of, people often', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"of, people often make this assumption, there's no unobserved confounding. And that is such a strong assumption, because then, even if you have the right confounder, if you just measure it in a slightly noisy way, then there's unobserved confounding. And so, he's gotten to this formulation called proximal causal learning. And it's, you can allow that--okay, I have some proxies for the underlying confounders, but they're not perfect proxies and what can I do in that situation?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='Finally, one thing on the causal inference side that I\\'ve been really excited about is a whole lot of machine learning just sort of takes a stance which is like, \"I\\'ve got this set of variables and I\\'ve got a collection of examples.\" My data looks something like a table. Now, it could be complicated because if it\\'s text, the different documents could be different length. But the typical formulations that people work with don\\'t usually allow for the setting where it\\'s like, \"Oh, I have a', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='like, \"Oh, I have a collection of a bunch of different datasets and I observed this thing and this dataset and this other thing in that dataset.\" But I feel like a lot of real-world decision-making is actually governed by that kind of process.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='I think we\\'ve all gotten a little bit of a crash course in this from just watching the COVID response unfold in the public eye. It\\'s like, \"Oh, got this data from the CDC, but it has these features. It tells you how many reported cases, but it doesn\\'t tell you how many tests are run. But, oh, I have this other data from the manufacturers of a diagnostic equipment and that data actually tells me what fraction of tests are positive, not just what number of tests are positive. And I have this other', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='I have this other data from the local municipalities.\" And so, you get these questions where it\\'s like, \"If I have some question where...\" I think very often we have queries. Especially in economics, this comes up. They call them data fusion type problems, but where the answer can\\'t come directly... I have no one dataset that can necessarily answer my query, but I have a whole bunch of different datasets and it\\'s possible that if I combined them intelligently, I could triangulate to the answer', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='to the answer to the question that I have.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:32:43] Sam Charrington: The [inaudible] to me makes me think of infrastructure types of...at least that we talked about that on the infrastructure side as well. Is there terminology evolving on the machine learning side for thinking about problems like this? For some reason it also calls to mind graphical kinds of things in that you'd imagine some kind of connectiveness in the data and the way they're represented to one another.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[00:33:11] Zack Lipton: Yeah well, in the the econ world, they call these data fusion problems.\\n\\n[00:33:16] Sam Charrington: Yeah.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:33:17] Zack Lipton: Someone who's done some really interesting work on that from the AI ML side is a researcher named Elias Bareinboim. He's a professor at Columbia and he was Judea Pearl's grad student. And now, he's a [prophet] in his own right doing a bunch of--I think a lot of the super exciting work in this area. He's gotten to the sort of questions where...he has this paper from--I don't know if it was technically 2020, but I read it in '21, so we can call it 2021. But on an algorithm\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='But on an algorithm for what he calls the general identifiability problem. So, it\\'s not just saying, \"Oh, I\\'ve got this one dataset, can I answer my causal query?\" But it\\'s like, \"Oh, I\\'ve got this collection of datasets and in this dataset, these are the variables that are observed. In this other set, this other variable\\'s observed. And maybe this dataset was collected by someone doing a particular kind of experiment on one of the variables and this other...\" and so, I might have different', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"might have different datasets from different experiments, they're not even necessarily just different views of the same data. One of them, someone was intervening in some way.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='But if you have this collection of datasets and some underlying causal structure, now, can you tell me precisely how can I combine all these datasets to answer the question that you have? Or I guess, with causal questions it\\'s always the first step, \"Is it possible to identify the answer to the question that you have based on the data that\\'s available?\" And then, if you can, give me the formula, such that if I plug in the data from these different datasets, it would give me that estimate. So', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='me that estimate. So it\\'s like, \"Is it estimable? And if so, how do I produce such an estimate?\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='Yeah, so I think these are general exciting areas. There\\'s also a lot of work happening now in causal discovery. This is a really ambitious problem because...in causal inference, you basically say, \"I know the structure of the causal graph. I know which variables potentially cause which other variables, but I just don\\'t know the functions that determine.\" So, if it\\'s like, \"X and Y together influence Z.\" I don\\'t know what is the function by which the values of X and Y determines Z, but I know', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"Z, but I know that Z listens to X and Y. If I were to intervene on X, that could potentially change Z. Whereas, if I were to intervene on Z, it wouldn't change the value of X.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And so, if you have this kind of structure, causal inference says, \"How do I figure out, basically what are those functions so that I can then answer a causal query?\" But there\\'s a sort of....and that by itself is super hard. And we always never agree on causal effects because if you assume the graph looks like this and it\\'s slightly different, then all bets are off. Causal discovery basically says, \"What if I don\\'t even know the graph [app for Yori],\" or \"I have some partial knowledge of the', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='knowledge of the graph, but I don\\'t actually know fully which arrows go from which variables to which other variables?\" So in that case, you ask this question of like, \"When is it possible to recover the graph?\" And in general, you can only recover the graph up to something called an equivalence class.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='But now there\\'s a whole bunch of other papers that...I don\\'t have all the links, I could send them to you offline. But things where they start asking questions that says, \"Okay if I\\'m able to use causal discovery to get the graph up to equivalence, now I can ask a question like, \\'What set of experiments should I run in what order to, as efficiently as possible, resolve any lingering ambiguities?\"\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"So, you're right, just observational data might at least tell me something like certain variables aren't connected to other variables and I'm able to orient for some edges in the graph, like which direction do they point? But others, I can't. But then the hope of causal discovery is to be able to additionally do that.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='So, that\\'s one exciting thing. And my student Shantanu has been working a lot in that area so we have a paper that gets at this question of, if you had to make these decisions about--like I was telling you before--if you have different datasets and by combining them, you can answer a question, but not necessarily by using one of them alone. Or even if you can combine them to answer the question, there\\'s still an unresolved question of, \"How much data should I collect from this source versus that', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='source versus that source in order to, as efficiently as possible, pin down the causal effect?\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='We\\'ve been working on that problem of basically...imagine you\\'re working at a company and you have some third party data provider that charges you for, I have to pay this much per thousand examples, right? How would I make the decisions sequentially of, \"Okay. Based on what I know now, which data source should I query next and for how many samples?\" And then, okay, now I update my belief. I make a subsequent decision. Which, I think, this decision process is always going on in the background,', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='in the background, right? Like if you\\'re a company that\\'s buying data from people or going out and actively doing some kind of monitoring effort, data collections, you\\'re making decisions on the fly about, \"Oh, I want to collect data from here. Oh, now I know something I didn\\'t know before. This is going to guide my decision of what to collect next.\" But we don\\'t usually formally model that process. We usually assume the data is already there and then focus on how do you estimate something,', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='estimate something, given that the data is there?', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"Yeah, those are some more so I'm excited about that direction. And I think on the fairness side, I think one way that things are maturing is that people have been posing these questions in ways that maybe... I don't know if you're familiar with this philosopher, Charles Mills, who passed away recently. He's some this great moral and political philosopher and he writes about...this ideal approach to theorizing about questions of justice.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And I had a post-doc who graduated student, Sina Fazelpour, who is now a professor at Northeastern. But we wrote a paper a couple of years ago, just making a connection between what's going on in ML and this sort of framing of ideal versus non-ideal theorizing about justice that comes from, among other folks, Charles Mills. But he has this point that when you start posing a question about equity or question about justice as a sort of technical problem, and you make up a toy model, there's this\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"model, there's this danger that you highlighted as salient and relevant, those parts of the problem that are captured by your toy model, and you relegate as not even of academic consideration, everything that doesn't show up in your model.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"The danger here is that if the things that you're just completely forgetting about are actually everything that really matters, then you wind up in a situation where you could do a lot of academic tinkering and you could even develop elegant mathematical theories, but they have almost nothing to say about the underlying question of justice that you care about.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And I think this is sort of the situation that we\\'ve been in to some degree. And it\\'s not to implicate everyone, but it\\'s to say the main thing, right? It\\'s that we\\'ve been posing these questions of equity in the form of, say I have a dataset, say I have a particular feature. Let me just start enumerating different things that should be equal and then saying, \"Oh, it\\'s not possible to make them all equal simultaneously, so let\\'s either just naively pick one and then flush out an algorithm for', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='out an algorithm for it. Or just pine about how fairness is impossible.\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"I think what gets lost in that whole kind of discussion is that it's almost all of it, it's taking for granted just I've got a dataset, there's a bunch of anonymous features. I don't really say anything about what they actually mean or what real-world processes they correspond to or how disparities arise and how that consideration really bears on what is the appropriate response from a standpoint of effecting justice.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='You don\\'t don\\'t look at...the major league baseball, for example, and say, \"Oh I noticed there were more players from some country than from some other countries relative to their...\" and say, \"Okay, let me just equalize it,\" instead of a quota system. But it\\'s also because you don\\'t believe that--I dunno, say it\\'s some country that excels in baseball like Puerto Rico. You don\\'t think they\\'ve been given an unfair advantage in getting to the major leagues.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And so, this whole backstory of what actually do these variables mean? And to the extent that there are disparities reflected in the data, where did they come from and how do they correspond to some coherent political stance or theory that sort of makes a straight line from that to who is a responsible to remediate? Who has a responsibility to remediate it? These are fundamentally, the concerns that we always have when we speak, I think, in the law or in a broader sense about questions of', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='about questions of justice, that for some reason I think that--these concerns...there\\'s something, I think, maybe just about the fact that it\\'s a new field or something like that, but that for some reason have been just completely sidelined. Or \"completely\" is a strong word. But by the main branch of fairness research.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And I think there is a number of people who are doing interesting work here to try to actually ask the critical questions. And I think Lily Hu and Issa Kohler-Hausmann are two people who I think just have been asking the right kinds of questions for a while and framing that critique in a way that I think is what's so rare. Both really understand what's happening in the fair ML world, and also really understands the sort of context. And they're the people who actually understand ethics and\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"ethics and actually understand legal principles of justice and are, I think, able to speak from some degree of authority to what's missing in the way we're posing those questions and tackling them.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:43:49] Sam Charrington: Before you jump into their work, the things that come to mind for me are this idea of techno solutionism being part of the problem, like what we're trying to throw technology at the problems that technology is creating for us that...\\n\\n[00:44:08] Zack Lipton: Yeah, we talked about that a couple of years ago.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:44:12] Sam Charrington: We did. Also, there's a nod in the way you talked about the problem of fairness to causality, and when we all got really excited about causality a couple of years ago; I think it was that same NeurIPS was where everyone left excited about causality. But it was supposed to be the savior of fairness and it was applying causal modeling to machine learning more broadly was going to give us transparency, give us fairness, give us interpretability, and break open all of the\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='open all of the black boxes and all of that.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:45:02] Zack Lipton: Yeah. I think....I couldn't more highly recommend Issa and Lily's work here. I think, there's a handful of work. There's some work by Elias Bareinboim and by Ilya Sphitser that has--and before, some earlier work by Matt Kusner that sorta pose different notions that are within a causal framing, coming out of Pearl's causal modeling. Some notions of fairness that are...now, the earliest versions of that say something like... there's a lot of different versions.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='If someone wants to say something like, \"Okay, it\\'s not just a question of is race or gender or whatever is considered its protected attribute, does it turn out to be correlated with some outcome?\" We\\'re going to ask some question of, \"Is it what causes the outcome?\" And there\\'s a way that these questions have been pub--and it\\'s actually, the causal framing is not unique to machine learning. It\\'s actually something that I think the legal scholarship itself often expresses things in causal terms.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='in causal terms. And before them, I think economists, for example.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='There\\'s a famous experiment, right? Where people say, \"We sent the resume\" experiment that I think Sendhil Mullainathan and some others ran where they randomized names to tip more likely black Americans signing as it was more likely to be white Americans signing in. And then they send the resumes to people and they measured the response. And it\\'s an interesting experiment. It\\'s certainly valuable research. And the fact that there is, in certain contexts, a difference in the response rates does', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='response rates does jump out as problematic, right?', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='On the other hand, If you sent them out and there was no difference in response rates, should we conclude in the other direction like, \"Oh there\\'s nothing wrong.\" Right? And I think the answer is, obviously different people will have different opinions and the answer might be answered different in different contexts. But I think that there\\'s a lot of context in which I think many of us, or most of us would say that that\\'s not necessarily the case.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"For example...because what does it mean to just change the name? Like I could change your name and that wouldn't make a difference. But if I change what college you went to from say, HBCU say some other school and that made a difference, even if your name by itself, conditioned on everything else, did it make a difference? So, there's this notion that's baked into a lot of literature that tries to pose questions about discrimination through a causal lens that sort of tends to adopt a rather\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"to adopt a rather narrow notion of what could constitute discrimination as the direct effect of some attribute, like the direct effect of gender, the direct effect of race on a decision. And the problem is that, well, what about all of these sort of potentially indirect effects that could still be--if I were someone were to make a decision based on some factor that is super correlated with race and also irrelevant to the decision otherwise, would you say that that's not discrimination?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And there\\'s some work by Elias Bareinboim and Ilya Shpitser which is, I think, a step, at least conceptually, in a more distinct direction. Whereas, what they try to do is...if you have a causal model over all the variables, you could say something like, \"Let me disentangle how the effect of some attribute of interest, whether it\\'s race or gender, comes to influence some outcome of interest along all the different sort of plausible causal paths that have been taken.\" And I can attribute to what', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='attribute to what extent is this influencing the outcome via that variable versus via this--by this path versus via this other path?', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"Now, keep in mind though, that's sort of--I think what's cool about it is it's like a thinking tool. Like in practice, do we actually expect that we would have a causal model that captures all the variables of interest and actually says exactly--we would know precisely which variables influence...every variable that goes from somebody's gender to whether or not they got hired? We'd be able to--we're going to trace over what scale? Over the scope of someone's entire life, we're going to build\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"we're going to build into our graph, every opportunity...\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[00:50:01] Sam Charrington: [Inaudible] resume?\\n\\n[00:50:01] Zack Lipton: Right. Every decision, every opportunity that someone was given or not given on that account. We\\'re going to have a graph that is so rich as to capture all of that. It seems unlikely, but at least it gives you maybe a thinking tool as like, \"Okay, at least I can conceptualize and step back and think about the fact that there are these.\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"But among other things, it outsources the normative work, right? At the end of the day, presumably, the reason to disambiguate these different pathways is to say someone believes that-- they usually put it in the terms of some paths are permissible. Like maybe they run through unambiguous qualifications for the position being hired for versus other paths or impermissible paths, because all they're really doing is telegraphing information, but they're not actually influencing...they're not\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"not actually say, relevant to the job qualifications or whatever the context is. But is they're still outsourcing the normative work. Someone has to go in and say which paths are permissible and which paths are impermissible.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And Lily has a really sharp critique. She also has a nice set of blog posts that are called Disparate Causes, I believe, on this blog phenomenal world. But it goes into this problem critically and among other things, getting at this question of that... I'll put it like, what we call a direct effect or an indirect effect is partly an artifact of the representation that we have. And there are some causal questions where...what's the right way to say this? For any kind of process that we describe,\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='that we describe, there\\'s multiple different valid causal representations conceivably, right? Because you can always zoom into--if I have this variable and this variable and an edge between them, I can always zoom into it and say, \"Oh it\\'s not just that someone\\'s college influences their internship. It\\'s actually, their college influences this subtle decision that\\'s made by some recruiter, which influences this, which influences that.\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And so, you can always zoom into it and bring more into focus whether or not someone would look--now, a very generic question, like, \"What is the average treatment effect?\" Maybe as long as you have--whether you had a very sort of granular or very coarse representation of some process. If they\\'re both valid, you\\'ll have the same answer for a question like that.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='But this question about, \"What are the pathways taken and are they permissible or not?\" is an artifact partly of at what resolution do you zoom into this process and do you capture it? And something might look okay if you zoom way out and you subsume a whole lot of mediators into just an arrow. But if you zoom in closely and you knew more about how that process took place, then maybe you would say, \"Oh, this isn\\'t kosher.\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"I think, at a high level, I think that causality gives us a set of thinking tools for thinking critically about some of these problems. And they are, maybe in some way, a partial step in the right direction. But at the same time, I don't think it's like a magic bullet that addresses all questions of fairness or justice or discrimination. And I think that often, the sort of model that was sufficiently rich to be able to--even if you believe that they were, you wouldn't actually be able to produce\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='be able to produce the causal model so that you could fully resolve those questions.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And I think one nice point that Lily makes, and I think it might\\'ve been in joint work with Issa...but I remember one of the points is that, I think that there is a lot of times a dangerous--it could be a little bit of a distraction. If you said that there\\'s heroic amount of, \"I have to know every single variable and every single thing and estimate every single relation before I can make any kind of conclusion about whether there\\'s discrimination,\" that might not actually be necessary. And it\\'s', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"necessary. And it's not in general what we do. I think there are situations where we can size up, at a bird's-eye view, that there is some fundamental inequity in society and conclude that we have some responsibility to do something about it. But that doesn't need to be contingent upon saying that I've exactly estimated every single possible causal functional on the pathway of every single factor that plays any role on the path to some decision that's made about someone in their life.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"But that might set, at end of the day, too high a bar that...I think we're able to recognize cases of discrimination and plenty of cases where we're not able to do this kind of Herculean numerical feat.\\n\\n[00:55:25] Sam Charrington: Let's maybe shift gears and talk a little bit about use cases or application areas that have made notable progress in 2021. Anything come to mind there?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"One obvious one--and as much as I might be called a contrarian, but one area you got to give some credit is I think AlphaFold from DeepMind. I'm not a protein folding expert, but I know some people that are not just gullible, deep learning boosters who do work in the area. And as far as I can tell, it's actually a pretty significant leap forward. It's work that could very well have won a significant science prize, that level of accomplishment. And that's a little bit, hearsay in that I'm not an\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"in that I'm not an expert in protein folding. But as far as I understand it, it really is a legitimate, significant contribution. And I think an area where, maybe deep learning wasn't quite as inlined as an essential tool. So, that's certainly a use case.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:56:52] Zack Lipton: I think you're starting to see a lot of the use cases that were maybe obvious ones, but not necessaril...for example like radiology. It's an obvious initial thing. And hearkening back to our earlier conversation about the difference between prediction and decision--part of why radiology is...people see it as this big target is that there are certain roles of the radiologist where they really are involved in decision-making and recognition as part of a weird...it's like an\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"weird...it's like an interventional radiology. But there are also lots of people who literally are looking at images and making classifications. And medical imaging is a case, like a diagnostic kind of imaging.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And I think that\\'s a case where we\\'ve known since the moment big image recognition results started hitting in say 2012, 2013, that radiology was a potential target. And you had some maybe overly optimistic statements from Geoffrey Hinton like, \"If you\\'re in medical school now, do not specialize in radiology.\" It hasn\\'t quite gotten to that point. It hasn\\'t taken the radiologist out of the loop.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"But I've been chatting with a lot of radiologists recently and I've been surprised to find two things. On one side, that some of the systems really are quite good and you actually have some systems being deployed already, actually piping information into patient records. And at the same time, I think some of the problems that we discussed earlier about what can go wrong are happening on the ground. And you do have a situation where, for example, systems that work well on one set of equipment are\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='set of equipment are not performing well on some new scanner, which--it\\'s sufficiently similar to all the other scanners that the human radiologists should have no problem. These are not adversarial examples. Nobody\\'s out there designing a scanner. It\\'s not like there\\'s a radiologist that\\'s I\\'m going to build a scanner that just fucks up all previous...all the deep learning, so that way we can keep our jobs.\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='So, I think you have, both a moment of the technology actually making landfall. But I think you also have some moment of the rubber hitting the road and people seeing upfront, up close, some of the ways in which the technology is brittle and dangerous. I think that largely...this might be an unsexy story, because it\\'s always like, \"What\\'s the big sexy application?\" But I think largely the story now. ...and I think that overall, the biggest--if I were to take a bird\\'s eye view of the economy and', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"of the economy and I'm just watching what is AI doing? I think the story of 2014, 2015 is these new use cases; fundamental new things popping up, like things we weren't doing with deep learning suddeny--like machine translation, people swapping out the old guts and sticking into deep learning systems. And suddenly, every single mobile phone having the capacity to run some kind of small, deep learning model, because it's being used for recognizing objects in the cameras and doing the face\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='and doing the face recognition that unlocks your phone and all of that.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"I think the bigger story of the last couple of years has been more on the side of deployment and diffusion and maturity of the operations around ML. Like I noticed more and more companies; their pain point isn't that they need someone who could train a model. Their pain point is they need an ML ops person. They need someone who can actually keep the crap running day in, day out. Someone who knows--they're someone specialized, like a purely ML researcher. Like someone like me, I don't have this\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"I don't have this skillset. I haven't spent my life in... There's just a real serious discipline in keeping software working day in, day out. It's amazing what we can do when you see companies that have a software product that 400 million people use every day and they go seven years without a single hour of downtime. It's absolutely bonkers how difficult that is.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And machine learning throws in a whole--I think researchers don't have that, but machine learning throws a weird set of complications because there's all kinds of ways that things could go wrong, even if there aren't software bugs. And so, they need to understand something about...enough about statistics to have some sense of what could go wrong and ways that you need to model things that aren't software glitches. They're the world changing glitches. It's like the world is the bug, even if\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"is the bug, even if everything's coded precisely, and need to be able to interface back and forth between software developers, ML engineers, and researchers.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='So, I think the maturity of ML ops--and also just broadly, the use of ML, not just in--I think there was a moment, when there was Google, Amazon, Facebook, Microsoft. And I don\\'t know if you\\'ve ever read this, but I wrote this satire bit...just because when everyone was making a big deal about, \"Oh, whatever professor left to go to whatever company and this is their salary...\" and they were writing about it almost like football players getting traded or something. So, I wrote this stupid post', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='this stupid post that was just announcing that I had been hired as the Intergalactic Head of Machine Learning by Johnson & Johnson or something for some astronomical sum. And it was just a stupid joke. But the funny thing is a year later, I forgot where I was and I met someone and they worked at Johnson & Johnson AI reserves.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And I think that this is part of what's going on now, is that...there was a moment in time, sure I'm--making this up, I didn't research it before. But this is what you come here, to speak from academic authority just to make up crap on your podcast. I'm sure there was a moment in time where there were only a small number of elite tech firms that were using modern SQL databases. When it was fresh, I think it was at IBM when it was developed. But there was a moment where there's a really hot,\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"a really hot, fundamentally new technology that really changes business operations at places. And there were a handful of super technical firms that knew how to do it. And now it's like the most boring technical firm in the world uses SQL.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"I think that this is a huge part of what's happening in AI if you were to size up commercial environment. I think there are exciting startups that are using this technology in new ways. There are interesting things going on at the sexy tech companies. But I think there's a lot of...there's no company that you go to, whether it's--I'm sure if you went to a waste management company, they're using AI for something or forecasting demand, or trying to figure out how to route their trucks or\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"their trucks or something. And I think that this sort of just general progression of AI from a luxury good to a commodity is an essential part of what's going on. And the fact that every company has--this is becoming their concern.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='I think part and parcel of that is the way that the tooling is getting better and better. A whole lot of companies, what are they offering? Things that make it...like the stuff that everyone\\'s already been doing it for awhile, that anyone could do it and it\\'s easy to track and it\\'s easy to organize. I think this movement of AI from a concern of \"What\\'s the new model?\" to like, \"What is a stable workflow that we can adopt such that accompany that can\\'t spend half a million dollars per engineer', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='dollars per engineer can still use this technology successfully and profitably?\" I think that\\'s a major part of the story of the commercial application of AI right now. And it\\'s a pretty unsexy story maybe of just like, \"Oh, this is just becoming...\" Right? But I think this is what happens to everything, right?', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[01:05:12] Sam Charrington: Maybe an unsexy story if you're an AI researcher, but if you're in ML ops, it's pretty cool.\\n\\n[01:05:18] Zack Lipton: Yeah.\\n\\n[01:05:18] Sam Charrington: A lot of really cool stuff happening in that field for sure.\\n\\n[01:05:21] Zack Lipton: And there's a lot more jobs at every company in the world together, than there is at whatever it is, like Apple, Microsoft, Amazon, Facebook, whatever. So, I think that moved to...yeah, for sure.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[01:05:40] Sam Charrington: Before we run out of time I'd love to have you kind of dust off the crystal ball a little bit more and share some of your predictions for the upcoming year, years. We've talked a little bit about where you'd swing the bat from a research perspective, but how do you think 2022...? With the backdrop of...I don't know if you'd call it a cooling or a slowing or a boring-ification or whatever you'd want to call it. Are there innovations that you see the silhouette emerging\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"silhouette emerging from the shadows and you think something's there?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[01:06:27] Zack Lipton: Right, the cooling. The funny thing about that is it's not like it's all cooling or it's all heating up. I think the coolest or weirdest--the interesting thing about it is that it's...whenever you sum up something like a complex phenomena with a single number, you lose a lot of information. I think it's...more like fall of the Roman empire, right? It's like Rome is all right, Rome still partying, the borders are still expanding, but you also have cities being lost and\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"being lost and whole countries going off the map. I think that's happening. You have Uber AI shutting down, AI research, you have hiring freezes at major companies. The big leaders are having major hiring freezes, not offering the kinds of salaries in 2022 that they were offering in 2018 to well-known researchers. And at the same time, you have whole companies where the shockwave hasn't even hit them yet. And they're first getting into... Like major health systems are starting to adopt deep\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"to adopt deep learning. And I think that, yeah, there's that going on.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"If I had to predict what's going to happen, I'm going to double down on decision-making. I think something I'm already seeing a lot of is...you could think of-- a few things came together that made AI so hot, which is one, was suddenly the fact that the existence of easily queryable well-organized curated data at every single firm in the world. The fact that health companies started using electronic health records; every company being basically an internet company; everyone having a digital\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='having a digital trace of all their customer interactions. Now, we can get to a separate normative point about whether we want to live in that world or whether we\\'re irked by the surveillance state. But from an economic standpoint, that happened together with advances in both the tooling and algorithms around statistical modeling. And so,the question became, \"We have this data, we have statistical tools, how do we do this analytics on the data?\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='But there\\'s another side, which is like, \"How do we use the data to guide actions?\" And I think one thing that is underutilized by most firms--and I mean only a small number of people are really sophisticated about it--is really focusing on this, the decision problem. And part of that is offline causal inference, which is some of the stuff we were talking about. Like how can I use some causal background knowledge together with the data that I have to infer a causal effect and then use that to', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"and then use that to guide decision? But a huge part of that is experimentation. And I think that this is a huge thing that not enough companies do that you're going to start seeing become... obviously, like Amazon, has what they call web labs. Google does randomized controlled trials for which shade of green the G should be in Google or something. But I think most companies grossly underutilize experimentation, like really methodical experiments because that plays into the data picture.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[01:09:45] Sam Charrington: Online experiments in particular?', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='Well online, not necessarily in the sense--I think online as part of--in the sense of doing reinforcement learning and having a policy that\\'s adaptive as you\\'re getting the results. But even experimenting at all, right? Like if you look at how we guide personalized decisions, it\\'s often in the context of, \"I just take passively collected traces of people\\'s data. I do some kind of latent factor analysis or whatever to build a recommender system,\" versus actually, \"I\\'m going to randomize choices', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='to randomize choices and try to estimate the sort of potentially heterogeneous treatment effects of how different people respond differently to different things,\" but actually to estimate the effects on whether it\\'s people\\'s behavior or whatever. I don\\'t mean this to sound like I\\'m advising that we willy-nilly experiment on people without thinking about the considerations or which decisions or which experiments are potentially of ethical import. And obviously, there\\'s a lot of considerations', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='of considerations that need to go into how you do that and doing it right.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[01:10:52] Zack Lipton: But yeah, I think that the reckoning we\\'re seeing, I think, is over and over again, it\\'s people claiming that AI is going to personalize this, personalized that. It\\'s gonna lead you to make all these different decisions in better ways. And then people find like, \"Oh, I just naively trained a predictive model, came up with some heuristic for how to operationalize that as a decision and something didn\\'t go as planned.\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='I think that people are actually getting more into this world of both using offline...causal inference on observational data, but also actually experimenting in the real world and developing more mature processes for saying, \"How do I test hypothesis? How do I see what the impacts are of different actions that I have?\" I think that that\\'s going to become more and more important and you\\'re going to start seeing the hiring focus in just where teams start moving towards those kinds of problems.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And again, I don't think this is overnight, you're going to go from people hiring 90%, deep learning, PyTorch jockeys to 90% hiring experts in bounded algorithms and causal inference. But I do think that there's a shift here. I'm seeing it at every level. I'm seeing it in what looks interesting among new students? What looks interesting among folks hitting a hiring market? I think that this sort of intersection of CS, operations research, economics and bringing to bear tools of predictive\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"tools of predictive modeling that we've gotten, but also more sophisticated processes of experimentation and estimating causal effects and principles of just guiding intelligent decision making. I think there's a growing up process happening there.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"I think the other thing though, is I think I'd add on--and this is not a specific prediction, but a meta prediction is...the Internet, like Web 2.0 Web 3.0, whatever the hell we're doing. There's a lot of new stuff that we're seeing in the way companies are behaving, in the way they're interacting with people that isn't technologically new. There's a lot of stuff that you could have done from the late 1990s. The tooling wasn't as there, which restricted how many people could develop it. But it\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='develop it. But it was something else. It was something about--there was a capability that came and a few people have figured out--some early players that figured out how to conquer e-commerce like Amazon, whatever. But it took a long time before you got to Uber.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And so, there are certain innovations there that were...it\\'s like were a bunch of pieces that need to fit together, like a certain understanding of markets or a certain understanding of usage patterns of phones with technological capability that had been there all along. And I think that there\\'s a kind of innovation in deployment that doesn\\'t actually correspond. I think when people have been stoked about ML recently, right? It\\'s been like,\"Oh, BERT is good at classifying texts or, seq2seq,', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='texts or, seq2seq, LSTMS and then transformers are good at this one thing.\" There\\'s single purpose models.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"But I'll give you an example. So, I'm an advisor for companies that's full COI. I'm an advisor for a company called Abridge AI. And Abridge is a company that is sitting between doctors and the patients, and sitting in this interaction where patients--it turns out patients are basically recording their visits on their cell phones. And they're doing this already. Sometimes surreptitiously sometimes with the doctor's consent. It may or may not be wiretapping depending upon what your state,\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='what your state, two-party system is. So, their idea was like, \"Let\\'s inline this as a normal part of the doctor-patient interaction. Let\\'s have permission, let\\'s have both parties get in, they\\'ll agree to record the conversation. They\\'ll pull out Abridge and then they record it.\" And there\\'s all kinds of different things you could do, right? Like you can help the doctor to draft the summary of the visit. You can help the patient to understand like, \"Oh don\\'t forget, you mentioned that you would', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='that you would be starting this new medication. Have you picked it up or have you called in that prescription? Or did you schedule out this follow-up?\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='So, there\\'s a million different places to plug in models and any one of them by itself may or may not be a single purpose major innovation. But the ways that you can mix and match these like, \"Okay, I\\'ve got the conversation, I\\'ve got to send it to an ASR model. I get back the text. Of the text, I need a flag out what are the relevant or salient parts of the conversation? How do I then take that, turn it into an interface feature that provides some value or make things useful to the patient?\"', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And I think that like a lot of things, like when Alexa works really well, or Google Home or any of these things, when it works really well, it's usually not because there's one model that's magnificent. It's like the magic is in the clever way that they stitched together some astute observations about what are the common interaction patterns together with what were the right little places you could patch it in machine learning and the right ways that you can patch in some intelligence heuristics\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='heuristics and rules around it, such that you have an end-to-end product that feels like it\\'s magic? Shazam even is a little bit like that. One of these things where there\\'s a few little heuristics where if you start thinking, \"How do I decompose this into something that works?\" you can make a pipeline where every single step of it\\'s simple, but the end result is something where it feels a little bit magical.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"And I think that this is going to be...I think a major part of this is I think we've been looking at people who are really good at building single purpose models, then turning that into a big startup or are trying to turn parlay that into a startup. And I think there will be some amount of the single purpose models are mature and will get a little bit better. But what's maybe under explored a bit are ways that you mix and match models together with cool interaction patterns and some clever\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"and some clever understanding of what people want, what data's available, et cetera, to build user experiences that maybe under the hood are invoking seven different models in seven different contexts but it's hidden from the user in a clever way where it just feels like you're having...like it adds up to a new capability that no one model or piece of software by itself would provide.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And so, I do think that there is some elements of this. Like we\\'ve built a bunch of cool Legos and we haven\\'t given people that many years to...instead of--some innovation comes from like, \"I designed a new Lego piece,\" but I think a lot of innovation will come from people that don\\'t have to have off-the-charts skills at building Legos, but they have a kind of design sentence for what are cool ways to put them together.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[01:18:33] Sam Charrington: I think that\\'s a natural consequence of the broader maturity conversation we\\'ve been having. The Lego pieces are--not that we\\'ve come up with every Lego piece that\\'s ever going to be created and that there aren\\'t some cool ones to come. But all the basic pieces required to build really cool stuff is in place. And now it\\'s all about, \"How do you put them together?\" Yeah and even more so than the pieces themselves, the tools to easily put them in place. You\\'ve got your', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"You've got your Hugging Faces. You've got your ML ops tools. It's a great time to be a builder.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[01:19:08] Zack Lipton: Yeah. It also takes some of that work away that allows you to focus. I think music\\'s that a little bit, right? this way when you\\'re learning an instrument and you\\'re like, \"I gotta practice articulation, I gotta practice rudiments. I gotta practice scales. I got to do that.\" Then you\\'re sitting there going de-do-de-do...playing this kind of shit over and over again when you\\'re like 10, 11, 12, 13, 14 years old. But you get to some point where maybe you still practice that', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"still practice that one hour a day, but when you go to play, you're not even thinking at that level at all.\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='And I think there is some element of that, of people using machine. Like recently I\\'ve been thinking just like, \"How do I get the data and train a single model?\" I think once you have a lot of these contexts where--maybe you don\\'t even need to train a model, maybe there\\'s an off-the-shelf model that\\'s sufficiently good at this task and it works better than anything you could train even if you\\'re applying it sort of on slightly different domain-shifted data. Then, you start getting to this point', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"to this point where...the difference between a great artist and a super boring artist isn't that the great artist is better at scales. It's not...at some point...it's not like Miles Davis plays cleaner scales than...\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[01:20:23] Sam Charrington: These These state-of-the-art is staying on key or something like that? It's not like that.\\n\\n[01:20:28] Zack Lipton: Yeah so, I think there is a lot of innovation to be had on that side.\\n\\n[01:20:37] Sam Charrington: Yeah. Awesome. Awesome. Well, Zach, it has been wonderful catching up. Let's make sure it's not two years until the next time.\\n\\n[01:20:47] Zack Lipton: Yeah. Who knows what pandemic will be in by that time?\", metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content='[01:20:52] Sam Charrington: Awesome. Well, thanks so much for helping us reflect on 2021 in the ML and DL domains and catch you next time.\\n\\n[01:21:04] Zack Lipton: Yeah, thanks for having me, Sam. Great to see you.\\n\\n[01:21:06] Sam Charrington: Thank you.', metadata={'source': 'content/data/556 - Zack Lipton.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: All right, everyone. I am, of course, Sam Charrington, host of the TWIML AI Podcast. Today, we're joined by a friend of the show, Kamyar Azizzadenesheli, Assistant Professor at Purdue University for AI Rewind 2021 Deep Reinforcement Learning. Of course, in our AI Rewind series, we talked through the trends and advancements in each of the fields we cover, as well as what's in store for 2022 and beyond.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Kamyar last joined us for the reinforcement learning office hour session we held in conjunction with TWIMLFest in 2020, which was, by the way, a great session. We'll link to that in the show notes. I'm super excited to have him join us again today. Kamyar, welcome back to the TWIML AI Podcast.\\n\\n[00:01:00] Kamyar Azizzadenesheli: Hi, Sam. Thank you. Thank you so much for the introduction. Thanks for having me today.\\n\\n[00:01:05] Sam Charrington: I'm really looking forward to diving into our chat.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"You pulled together a lot of great material for us to talk through. The bulk of our time will be spent talking through the four key themes that you identified as being important for RL in 2021. But before we do that, I'd love to have you catch us up. The last time we spoke, you had just graduated from Caltech and transitioned over to Purdue. How's that been going?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:01:31] Kamyar Azizzadenesheli: Well, everything is going well. I was actually visiting research at Caltech at the time. It's been an interesting year. So the pandemic part, I would not talk about it. It was like hard part, but excluding the pandemic part, everything was fantastic. The transition to Purdue was awesome.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Building collaborations with many people across the country or across the globe, all of them were fantastic. Great colleagues here, great friends here really enjoyed, and my students are amazing here, so I'm working with them, and we are doing really, really nice stuff these days.\\n\\n[00:02:15] Sam Charrington: That's great. That's great.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Well, to ease us into the topic, maybe you can generally characterize the past year in RL. Was it a big year, slow year? Broad brush strokes. What was your takeaway about the field?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:02:32] Kamyar Azizzadenesheli: So we had amazing years in 2015/16/17 and 2018. In the last two years we had another two or more amazing years, but it was interesting in the sense that we have made many theoretical development in the last two years from practical standpoint, we have done so many advancements and so many technologies emerged, but if you want me to compare again with stuff happening in NLP. Probably we were a little bit less in the media. I would say there were so many great', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='were so many great progress in field of RL, but not as much coverage at NLP [inaudible] in last two years.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:03:24] Sam Charrington: Do you think that was just because of the transformative nature of what was happening in NLP or because the advancements in RL were more academic, less easily applicable?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:03:40] Kamyar Azizzadenesheli: I think it was mainly we have made many great advancements in the last few years, but these two years, mostly we've been focusing to harvest them. So there have been many technological advancement. Now we are basically taking them to practice and there were so many great theoretical advancements, but these days we're actually harvesting them. Basically, we are using many of those to make many advancements, and which I don't know, it's like my work being flashy\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='my work being flashy everywhere. But for some reason they did not get to be so flashy. Also in last two years, we have been not going to conferences, so we did not get to share with each other what have happened in the last two years. Unless something is so flashy, they make it to the public easily, but other stuff that we do, they might need it to be communicated among people and get boosted up. But since we were not going around and talking with each other in meeting and hanging out, that', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='hanging out, that might also be a reason for things to little bit not be on the media that much.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:05:09] Sam Charrington: If you had to pick out one or two of the most flashy developments in the field, what would those be?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:05:17] Kamyar Azizzadenesheli: So one of them is this recent adoption of reinforcement learning methods in robotics. In robotics in last two years, I've been observing, okay. Despite the fact that many, many researchers were not able to go to their labs to run experiments for robotics, there have been great progress in the field of robotics mainly due to the deployment of RL methods, or I would not say deployment.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='The people in field of robotics are so great in knowing topics in RL that they develop RL algorithms for their problems. These developments actually made it possible to make many fundamental advancement in robotics. For example, now you can have drones flying weirdly with everything guaranteed, and not just plug and play. Everything is guaranteed. You can have many robots actually walking in different trains and mainly all of these things are made possible using learning methods. So this is one', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So this is one flashy thing happened last year.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:06:35] Sam Charrington: Actually, let me pause you because that's getting into one of the areas that you identified as a theme. So let's just stick with that for a second and dig a little bit deeper. We'll include in the show notes links to a bunch of the papers that we'll be talking about, or as close to all of the papers that we're talking about, and demos as we can so be sure to check out the show notes, but you mentioned with regard to the drones that well... there's one paper and video\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"one paper and video that we'll share that's high speed RL controlled flight through a dense forest. That was really interesting.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"You just mentioned guarantees. Talk a little bit about the guarantees aspect of that. What does that offer?\\n\\n[00:07:27] Kamyar Azizzadenesheli: So that's a really good question. It has two folds to it. Many people in robotics, when they want to deploy an algorithm, they want to make sure that the algorithm works guaranteed, not just by chance. They want the algorithm to be there and work for sure.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Okay. So this is one of the things that they actually need for many applications. You might call it cultural thing. It has been there for many decades. If you want to propose a robotics algorithm that is acceptable to robotics, roboticists, basically, most of them, they require you to provide a guaranteed algorithm or basic guarantee that your algorithm works.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So the good thing is one of the thing that prevented a roboticist to adopt methods with developing machine learning was the fact that we're not seeing a way to get guaranteed algorithms out of them. Okay. But in last few years, there have been many amazing researchers in robotics with robotics and control background who are now, I would say expert in machine learning. They can develop algorithms in some topics way better than I would do.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"They are actually behind all these improvement and advancements, and they are able to deploy and develop reinforcement learning or general machine learning algorithms that can be used in robotics. Robotic control that is actually guaranteed to work. What happens when things are guaranteed to work is for example, you can, if you have an algorithm which is guaranteed to work, you can deploy it in a very extreme scenario. For example, extreme unknown wind. You're having a drone which was supposed\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"which was supposed to fly in a weird situation. If you have an algorithm, which is guaranteed, I'm not just saying some guaranteed are actually guaranteed to work right away. You just plug and play. You just deploy algorithm in the wild. It works. You don't need to crash your drone and might cost you millions, not millions. Like thousands of dollars. You don't need to spend so much time tuning. Everything will work right. So this is one thing that a roboticist they would like to have as for\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='like to have as for their algorithms.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:09:53] Sam Charrington: What's the next level of detail or technical detail around a guarantee? It strikes me that that's fairly ambiguous. Are we talking about guaranteed convergence, guaranteed predictions around control within a certain range, or something else?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:10:20] Kamyar Azizzadenesheli: So the guarantees are mainly about the stability and the performance. So when you come up with the policy to control a drone, one thing that practitioners would ask you immediately is would you guarantee that this controller is stable? Or you have a walking robot, you can guarantee that this controller would not crash or would not fall, would not hit, or the action that in the control system, the actions can go to infinity mathematically. So do you have a', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So do you have a guarantee that your machine is not going to overshoot to some unknown region? For example, if you have a drone, you're not going to have a power of 10,000 times what is allowed, and the drone might crash or the engine might just burn down. So these are the types of guarantees for the stability, and the performance guarantee is like how far you're from what you actually desire to be.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So this is, for example, if I have a drone is going to fly to do weird maneuver in extreme wind and follow a specific pathway. Can I guarantee that this drone would do that if I use a machine learning model inside the closed loop control. So these are type of guarantees that we are talking about.\\n\\n[00:11:55] Sam Charrington: What are the techniques that have been developed that allow us to now provide these kinds of guarantees?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:12:01] Kamyar Azizzadenesheli: One of the coolest one I'm aware of is the notion of Lipschitz. So if you have a deep neural network to model... Let's put it this way. I can talk about one of the works that I'm fully aware of. So let's say you have a drone. This drone is trying to land. When this drone gets close to land or it gets close to ceiling, this air circulation, the circulation of air through the wings of the drone imposes many veered fluid dynamics space like a pattern that's\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"a pattern that's Newton's Law would not easily give you.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Newton's Law that you have actually put in the motion equation for the drone. So those are not there. So can you use machinery models to learn this residual pattern or whatever it is, this thing, the circulation of air results in the drone maneuver? Can you learn those things using deep neural networks?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"That's we know we can learn but the thing is, can you make sure that these neural networks that you're using is Lipschitz? If this neural network is Lipschitz, which you can use some techniques like self normalization or other techniques that make sure that the neural network is Lipschitz, given this, you can actually prove that whatever controller you get is going to be robust. This is one of the things you would get as a guarantee.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:13:27] Sam Charrington: Your ability to guarantee that the neural network has Lipschitz is around the way you formulate your cost functions and things like that?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:13:39] Kamyar Azizzadenesheli: Your former, the cost function and the architecture. So both of them together, I don't want to have soft guarantee. I want to nearness. If I put it up in the cost function, it becomes a soft guarantee. I want to put it built in the architecture that is going to be for Lipschitz function. I know, I want to know what is that Lipschitz constant. If I know all of these things that can go and design a controller, but the result of it is going to be, after doing all\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"be, after doing all these training, the first time you deployed the machine in the wild means the first time you deployed a drone or a robot in the wild, it's going to work right away. You don't need to spend two months or five months or two years of fine tuning.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:14:22] Sam Charrington: Yeah. Historically, one of the things that has prevented us from taking things out of training and putting them into production and having them work right away is the whole idea of, call it what you will, generalization domain adaptation. Like the real world is different from the environments that we train on. It sounds like the guarantees are strong enough that they overcome that issue is that the case?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:14:50] Kamyar Azizzadenesheli: Yes, it is the case. Also the expertise in roboticist machine learning expertise in roboticist researcher is a second thing. For example, this problem that'd be brought up. That's when you train things in the lab and when you change the situation, things break down.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='The recent advancement that people in robotics made is like this new era of doing some online metal learning on the fly. So there are many algorithms they proposed recently that you actually can learn if setting that can adapt extremely fast to a new scenario. For example, that VIN condition problem I was talking about.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"You are flying a drone in extreme wind scenario and the VIN. What does that mean? You, in your training, you probably had five or 10 wind condition, but in the wild it keep changing is going to create this turbulent flow. It's going to be extremely hard and there are known as well. They came here at rosary. They chosen to, okay can you come with an algorithm which can adapt to any wind condition on the fly? So these, for example, one of these cool algorithms with, again, learning theoretic\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='learning theoretic guarantees have been there, look by it about assists and control theorists who are extremely well, an expert in machine learning, basically this, okay.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='There is a general theme and thread trend in reinforcement learning these days that people use the basic topics and core topics in reinforcement learning and take them all and develop problem specific algorithms. This is one of the general themes these days in reinforcement learning. Eight years ago, when I was doing reinforcement and I started doing reinforcement learning, we were like, find the hardest problem ever could exist and try to have an algorithm solve that.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"This was a theme when I started working in reinforcement learning and was the main theme for many years to come up with principle algorithms, which actually works for worst case even like not even earth or the universe, like whatever, can mathematically be hard. It's going to work for that.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='But these days people are like, \"Hey, let\\'s use all those principles that we have developed in last, I don\\'t know, 30 years or 40 years, and take them to design and develop problem specific algorithms.\" So this is one of them, like you want to fly a drone and you want to be fast and adaptive. You want to be a robust go and design your rL algorithm. Given those principles design your RL algorithm to do such. So this is a interesting trend at that I really like.D', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:17:40] Sam Charrington: I'll encourage folks once again to check out the learning high-speed flight in the wild video. It is super impressive that drone is going fast and the trajectory is a lot smoother than if you saw a drone ML controlled drone video.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"A couple of years ago, it was like a lot of stops and starts and things like that. This is pretty, pretty smooth. The robotics topic that we were just talking about is related to another area that you identified as a key theme in RL over the past couple of years and that's advances in control. Can you talk a little bit about what you see happening in control?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:18:23] Kamyar Azizzadenesheli: Yeah, definitely. Well, control theory arguably is one of them, one of those oldest settings or problems study that firstly asked about how we can come up with a policy that can do something. So the field of cybernetic used to be called was around this idea that how we can actually come up with a way to control a system.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='This problem has been there for almost ever. You can find books that are like haven\\'t been opened for like last 60 years. This is how old is this topic but the thing is, this topic did this problem with control theory. It\\'s been there for long time and there have been so many improvement and amazing developments in the end in that field, but recently specific in last two, three years, many reinforcement learning folks there were, and basically learning theory folks, they were asking, \"Hey,', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='were asking, \"Hey, almost all of the control theory is about the setting that you\\'re not going to learn anything.\"', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"You are. Everything is given in advance and there's no learnings involved. So I give you a model or the 10 environment, the parameters, everything. I asked you to come up with the optimal controller. Of course, there are settings like adaptive control that you would learn, but those settings were not that established yet.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"In last few years, many of us started to learn many things in control theory, and try to see whether we can frame them as reinforcement learning problems. So now in this problem, like three years ago, we were like we don't know how to solve control problems when they don't know and we don't know the environment. Now we actually know a lot too today. We know a lot about how to control at a control system, bid out, knowing the parameters of, or how the environment works in advance. Basically we've\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Basically we've literally turn the problem to a reinforcement and a problem that things are unknown in advance.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"You're going to interact with the system, learn how the system works. Given that come up with a good controller, which actually can establish a system. The system does not blow up and maintain some guarantees that you want. So this was one of the things that happened in last few years, and it's a theme because it's one of those areas that machine learning got involved and, control theorists. They were extremely welcoming, and there are many works in this area of learning and control that\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"and control that actually drive by control theories that I'm actually extremely excited and they actually have a new conference called L four DC.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So there's a new theme of research. That's basically goes back, and there are many problems in the world. There are control theory problems that nuclear power, then you want to control it. You need to have a control theory. Problem is as soon as you want to send human to moon. You have a control problem there if you want to, I don't know anything or you want to control...\\n\\n[00:22:08] Sam Charrington: Any of the robots we we're just talking about.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:22:11] Kamyar Azizzadenesheli: Robots or big things like data centers, the cooling of data centers. You want to control those basic, all of these things are controlled problems, but what we did, the new theme is like, \"Hey, great, Pete back backing the time people were going and analyzing the model and come on with the model themselves and then design the controller.\" Now what you\\'re saying is like, \"Hey, you don\\'t need to spend five years doing that. You or doing the designing or', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='the designing or understanding the model, just give it to them, to the RL algorithm. It would do it. The question is, how are all going with do it? These are these are the things that researchers these days are working on and they have developed many algorithms for, and some of them were really surprising and some of them were changing the topics.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Basically, for example, there is a topic in control theory called robust control which is, it\\'s been main thing for control theory for almost ever. A recent thing, like last two years, we actually altered the definition of it. We were like, \"Okay, robust control, fine. But we don\\'t want it.\\n\\n[00:23:16] Sam Charrington: What did it mean before? What does it mean now?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:23:19] Kamyar Azizzadenesheli: So the thing it was saying before was, I give you a system to control. Let's put it in the RL context.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='I give you an RL environment that you don\\'t know exactly how the environment works, but I give you an estimate of the environment. But the true environment is going to slightly vary from this environment. So one question you can answer is, \"Can you come up with a policy or controller which is when I applied a controller is going to work for even the worst choice of this environment?\"', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So I give you an estimate of the environment, but the two, I also tell you the true environment is like somewhere closer to this is estimated environment.\\n\\n[00:24:12] Sam Charrington: When you say an estimate of the environment, is it the state of the environment that is unknown or is it the whatever you're trying to optimize, the score or the performance?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:24:26] Kamyar Azizzadenesheli: Let's say the dynamics of the environment is not clear to you. So if I have a cup of water in my hand, if I want to lift it, I would expect the glass go two centimeter up but it might go one centimeter and a half. So this is the uncertainty I have about the environment itself or uncertainty I have about them [inaudible] noise. There's a noise in the environment. I have uncertainty about that. So these are the things that are not models. Basically, these are\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Basically, these are unknown to me, so I don't know how exactly the environment works. In my mind, if I lift this cup of water, it should go two centimeter up. But when I do, and I apply my action on this environment, the cup of water goes up one centimeter and a half.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So this is basically, there's a discrepancy between what happens in the world and what you have in mind. So the robust control says, you have an estimate of the model mind. The two environment is not the exact estimate you have. The true environment is somewhat close to it, but you don't know what is it, but what you do, you make it a min-max problem.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='You try to find a controller which works for the worst possible that can happen. When you come with a controller, when you apply that controller, then environment might be a good environment or might be a worst environment around the estimate you have in your mind. So you were trying to come up with a robust way of doing it.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='You will say, \"Okay. I don\\'t know what is the true environment but I know it\\'s close to the estimate I have. So I try to find worst environment possible close to my estimate, and I try to be best for that. Somehow, what it means is whatever controller you\\'re going to use is going to do somewhat good for any environment, these set up environments that are possible.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So this was a robust control that has been there since the sixties. So basically solving min-max problem. I don't know how the environment works, but I hypothesize is going to be the worst possible that can happen to me, and I want to find a controller which actually solve all the environments there.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='This one is going to be bad in a sense that if you want to robust yourself against the worst thing that can happen, the control you are going to get is going to be really conservative. But this was a practice for 60 years. Yeah. But in last two years we were saying like, \"Hey, good, fine.\" You can design a controller at the beginning, which is going to be robust to whatever is going to happen in the future. But if you run your controller for 10 times steps and you realize that the environment is', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"the environment is not that bad, update it. You don't need to keep running that very conservative controller for next 55 billion years. After like few time steps, if you realize the environment is not that bad, you don't need to robustify by yourself against something that is worse. You can just robustify yourself against the worst is going to happen. Not the worst that would have happened.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='In robust control, we were saying that I want to be robust against the worst that could have happened to me. But what we have been saying recently is, \"Hey, you don\\'t need to be that conservative. You just make yourself robust against what the worst is going to happen to you.\"\\n\\n[00:28:06] Sam Charrington: So it\\'s like you based on the observed data, you try to identify a distribution and be robust for that as opposed to the worst possible.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:28:15] Kamyar Azizzadenesheli: Yeah. Yeah. Worst possible is there, but if I interact with the environment, the uncertain is not that bad. My estimate is not that bad. Just update myself, be more relaxed, and this is going to work in practice very well. So this was one of the themes that I really liked that happened last year.\\n\\n[00:28:34] Sam Charrington: Is there a name for this? It sounds like it should be called meta robust learning or something like that.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:28:41] Kamyar Azizzadenesheli: I think it's called improper learning and control.\\n\\n[00:28:47] Sam Charrington: Is that the improper learning for non stochastic control formulation?\\n\\n[00:28:50] Kamyar Azizzadenesheli: [Inaudible] his group and others.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:28:57] Sam Charrington: One of the things that I saw in taking a look at that paper was they talked a little bit about this arc and control from classical control, which you described earlier. You know all the parameters of the thing that you're trying to control to stochastic control, which, there's now some noise in the system, but it's random noise.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='This paper was really geared around non stochastic control, which as opposed to assuming just noise injected, it assumes adversarial perturbances. Is that non stochastic control formulation? Is that newer? Can you talk a little bit about this like assumption of adversarial perturbance versus noise?\\n\\n[00:29:52] Kamyar Azizzadenesheli: Yeah, sure, definitely.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"In that paper, you make this assumption that things are adversarial because you want to be robust against the worst that can happen to you. So assuming things are adversarial has been there in control forever. But they were saying you don't need to robustify yourself against that adversarial noises or adversarial changes or perturbation in the model via looking what happens to you.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='They were saying that, \"Hey, look, what happens to you?\" You can adapt to the noise, to that research noise as well. So this was one of the things, but when you make things noisy... basically you make this thing to be a stochastic noise, you can do many things. Making things a stochastic noise has been there forever.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Like when we send human to moon, we used a model called LQG - Linear Quadratic Gaussian. Yeah. So this model basically solved by Coleman and others back in age of dinosaurs many years ago. So this model, this solution, sorry, this setting is noises;, noise is stochastic. You're trying to come up with a controller for the setting that the noise is stochastic.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So the noise in the system is stochastic, it's not adversarial. Coleman was able to give a solution to this problem. So you know the environment. You know the noise is Gaussian, and for that, you can come up with the optimal control design. People did it. People sent human to moon with this exact solution.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"But the interesting thing is now assume that for the same model, for the parameters of the model, I don't tell you what is the dynamics. Can you use data to learn the dynamics? It's basic machine learning question. I dug down so many books from many years ago. I talked to many colleagues in control theory. There was no solution for it.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='If I give you the few samples and I asked you, \"Hey, can you estimate the model parameters of that thing we use to send human to moon?\" I couldn\\'t find anything. This was another big innovation in machine learning and intersection of reinforcement learning and control that happened two years ago and also keep happening last year and also these days. That\\'s people now actually proposing interesting and weird and cool algorithms to be able to learn the parameters of the dynamical systems that are', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='systems that are heavily used in practice. These are new things like now we know how to learn the model of that system that we used to send human to moon.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"What does it mean? It means that now if you want to deal with a new system. So for that system, we had many years of experience, hundreds of engineers. They were like tweaking things to come up with the parameters. Now with this new machineries that we have, you don't need five years of engineering and hundreds of engineers to go and tweak things to see what are the parameters of the model. You can directly deploy these algorithms to actually directly learn the parameters of the model. So the\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='of the model. So the machine itself learns everything, which is very exciting.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:33:37] Sam Charrington: Is the paper, that is, the best exemplifies that, is that algorithmic regret bound and partially observable linear dynamical systems?\\n\\n[00:33:48] Kamyar Azizzadenesheli: That's a paper first proposes how to learn the dynamics of this partially observable control systems that you were saying, there's a noise in the system. We don't observe everything. The state is noisy and you don't observe everything, which is the same model of people using sending human to moon.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='For that setting, this paper actually shows how to learn the parameters of the model. The interesting thing is, after being able to learn the parameters of the model with the algorithms proposing that paper, you can actually get a controller which controls the system without knowing the system in advance such that the performance is almost identical to the performance of the optimal goals.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So this algorithm learns so fast, basically exponential fast. It learns everything, the optimal controller exponentially fast, which is weird. It's able to do that, which is I like it a lot.\\n\\n[00:34:48] Sam Charrington: Learning the environment and learning the controller, is that happening in parallel or in the same loop or are they serialized steps?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:35:00] Kamyar Azizzadenesheli: In the same loop. It happened in the same loop and interesting observation there is, in order to come up with a good controller, you don't need to learn the model very well. If you have some idea about the model, you can come up with a really good controller. That was another observation in that paper. You learn a model with a rate of one over number of square root of number of samples, but your controller would converse the good controller exponentially fast,\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='exponentially fast, which was another cool thing.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:35:33] Sam Charrington: That strikes me as counterintuitive in the sense of learning a controller has been hard for a long time, even when we were given the model.\\n\\nSo how is it that not knowing the model and learning it, but not very well, gives us good performance and allows us to learn a good performing controller?\\n\\n[00:35:58] Kamyar Azizzadenesheli: That's a very, very good question. So it's like, you don't know exactly what is a model, but the cost function here is something convex.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So we were talking about Linear Quadratic Gaussian. So the cost function is quadratic. It's called regulatory costs in the sense that it's quadratic in the sense that if you're away from it, you get penalized, the distance is squared. So if you are too far, you're going to get penalized even higher.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So now you have a model, some estimate of the model, you deployed your policy, your controller in the real world, and the deviation is large. Your model is not accurate, but when you deploy your controller on the environment, the deviation you get is large. So you are not going to use the optimal policy of the model you're using. You're using a policy, which getting some information about the model you learn. Such a venue applied on the real world is not going to deviate too much. So it's\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"too much. So it's different from the paradigm we have been using in classical reinforcement learning algorithm that you come over the estimate of the model, and then build a confidence interval, and find a model in that confidence interval, and then find a policy for that model. This was a paradigm we have been using, but in this paper we were saying that, no, you estimate the model, good. Use this controller that is going to do well on this environment, on the real world. If it's not performing\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"it's not performing well, make it better. Despite the fact that you don't know the real world.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:37:36] Sam Charrington: The initial estimate of the models, like an initialization, as opposed to something that you're fixed on.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:37:43] Kamyar Azizzadenesheli: Yes. Yes. So you have a initialization of the model in your... you have basic estimate. You [come] with the controller, you applied a controller on the world, take five samples. You see the deviation is really large. What you do, you do not just keep looking at it. You update it. How you update it, gradient descent. You literally do gradient descent to update it. The controller here you come up with is actually great in the sense based controller. You're not\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"You're not doing, you don't do anything fancy. You just do SGD. Everything works.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='This was another cool thing happened. These works actually opened so many new doors for many people in control theory and reinforcement learning. In general, machine learning. Now they can, given these tools, you can go and develop many things.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"For example, knowing how to learn this partially observable linear dynamical systems. So these settings are partially observable. Linear dynamical system. They are linear because dynamics is linear. They are partially observable because of the example you gave, then the estate is noisy. You don't exactly observe the state.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Now people are developing all sorts of algorithms for these settings because now we know how to design a controller and we also know how to learn the dynamics. People took this stuff to nonlinear control as well. So now we also know how to control nonlinear control problems. If this interview was in two months, I could share many weirdly cool news with you, but maybe next time.\\n\\n[00:39:13] Sam Charrington: Awesome. Awesome.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"One of the other areas that you identified is risk sensitive RL. Talk a little bit about the shifts that you've been seeing in the way where optimizing these are a problem.\\n\\n[00:39:28] Kamyar Azizzadenesheli: Yeah. So this is where good, and I hope that the audience would also see it. Sometimes my friends, they told me that I'm good at finding these seeds happening in machine learning field that start growing and blooming. I think, I hope that my prediction is correct for this one.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:39:47] Sam Charrington: This is one of them?\\n\\n[00:39:49] Kamyar Azizzadenesheli: I think this is, I mean, I'm going to make a prediction, but I made so many predictions before. I hope this one works as well. If it doesn't, I apologize for those folks that were looking for something which is going to be big but turned out not to be big, but okay, let me come and see...\\n\\n[00:40:08] Sam Charrington: It sounds like an important area.\\n\\n[00:40:11] Kamyar Azizzadenesheli: It is, it is.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:40:12] Sam Charrington: I\\'ll let you go ahead and describe it.\\n\\n[00:40:14] Kamyar Azizzadenesheli: It is insanely important. All the machine learning... Not all of them, almost all the machine learning stuff we have been doing in last, I don\\'t know, 80 years, they were around this idea that, \"Hey, I have a loss function. I want to maximize it, or I want to minimize it.\"', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"How I'm going to evaluate it. Look at the accuracy. This is what we have been doing in supervised learning. In reinforcement learning, give me an algorithm which maximizes the expected return. What I carry is expected return. Now you come to my office. Let's assume that I'm a healthcare practitioner.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='You tell me you have a prescription drug machine which is going to have 90% accuracy. I would ask you, \"Hey, what happened with that one percent? Are you going to make a small mistake or you\\'re going to kill the person?\" So it\\'s like your act, the expected value of your return is not the thing I would care in practice.\\n\\nI would care how you would do in different parts of the tail. So if your expected return is really high, good. What is your variance? It varies.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Let\\'s assume I\\'m a hedge fund holder or whatever it\\'s called, hedge fund manager, and you gave me a policy and you tell me, \"Hey, if I use this policy and expectation, I\\'m going to make $5 billion a year.\" Good. Ask where\\'s the variance or the variance is like or the standard deviation. If the standard division is like 10 billion then I\\'m not going to use it.\\n\\n[00:41:59] Sam Charrington: All right.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:41:59] Kamyar Azizzadenesheli: Or if you tell me this is the variance, let\\'s assume the variance is also low, but if I apply your policy in the real world, I\\'m going to make money every day, right? Some different money or can lose money every day. But if I look at 10% lower quantile, if it is going to be that 10% lower quantile is going to be like a humongous low. These are examples, or if you are deploying a policy in a societal setting or judiciary system, and you say, \"In this city, I use', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='\"In this city, I use this policy to help judges.\"', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Then you say, \"Okay, the crime or the vote of the people in the city increased by ten percent.\" Okay, great. But now I go and see five people in the city became billionaire. So the expected value is not that important. Ryan\\'s also may not be that important. 10% of 5% or even one percent upper quantile of my distribution was important.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So these are the things like now you give me a classification algorithm. I applied on my problem. Great. But I want to know what is the top two [inaudible]. When I show image of dog to you, you tell me you misclassified, how bad you misclassified. So this kind of things that actually, we care about the distribution of our performance, not just the performance itself.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So now what I think is, and also I\\'ve been working on it in this area is, and also there are so many works just happened last two years, weirdly just last two years, there have been bombards of papers in this area that people are asking, \"Hey, can I have a machine learning algorithm that is able to actually maximize different brisk functionals instead of just expected value?\" this is one thing.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Another thing is given my machine, can I evaluate the performance on my machine with respect to all sorts of risk functionals? If I'm a healthcare practitioner, you give me your policy. I was going to look at the past data and see what is this expected performance.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Now the question is, can I look at the top 10% contact? Can I locate this variance? Can I look at top 50 quantile? Can I look at different weird things about it and decide whether your machine is good or not? So these are things that, I think, people in practice need. This is aligned with that idea or theme I was saying that we are these days, we are trying to develop specialized machine learning methods.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So for here, we're trying to come up with specialized methods that practitioners are saying healthcare or in a stock market would be able to use.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Let me give you this example. I asked 20 companies to give me their drug prescription policies and I'm CDC. I'm going to adopt it. This is a hypothetical example. Now what I would do, I look at these 20 machines. I look at their expected value. I look at their variance. I look at many different risks quantities, and based on all of them, I'm going to decide which one is better. So first question comes up is whether the thing I'm doing is assessing that it's statistically valid or not.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"If I look at 10 billion different tests and run the 10 billion tests on these 20 machines, the result I'm going to get are going to be valid or not. These are questions that people are trying to answer these days. They have been trying to ask. Similarly, we're doing enforcement learning algorithms.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:46:05] Sam Charrington: It sounds like this is a broad movement or trend that you're seeing in machine learning. In the RL setting, how is it accommodated? What are some of the things people are doing?\\n\\n[00:46:21] Kamyar Azizzadenesheli: Actually, the interesting thing is most of the fundamental development happened actually from RL.\\n\\n[00:46:26] Sam Charrington: Happened in RL first?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:46:28] Kamyar Azizzadenesheli: Yes. Yes. So for example, this idea of this healthcare setting, you give me your policy. I want to evaluate the performance of your policy with respect to all the risk functionals. So this is a contextual bandit problem that these topics I'm talking about, they are mainly or so many other risk functionals. People have studied these things in the context of RL. People have studied in MDP and contextual bandit.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"These are what I am aware of, and there are so many impossibility result. There are so many positive results when you are using different risk functionals . There are many things out there coming from reinforcement learning, and now people are getting ideas and generalizing to general machine learning settings.\\n\\n[00:47:18] Sam Charrington: All right. Interesting, interesting.\\n\\nCan you give us an overview of some of the specific papers and the specific things that they're trying to accomplish?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:47:28] Kamyar Azizzadenesheli: Yeah, just one other point. The reason it actually emerged from reinforcement learning is most of these things arise when we were talking about decision-making.\\n\\nIf I'm going to make us come up with a policy for society, or if I'm going to come with a policy to be used in healthcare, I'm solving a reinforcement learning problem. So these type of questions basically came from reinforcement learning setting.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Another example I give you. In supervised learning, we don't talk about safety much. Safety is another constraint where we need to have. These safety mainly is talked about and developed in the field of reinforcement learning. I'm pretty sure people are taking these things to supervise learning as well because in supervised learning, safety is important, but these are more important issues in reinforcement learning.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Yeah. So these are basically some of the reasons why these things emerged from reinforcement learning, as some of the papers. So there are some papers that actually talk about at this risk functional that Daniel Kahneman and his colleague, they came up with this prospect theory that you would prefer to lose less than gain much, gain more basically. This is his whole idea of prospect theory is, if I give you $10 more, you're going to be less happy than if I get $10 from you. So this idea says,\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So this idea says, \"Hey, you don\\'t care about expected value. If you earn more, you\\'re going to be less happy than you are going to lose the same amount.\"', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So, therefore, the expected value is big. These things, they don't sum up. If you lose more, you're going to be really angry. If you gain the same amount, you're not, it's not going to compensate.\\n\\n[00:49:11] Sam Charrington: Right. So loss aversion should have a higher impact than the possibility of gain?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:49:15] Kamyar Azizzadenesheli: Yeah. So, yeah, exactly. So these are the things that now, if that's the case, if I want to come up with an RL algorithm for MDP, for contextual bandit, if I consider these things, what can I say?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Is it possible to learn a policy which maximizes the prospect theory objective function? Can I find, or is there impossibility results? There are some other things which come from KL divergence stuff which says, if you make more, you're going to be less happy than... So if you have some certain amount of money, if you make a little bit more, you're going to be more happy than making so much more.\\n\\n[00:50:03] Sam Charrington: Okay, saturating.\\n\\n[00:50:06] Kamyar Azizzadenesheli: Yes, exactly.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:50:07] Sam Charrington: That kind of idea.\\n\\n[00:50:08] Kamyar Azizzadenesheli: Yeah, exactly. So if you are going to use some ideas like that, can we get algorithms to work?\\n\\nSo these are risks specific settings. There are some other people working on the area that say, \"Hey, you\\'re interested in prospect theory? Good for you. You are interested with this exponential stuff or this marginalized the benefit of stuff? Good for you.\"', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Can we have a theory which actually answers question? We just spoke to all possible risk functional's ever developed. So in insurance premium design, there are people they talk about some risk functional called distorted risk functional. What is this? It just takes different part of the quantile and distort it, and then do the expectation of that distorted reward basically.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"In risk management, they look at things called CVaR. What is CVaR? It looks at, let's say expected value of your term off the 10% upper quantile. So I don't care what is your expected value you are going to make. If you're going to lose means that 10% lower quantile, what is the expected value there?\\n\\nSo this is another thing that people use is called...\\n\\n[00:51:29] Sam Charrington: Conditional Value at Risk, the CVaR.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[00:51:33] Kamyar Azizzadenesheli: Yes. Yes. Condition value at risk. So condition under your intent, lower 10% of the quantile. What is the conditional value of your money at risk? So these are the things my company cares about quantile of 10%. Your company cares about 15%. My company might care about 15%, 12%, 13%, 14%. All of them. My company might also care about the distorted risk functionals. My company might care about prospect theory risk function.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:52:04] Sam Charrington: Is the idea to be able to decouple any particular problem from the specific loss function or optimization functions so that you can get results for multiple ones at the same time? How exactly we're formulating the problem here?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:52:28] Kamyar Azizzadenesheli: That's a very good question. Now let's say I give you the past data dataset. My company has been working in healthcare for last 10 years. I look for last five months, and if I'm lucky, last 10 years. So I have five years of data, and now you give me many RL developed policies. I need to look at the performance of these policies with respect to all these risk functionals. Then I want to give me 20 policies. I use this dataset to evaluate the risk performance of\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='risk performance of all these 20 policies with respect to infinitely many risk functionals. Who designs those risk functionals? My experts in my company.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"They come up with all these risk functionals, that or tests basically. One of my expert says, let's look at the CVaR of 10%. Another one says, let's look and see what at 15%. I take these 20 policies and applied under my data and estimate all these quantities. After these guys, seeing all these numbers, they might come up with new tests, and after seeing those results of those tests, they might come with many new tests. Then in the end, they might choose one of these policies.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So this is the setting. I have this past data from like last five months, you or some other companies, they give me 20 RL policies and they tell me these are good. I'm going to go and talk with my expert to see whether they're good or not. So I'm going to use these policies and apply it on my past data, and see how they perform with respect to all these risk functionals.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:54:21] Sam Charrington: I'm not very clear on what makes this interesting from an RL perspective. Like the first thing we talked about was it's clear why that'd be interesting and important.\\n\\nYou want to develop a policy using RL, used to do it based on maximizing expected reward, but there are all these other things that you care about. How do you do those with RL?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"The second problem sounds like you have a policy. It could be RL policy. It could be any policy and you're just chugging your past data through the policy, and evaluating the results. What am I missing there?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:54:57] Kamyar Azizzadenesheli: The first setting is called online setting that you're actually using your RL around to design and come up with some policies. So these are those papers I talked about that they look at the different risk functionals. This set, the second setting I'm talking about that you have 20 policies, they can be expert design policies, they can be RL policies, whatever policies. This has got offline setting or off policy setting.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So I have the data, you give me policies. I want to evaluate them first before using them in practice. So I want to assess their performance before using them in practice. So this is we call off policy risk assessment problem. In short OPRA. It's like you have off policy data from the past or logged data.\\n\\nYou use that dataset to actually assess the performance of your policy. So this is a whole topic of off policy setting.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='We have off policy, policy evaluation. We have off policy, policy improvement. It means that I give you past data. I hire a new person. I show that person last 10 years of data, that person is supposed to give me a good policy.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"I'm not going to allow that person to deal with real world data real world system. I'm just going to give that person the last 10 years of data. So this is logged policy. I'm going to use to design a good policy. So this is called off policy, policy assessment. It's different from online setting that I'm like, I want to solve an Atari game. I want to go on in the wild, try different things at different situation to see what happens. This is a little bit different.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:56:39] Sam Charrington: I get that. I get the on policy versus off policy or online versus off policy. I also get the, there's also off policy training where you're developing the policy itself. I get that. What's not clear to me is why the assessment or the evaluation is an interesting problem. Like I'm thinking of it in the context of an inference. You're giving me data, I'm applying my policy. I get some results. What's the hard part there?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:57:19] Kamyar Azizzadenesheli: Oh, the hard part.\\n\\nSo the thing is, I have multiple policies and I applied them on my data, and I looked at the expected value. We know statistically that this estimate of the expected value is going to be close to it's mean, to the true expected value. Now you compute the variance. I go and look at the data.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='I want to compute the variance of the performance of each of those policies. I can do that and I can come up with an estimate that is going to be close to the true estimate. The first one was the expected value was close to the true estimated property like one minus delta.\\n\\nThe second one is also closer to the true estimate would probably be one minus delta, but both of them are valid estimates. [Priority] one minus two delta. So the priority that these are going to be correct became smaller.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Now you are asking me to test 1,000 different risk functionals. So all of them are going to be valid estimation with positive one minus 10,000 times delta.\\n\\nOkay, so now the question I'm asking, can we do these things with respect to infinity, many of these functionals? Why I care about infant functionals because if I show expected value and variance and see what of 10% to an expert, expert might design an arbitrary risk functional that I have not seen before.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So I want to come up with a way to estimate all the risk functionals - performance of my model with respect to all the risk functions - and make sure that the estimate I'm going to get is going to be valid estimation. This was not known before. This is a new thing that people are actually showed as possible.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:59:07] Sam Charrington: So it's the is managing the statistical assessment of the policy given a size of a dataset, number of runs. All of that and trying to get as much information as you can about all of these different things that you care about without compromising the validity of the estimates?\\n\\n[00:59:31] Kamyar Azizzadenesheli: Exactly.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"That's the exact way of putting. Also, one important thing is I want all these estimates, which I have infinitely many of them to all those estimate, I want them to hold simultaneously with the constant [inaudible]. So it's like, I don't want to say a compromise at all. I want to get all of them correct. Can I do that or not? So this was not known now in last two years, appeared that it's possible.\\n\\n[00:59:59] Sam Charrington: Got it. Got it.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So the fourth trend that you identified and we'll try to get through this one quickly is structured. MDPs what's that about?\\n\\n[01:00:09] Kamyar Azizzadenesheli: This is all very fascinating area, which is again align with the topic I was saying at the beginning that, that new theme trending in reinforcement learning is to come up and design more problem, specific algorithms.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Back in the time I was doing reinforcement learning. I mean, I'm still doing reinforcement learning. When I started doing reinforcement learning, we were trying to come up with [inaudible] which actually works for worst thing ever.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Nowadays, we\\'re saying, \"Hey, if you\\'re not dealing with the worst thing ever, we are dealing with the world and world is not as hard as things in mathematics can get. Why we are common withRL algorithms are going to work well against the worst thing can ever mathematically happen. So this is the idea behind a structure in reinforcement learning.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"This isn't a very old topic. But last two or three years, it became very... people got back to it basically. So, one of the things is called state abstraction. You're saying I have many states in my RL setting, RL environment, but it's not like all of them are behaving differently. I can actually cluster them and they're actually going to behave similarly.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So this is the basic says there is an underlying clustering of the environment and the observation that I can use to reduce the complexity of my model. If my environment has 10,000 states. But if I can cluster them each hundred or 500 of them and come with the problem with 10 states, I can easily solve everything.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So this is an idea. Let me give you another example if possible. So let's say I'm here. My job is to go to my blackboard. I can say this visual state I have is my state. So at this observation, I have is my state. If I move backward, my observation changes. If I move forward, my observation changes. If I turn left or right, my observation would change, too. Right? But the thing is, this observation is humongous space. It comes from humongous space, but I can map this observation, which is a big\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"which is a big observation to my current location. If I know my current location, I know the optimal action is this way. If I look at this direction, I'm seeing different, I mean, different state, but this state or this observation I have is rich enough for me to inform my current location.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"I go, I know the ultimate action is going back for. So this is an idea. So when I, in this state, all these observation I'm looking at, these are different states, but all of them are, they can be mapped directly to my current location. If I know my current location, I know my optimum policy. So this is called rich observation MDP.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So you says your observation is rich enough to directly infer your current location. So this is one of the settings that people have been working many more. There are many papers in this area.\\n\\n[01:03:20] Sam Charrington: It sounds like it's related to work that has been going on for a while to try to use geometry, to reduce the state space from observed pixels to something that's maybe in this language more structured and they can be more easily operated on.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[01:03:42] Kamyar Azizzadenesheli: So we have this ward model paper, so they are able to get this whole observation of the pixels and map it to the latent state of the VA which Layton says continuous, or I have a paper with some colleagues from Canada. Here that we actually mapped the whole pixel space to finite the many estates or there are many works that are actually, they are called by simulation. They're actually tried to come up with this type of geometry structure of the problem.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"There's a friend of mine. David Abel, he's also has done so many works in this area that are actually trying to do a state abstraction. This is one thing where there are so many auto restructure people came up with one of them, which is very interesting. It's called linear MDP.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='What it says basically things that transition function in my MDP, despite the fact that I have many states to transition, can we linearized? It can be written in the basically somewhat academic setting, some special case. It can written as a summation of bunch of a known MDP basically.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So your MDP can be written as a summation of some known MDPs. This way, your cue function becomes linear in that, on those feature presentations that you would get from those MVPs. So this is, let me tell you this way. Let's assume that your queue function is linear with respect to some feature presentation. Why is good? It's good because, or at least might make sense is if I'm training a deep queue network, I have a really deep neural network and the last layer is a linear layer. I can assume\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='layer. I can assume that this feature presentation is good enough, then my cue function is linear with respect to his feature representation.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So he's actually has some meaning to the practice. So people have been studying this setting specific in last two years, and it's been glorified. There are so many, I think more than a hundred papers in this specific area that assumes that there is a some linearity of structure in the MDP that you can exploit to come up with a good policy.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='There are people making low rank assumption that the underlying system is low rank and that basically transition function or transition kernel, despite the fact that being humongous thing, it actually has some lower rank structure. This one has many interpretation, people making different assumptions. For example, in metal learning and reinforcement learning, people make the assumption that when you go from one environment to another environment, everything almost stays same, but some linear', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='but some linear part of the environment changes. These are all interesting because these are all easily transferable to deep learning networks.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[01:06:48] Sam Charrington: So I made the assumption or the statement earlier that a lot of the efforts I've seen the ultimate benefit is trying to get to sample efficiency and being able to convert faster. Is that the primary benefit of this work or are there also performance implications or generalize ability implications or other implications?\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[01:07:13] Kamyar Azizzadenesheli: It depends on who you\\'re asking, who writes those papers. Some people just care about the fact that how well they can improve the sample efficiency. I was part of that crowd many years ago. But these days there are other people, they are like, \"Hey, what makes sense in practice? How things work we know in practice, we can use deep neural networks to come up with a feature presentation and do meta-learning on just the last layer. If that\\'s the case, can I', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='the case, can I theoretically study this?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So some people, their goal is to theoretically study the thing that they know is going to work in practice and they theoretically have studied and see whether it works in theory, and then come over their real world applications. Some people mainly care about the fact that whether they can get a better sample complexity, both approaches are awesome.\\n\\nI love both, but I'm more in the, I have one leg in one camp and heavier leg in other camps.\\n\\n[01:08:23] Sam Charrington: Yeah. Awesome. Awesome.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So we started this talking about the flashy demos or results or papers that caught folks attention, and that we abandoned that, and went right into these trends, starting with robotics, because that was one of those areas did. We cover all of the areas that you thought were flashing and talking about the trends? Were they all represented in those trends?', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[01:08:56] Kamyar Azizzadenesheli: Yeah. There's one more trend that I did not talk about. I am still not very, I would say not knowledgeable enough to talk about, but I see it's a big trend is called self supervised learning approach in reinforcement learning. I'm trying to get myself involved in the sense that to be able to learn what people are doing, and whether their ideas... Those things I've read so far, they seem to be extremely promising and basically transferring knowledge from\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='knowledge from different tasks.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"Again, we are going to the direction of having problem with specific approaches. So I have many tasks. Can I do transfer knowledge from one to another? Can I use whatever I learned from one environment and deploy it, and get help to improve my performance in different setting? So these are the things that people are doing in this area. I think it's extremely promising and it's trending. Its general theme is a new paradigm that needs a lot of attention from us, but I'm still a junior student in\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='a junior student in that area.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[01:10:14] Sam Charrington: One of the historical challenges or critiques of RL has been that it's very difficult to apply. A lot of the results that got the most press or visibility were games and other toy problems.\\n\\nWhat kind of progress have we made and the applicability and real-world use cases, commercial developments, that kind of thing over the past couple of years?\\n\\n[01:10:47] Kamyar Azizzadenesheli: Yeah. That's a very good point.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='For supervised learning problems, people just go on plug and play and things usually work merely because those problems are much easier than RL problems.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"You can now just download one of the implementation of DQ and applied on some random problem. It wouldn't work. It's like, if you take the implementation of a model which works on ImageNet and applied to another image problem, it works. But if you apply DQN and best implementation of DQN and take it and apply it to another problem, I doubt it would work.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So it's like we are dealing with the harder problem. There are so many things you need to tweak there. So genuinely it's a harder problem because you are hardly solving harder problems, so you need to be more expert. So one thing I'm seeing now is yes, we have those games staff who have worked on those game stuffs. Basically all the experts in reinforcement learning. Now people are getting reinforcement learning algorithm to work in practice. They are actually experts in reinforcement learning.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='learning. For example, the robotic setting I\\'m talking about, people got reinforcement learning algorithm to work in robotics not because they just downloaded something from GitHub. They learn things. They invented new RL algorithms, those work in their setting. They did not say, \"Okay, let\\'s download this one and run it.\" No. They wanted to solve the problem. They took courses in RL.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"I have one colleague who is a roboticist and control theorist, who knows a lot of RL who can just generate and write down many machine learning algorithms. He's an expert in machine learning right now. Some of these domain adaptation stuff and meta learning in deep learning stuff I was talking about are wasting his work. He has all the learning theoretic guarantees and everything is, if you read the paper, you feel that it's like a veteran of RL theory personally wrote it. But this person is\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"But this person is three years into the machine learning field or four years. So he's extremely smart and he knows everything right now.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So people now working in different areas that are deploying the reinforcement learning algorithms learn that, \"Hey, you cannot just download and plug and play.\"', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='You need to know what you\\'re doing. So people are getting more expert in this area. In recommendation system, people have been using reinforcement learning algorithms forever and felt they\\'ve been making a lot of money. In the last many years, I don\\'t know how many years has been the case, but in the hedge funds have been hiring amazing RL folks getting RL algorithms to work. They also understood that, \"Hey, in order to make things working, you need to know things very well.\" So they actually', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So they actually became expert in this area, any, and in many other manufacturing companies that are trying to get RL to work, they also understood that you cannot just download them, press run or control for the machine to work.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Yeah, it was. No, seriously. It was saying it was the case like three years ago, four years ago, I\\'ve been hearing stories from big companies that people downloaded the DQN algorithm and ran it on random game. I was like, \"How you\\'re expecting them to work? They spend like two or three years to make that thing work and they fail. Of course it\\'s not. You need to know the pieces of it.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[01:14:20] Sam Charrington: You're touching on another slightly removed issue. One issue is the ability to take results out of academia and apply them to real world problems and have them easily work\\n\\nanother related issue is reproducibility.\\n\\nI'm downloading the paper and the game that the paper was written to play, and trying to get that to work. That should be easier in theory.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[01:14:53] Kamyar Azizzadenesheli: Yeah, but this is hard. Yeah. Yeah. Genuinely this happens because our problems are genuinely harder. It's like the supervised learning is a very tiny, teeny special case of reinforcement learning.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='So one of the thing I tell my students for my RL course is the first lecture is, I do not expect everything to be easy. Any problem you solve in reinforcement learning means that you have solved many problems in many fields because it subsumes many fields in machine learning.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"So it's genuinely hard. I don't know we are going into the right direction or bad direction because we are at least in academia. What I'm seeing is we are weak in RL. Not in sense of, we don't know in a sense that we don't have that many people to train the next generation. I mean, you look at France, like France had so many people in RL five years ago. Now almost all of them are not there anymore or in US we had slow growth in reinforcement learning. We didn't have that many reinforcement and\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"reinforcement and people 10 years ago, but now we have more, but the demand is much higher than the number of people we have. So who can give the next, I don't know the industry or other sections of academia, who can give or who can fit them with new experts in the field. So this is a scary thing, at least for me. I don't know if you're...\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[01:16:31] Sam Charrington: Are you still looking for PhD students?\\n\\nYeah.\\n\\n[01:16:35] Kamyar Azizzadenesheli: Whoever is out there who wants to do reinforcement learning, please join.\\n\\nYeah. I'm doing everything I can to train the next generation of reinforcement learning experts, but it's just me and few others. There aren't that many people in the in academia who do reinforcement learning, which is not what we want at the moment.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[01:16:55] Sam Charrington: Top prediction for 2022 and beyond.\\n\\n[01:17:01] Kamyar Azizzadenesheli: I would say at this for 2022, I'm sure we're going to have so many newest structure or a structural assumption in M in mark of decision processes. For example, and people would come up with new ways of modeling MVPs or a special case of MDPs to make them suitable for practice. So I would see that there is a huge wave of experts in the area.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Now they are trying to cook up new assumptions or new structures for MDP problems to come up with algorithms that actually are more sample efficient, and hopefully would help us to design efficient algorithms in practice. This is one thing I think is going to be one of the main thing in 2022.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"The other thing I'm sure is going to be the case. Given the fact that most of the control, sorry, most of the roboticists I've been in lockdown and could not go to lab. There's going to be a lot of work, intersectional, reinforcement learning and robotics in 2022. I lost track of this year.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"We are hopefully dependent make, would be over and we are going to get back to normal. So this robotics is another thing that I think is going to be huge. Given this techniques we have in control theory, I think is going to be one of the main thing in next few years that people there are many amazing and awesome control theorists out there in all the departments you go ask who's control theorists.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Do you see or any university you go, you see 10 or 20 people they collect. Control theorist, maybe in 25 or 10 people, they claimed that their control theorist, Asquith, RL expert, probably you get one. So these people, actually, the people in control there understand the power of this reinforcement learning algorithms and the tools we provide in this area.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"I'm sure all of them are going to recognize the power of these things and start to deploy them in their work resulting in new generation of learning, and our learning and control allergens for next few years. Basically these are some of the prediction, but I'm sure that we are in this direction, that we're going, that we are trying to come up with more problems with specific algorithms.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"We're going to have awesome algorithms that are going to provide safe and robust reinforcement learning method. In the next five years, we're going to have methods and our algorithms that are, can handle all sorts of risks function, risk functional that people carry in practice. These are the things that I think people would work on a lot.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='Also this from practical point of view, coming up with a scenario and the settings such that you can have some meta model that you can use at your... You can transfer knowledge from different problems to problems that you deal with this. This is another thing that I think going to be blooming in next few years, like in the NLP, you have this language model, you can just use it to do many things.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"We will have something like that. Not very long in reinforcement learning, of course. RL is more complex, so you're not going to have one model. You're going to have one model for robotics. One model for, I don't know, dialect systems, one model for Atari games, one model for self-driving cars. So these are the things that are probably going to be the driving factors for next few years. Yeah.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content='[01:21:14] Sam Charrington: Well, Kamyar thanks so much for running through this with us. Specifically, thanks for all of the work that you put into pulling this together, continues to be a fascinating field and a lot of interesting stuff to talk to.\\n\\n[01:21:35] Kamyar Azizzadenesheli: Yeah. Thank you, Sam. Thank you for having me.', metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"RL is going to be fascinating field forever as it's by definition. If you want to have general intelligence, you need to solve our ELLs. First, it's going to be in it's,there are so many open problems. I encourage people out there to get involved in reinforcement learning are so many open and cool problems to be solved in this area.\\n\\nYeah. Awesome. Thanks so much.\\n\\nYeah. Thank you.\", metadata={'source': 'content/data/560 - Kamyar Azizzadenesheli.txt'}), Document(page_content=\"[00:00:10] Sam Charrington: All right, everyone. I'm here with Sandra Wachter. Sandra is a Professor at Oxford. Sandra, welcome to the TWIML AI Podcast.\\n\\n[00:00:20] Sandra Wachter: Thank you so much for the invitation.\\n\\n[00:00:23] Sam Charrington: I am looking forward to digging into our chats. Of course, to get things started, I love to have you share a little bit about your background and how you came to work in the field of artificial intelligence as a lawyer.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:00:38] Sandra Wachter: I guess it started with the fact that I always was very, very excited about technology and I grew up with an understanding that technology could actually help us bring the world closer together. This started off in the field of health tech actually. That was the first area that I looked at because medical devices that makes immediate sentence that people understand that this can be helpful for a lot of people in our society.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='Then over time, and especially in my PhD, I branched out much broader and got interested in old types of technologies and how they can be used for good or bad, and got interested in the question of how it affects laws, how it affects society, and what it is that we can do to reap the benefits and mitigate the risks.\\n\\n[00:01:26] Sam Charrington: Nice. Have you ever been a practicing lawyer? Did you go through law school and all that or..', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:01:33] Sandra Wachter: Yes, yes, I did go for, yes. I did go for law school. I have a special degree in medical law. I do have a PhD in law. So yes, full fledged lawyer in that regard. Yes and stayed in academia.\\n\\n[00:01:50] Sam Charrington: Nice, nice.\\n\\nActually before we jump into that, tell us about your research.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"I was going to ask what's your take on the state of AI and the law but that is a very broad topic. But it's not one that I've talked about extensively here on the podcast. There's lots to dig in there but maybe we'll be a bit more focused and I'll ask you to talk a little bit about your research interests which you spend a lot of time thinking about specific areas that AI intersects law. What are those areas?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:02:37] Sandra Wachter: Yes. So in general, I focus on the legal and ethical aspects of emerging technologies. At the moment I have free very distinct research interests that have to do with AI. There is much more, so I don't want to say those are the only three I care about but those are the only three I have time to care about at the moment.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"They're free aspects that I think we all need to think about whenever we use algorithms for decision-making. One definitely has to do with the black box problem. The other one has to do with data protection issues. The third one has to do with bias. So those free areas, regardless of where you deploy an algorithm whether this is in the U.S. whether this is in Europe, whether this is in New Zealand, and whether this is in banking or education or in the health sector, those free areas will be\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"free areas will be important because you always going to want to understand how a decision was made. How did the Blackhawks come to the conclusion that you shouldn't get insurance or that you have to go to prison? For example. Always going to be a black [inaudible] problem. There's always going to be a data problem because an algorithm is useless without data. So whenever you talk about algorithms, you have to talk about data. Whenever you talk about data, you have to talk about algorithms\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='about algorithms because data is only worth anything if you can analyze it in a way. The genius thing about inferential analytics and AI is that you can learn so much about [people] but the scary thing about AI is that it can learn so much about [people].', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"The question is how can we navigate through that, that I have a powerful tool that is able to learn a lot of things about me that can be helpful and be good. Can help me diagnose cancer, but can also infer whether I'm gay or not, or whether I've voted in the last election or whether I'm a woman or whether what my sexual orientation is. So the questions, what needs to be done from data protection issue.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"Then the last one has to do with bias and discrimination. Again, this is prevalent regardless of country and regardless of sector where I deployed because the data that we collect is unfortunately, most instances, not fair, reason being because the world is not fair. It's not fair in any part of the world fully, at least. It's usually not fair, fully fair in any of the sectors where AI is being used. So the bias will be inherited when you train the algorithms on it and just think about all the\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"think about all the different types of sectors where we use them. We use them in education, we use them in traditional sector, we use them in employment. Those are all areas where we know that biases exists. So it is no surprise that we're just going to transport human biases into algorithmic biases. So regardless of where you are in the world, and regardless of what are you using the technology for, you need to think about those things. Those are the three areas that I am trying to make an\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='am trying to make an effort to come up with a contribution at least.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:06:09] Sam Charrington: Nice. Nice.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='Well, let\\'s maybe explore those in turn. In talking about the black box challenge, and we\\'ve talked about that quite a bit on the podcast, the need for transparency to some degree or explainability, to some degree, often from the perspective of \"I\\'m a business person. I\\'m relying on this algorithm to help me make a decision. In order to develop a level of trust, I want to know why it\\'s recommending the thing that it is recommending.\" When you bring in the element of law, and maybe more broadly', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='maybe more broadly regulation, how do the ways I need to think about that problem change?', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:07:04] Sandra Wachter: You can do it with a brute force instrument and just say, \"I, as regulator, I\\'m only going to allow algorithms that are explainable period, exclamation point,\" and just live with those consequences. That is something that has been discussed, and whenever this discussion comes up, then people will immediately say, \"Hold on, hold on, hold on. You can do this because you cannot explain algorithms.\" So if you do get them then you flat out banning them.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"There was a wisdom of the day when I entered the stage to get interested in this topic that it's just impossible. So when I thought about this a bit more, I came to the conclusion, yes, there are probably two reasons why people don't want to give you an explanation.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"The first is because they can't. The second is because they don't want to. Those are two different topics. One is definitely because they don't want to, and that has to do with trade secrets. So they could tell you how an algorithm works because it's not so complex that you would know.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"You could actually tell somebody why somebody has to go to prison because the algorithm is not that complex. So that's something where the law can come in and say, well, just open up that black box because we know the end. So it's just a question of trying to balance the interests of business and the interests of the wider community in our society.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"So there is something that the law could do. I recommended for example, to have a trusted third party that could have access to that. So it doesn't have to be spread everywhere. Then what's challenging? I don't want to give you an explanation part is there because I can't part, which is not even the person writing the code, allegedly does fully understand what's going on. So even if they wanted to, they can't, and that's the more challenging problem because the law doesn't really have an answer\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='have an answer there yet because some things are unfortunately not explainable and not even to the full extent to the people who are writing a code.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='However, I don\\'t usually take no for an answer. So I figured, I tried to explore if that\\'s actually fully true and I teamed up with two other people. One of them is Brent Mittlestadt who was an ethicist, and Chris Russell who works in machine learning and we wrote a paper that is called \"Counterfactual Explanations Without Opening the Black Box\". So what we try to do there is try to take all those concerns on board and say, \"Okay, is there a way to understand what\\'s going on inside of a black', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='on inside of a black box without fully understanding the black box?\"', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"We came up with counterfactual explanations as a way to do that because we saw it from the view of the person who wants to have an explanation. I have to go to prison. I didn't get the job. I wasn't promoted. The thing that I want is not a full fledged code explanation. What I want to know is why the hell didn't I get the promotion and what do I need to do different to get the promotion? That's the thing I'm actually after.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"If you fire me and you give me a piece of code in my hand, I'm going to be very angry at you actually, and feel like you haven't listened to me. That's exactly how explanation usually work in human settings. I want to know the criteria, the reasons why it didn't happen and what I need to do differently.\\n\\n[00:10:43] Sam Charrington: Yeah.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:10:43] Sandra Wachter: Luckily, that type of reasoning is something that you can code. So we call it counterfactual explanations in human settings, but in codes you can also generate a counterfactual. So where you just have a very complex system, one that you might not be fully to understand why, but I can tell you why in this particular case, the decision was made in a certain way.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='So if you apply for a loan, for example, a counterfactual will tell you, \"You were denied the loan because your income was 40,000 pounds. If it had been 45,000 pounds, we would have given you the loan.\" So you get the most important criteria and it tells you something, what needs to be done to change, to resolve. It gives you grounds to contestation all that good stuff without having to understand the complexity of the full code. That was a way to find a middle ground there where we can do', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='where we can do something in a way. That sends something that the law would require you to do, and that was actually quite exciting.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='So we wrote that paper a couple of years back, and Google came across our work interestingly enough, and they implemented an intensive flow and later on, they implemented it in Google Cloud as well. Then many other companies have followed suit such as Vodafone, for example, which is amazing to see.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"So the things that we cooked up in our ivory tower basically were actually something that had a positive, meaningful people working on the ground, which is exciting. But anybody interested in the topic can look at our paper and the code is freely available. Everybody can use the type of explanation if they wanted to. So it's freely accessible, but yet that is definitely a way to think about opening the black box in a meaningful way.\\n\\n[00:12:38] Sam Charrington: That's awesome.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='Can you give us an overview of how those counterfactual explanations are created or generated?\\n\\n[00:12:46] Sandra Wachter: What you do is you try to find the closest and minimal changes to a current decision model that needs to be taken in order to get the thing that you want.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='So you\\'re not actually just asking, how does the rationale of the algorithm work? What you\\'re doing is, \"Okay. What are the smallest possible changes that I need to do to get from 0.1 to B?\" The interesting thing is that I could give you multiple counterfactuals. I could tell you, \"Oh, you didn\\'t get admitted to law school because your reference letters were bad\" and/or \"because your grades were too low\" or \"because you had typos in whatever,\" then give you a ranking of that and then you can', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"and then you can figure out what would be the most helpful for you because for some of us, it's easier to change the spelling on the cover letter. Is it easier to find better reference letter writers. To give them what diverse sets of possible grounds to improve your current situation is a very, very good benefit of counterfactual.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:13:54] Sam Charrington: So you have some data point that you want to generate these explanations for. So then you permute it in different dimensions to try to understand how the different decisions the model might take.\\n\\n[00:14:12] Sandra Wachter: Yes.\\n\\n[00:14:12] Sam Charrington: Then you use that to create the explanations.\\n\\n[00:14:16] Sandra Wachter: Yes, exactly.\\n\\n[00:14:18] Sam Charrington: Awesome. Awesome.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='Then the second focus area for you is around data protection. It sounds like your work is exploring a fundamental question of \"Is privacy still viable in this fully connected world with machines making predictions and accessing consumer data?\" and the degree to which what our expectations should be and how we can protect data. Tell us a little bit more about that area and some of your work there.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:14:59] Sandra Wachter: Yes, certainly that is a topic very close to my heart. Why do we need to care about it? I said it already a little bit but just to give people a little bit of a scary landscape of what's actually out there is that I don't think we really fully understand how good those algorithms are. It can predict very, very sensitive and intimate information about us that we might not want to share with anybody at all. They can do that from very seemingly neutral data. So if I use\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"data. So if I use my search engine, for example, Bing. They're able to infer based on how I move my mouse, whether I have Alzheimer's disease. Are you aware of that? Are you aware that you are giving that health information away to the outside world? Are you aware that Twitter can infer whether you have depression just based on what you tweet online? Are you aware--\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:16:01] Sam Charrington: To be clear, when you give these examples, are you posing them as hypothetical? Bing could--\\n\\n[00:16:09] Sandra Wachter: No, no. They have published a paper that they can do that.\\n\\n[00:16:12] Sam Charrington: Okay.\\n\\n[00:16:13] Sandra Wachter: So that's what I'm trying to say. This is not a hypothetical, something that I could cook up and do ivory tower. That's fact. They can do that.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"One of the most problematic ones is definitely what happened with acebook, where they're able to, and again, there's research that shows they're able to infer sexual orientation, ethnicity, gender, ability, without any of their users identifying with any of those classes and groups, just based on what they click on, what they like, what they post and who their friends are.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='They can have this information and then use it in a way where they, for example, allow advertisers to exclude them from seeing certain products. This is something that they did for example. So they would, in the U.S. infer that somebody was, for example, black, and would allow advertisers to exclude them from seeing job offers and ads for housing and financial services.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"So it's not just a theoretical problem that you should not know those things about me, unless I say it's okay, but they've also actually has negative consequences because it can be used against you in a way where you don't know about it. So with all of that, and again, it's just three examples that show how powerful those algorithms are.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='The question is, well, we have data protection though so why not just apply data protection lodge, all of those problems, and the issue here is, at least one that I\\'ve been currently working on in a while. I\\'ve been working on a research project and the paper that I wrote, which is called, \"Rights to Reasonable Inferences\" is that I show that the current data protection law was designed in a way without fully anticipating the power of AI. Therefore, it was designed in a way in a very, almost 20', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='in a very, almost 20 century way of thinking about privacy in the sense that 20 century privacy is I\\'m in my home. I don\\'t like my neighbor. He\\'s very nosy. He keeps coming over to the fence and he\\'s looking at me and he says, \"Oh, Sandra is again eating ice cream before noon. Oh my gosh.\" She has no self-control. Yeah. So she has no self control, whatsoever, which is true but that\\'s the idea. So what is it that the law wants to do is that I want to prevent the nosy neighbor from collecting', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='from collecting information about me. So I give all the power to me. So you have to ask me first.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='That is how [inaudible] the protection that works is a lot of times it\\'s based on consent or transparency where somebody needs to tell you, \"Be aware, be aware. I\\'m taking this data from you,\" because in human settings that\\'s the dangerous part. They are seeing something and I can anticipate what they know.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"I'm sitting in my yard eating ice cream. That's the information that the neighbor now has about me. So this is why all the data protection law focuses on with algorithm collecting information about me eating ice cream is the first step. That's not the thing that they're actually after. They're interested in what they can infer based on my eating habits. That's the question. That's something that my neighbor couldn't do.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"Algorithm now might be able to infer that I might have a higher chance of getting diabetes at some point, which is something my neighbor couldn't do. But then the algorithm can. So the interesting or more interesting, more dangerous thing actually happens after data is being collected. So everything that is being inferred. But the law doesn't really care about that so much because the law still thought the data collection part is the most dangerous thing.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"So I've wrote a very, very long paper. I don't know, 150 pages, just to show that that's a problem because the data protection law focuses too much on the input side of things, collecting the data, taking data from you and not so much on the output stage, which is what can I learn about you? The new laws actually need to govern the outputs rather than just inputs.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:20:41] Sam Charrington: I'm curious about the length of the paper. It sounds obvious and clear when you made a very simple and clear argument for this, and I'm totally bought in. Why do you need 150 papers to... Who are you trying to convince? What is it that they needed that you had to build out this 150-page argument?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:21:07] Sandra Wachter: Yes because it's really... I don't think people have looked in incomplete detail how it's actually being regulated. I just went through with a magnifying glass to show that inferential analytics, unfortunately, or inferential data has almost to no protection. I showed that in the case law as well, which is something that wasn't really looked at also though with the fact that I was talking about the general data protection regulation, which at that point was really new,\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='was really new, too, and your framework came out and...', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:21:51] Sam Charrington: Explaining this new thing that no one understood.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:21:54] Sandra Wachter: Yes. Yes. That was important because it was very, I think, important to get the message across how really, really problematic that is which I think up until this point wasn't really clear. So yes, and that's what I usually do when I see there's a problem, then I'm not going to give you just one example. I'm giving you like all the examples. So you with me and can understand that you really need to care at this point, and something needs to be done.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:22:28] Sam Charrington: So I'm no GDPR expert but my sense is that GDPR didn't really, this wasn't really one of the issues that GDPR was addressing or trying to address. Is that right?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:22:40] Sandra Wachter: Yes, that's definitely also one of the problems and this is why data protection law was so much designed in a way to just keep the nosy neighbor out. What technology was capable of doing happened so much later. If we're very honest, the new GDPR that we have is to 80%, 90% the same stuff that we had in the data protection directive. That framework is from the nineties so there are updates there. Yes. But the core mechanisms and decor assumptions, and to think that it's\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"to think that it's supposed to be doing, hasn't really changed. This is not to say that it shouldn't necessarily regulate AI, but it's just to say that it was never designed to regulate AI anyway, and therefore it's failing. I think a lot of people had hope that this new framework will be the silver bullet to all the problems.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"I just wanted to say, no, I think there is still a lot of work to be done and we need to be very, very careful to do this right because there is so much on the line.\\n\\n[00:23:49] Sam Charrington: You mentioned regulating AI. It's not even regulating AI as much as regulating data in the age of AI.\\n\\n[00:23:55] Sandra Wachter: Yes, definitely. Definitely. Yes. So even further removed from that.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:24:00] Sam Charrington: Is there a locale or a regulatory framework that you think does a good job with the issues that you've described? Are we there yet or...\\n\\n[00:24:18] Sandra Wachter: No, I don't think we're there yet because I think it touches so many things at the same time that if you've wanted to come up with one framework, it will need to do a lot of work.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"I think what'll probably be more helpful is to rethink how regulation should work in the future anyway, that you just don't silo data protection in one corner without thinking about competition law; without thinking about non-discrimination law and without thinking about consumer protection law because all of those things are very much interconnected.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"So one law that governs everything, I'm not sure if that's useful or necessary. I think what's very useful and very necessary is that different types of regulators start to collaborating more closely because AI puts them in the same room anyway. The data flow does it anyway. So I think that's a better way of thinking about regulation is that almost every regulatory aspect or every sector law that we have will be touched by some type of technology at some point.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:25:31] Sam Charrington: So regulation is only one approach to ensuring good behavior. There's also self-regulation or industry consortia or the like. Are there any examples of folks that you can point to that have taken a responsible approach to these issues or are particularly transparent?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"I'm just wondering if there's a good example or reference model that has emerged for say, I guess I'm envisioning an enhanced data use statement or something like that, that talks not only about these are the organizations with which we share data but these are the derivative products that are created. This is how we use and/or share that information. Is anyone doing that?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:26:39] Sandra Wachter: Yes. I think everyone is doing that. I think that's a little bit also of the problem, that everybody is doing that.\\n\\n[00:26:48] Sam Charrington: Doing the creating new products and sharing them or...\\n\\n[00:26:51] Sandra Wachter: No. Creating codes of conduct, and guidelines, and best practices, and standards. All of that is being created everywhere. It's created by governments, by industry, by NGOs, everywhere and anywhere.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='My colleague, Brent, has said he wrote a paper, \"Nature\", I think, which was called why principles alone are not enough or something along those lines. I think at that point when he wrote that piece and that\\'s also, I think probably two years old at this point, he said that there are 150 different guidelines, best practices, and standards out there. They\\'re all roughly the same. He goes through for them all and just points out how they are still lacking the thing which is being applied in', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='is being applied in practice with having a good feedback loop of how well they actually work in practice. So like I\\'m all for responsible innovation, and research, and in trying to come up with best practices. I think that\\'s absolutely needed but I think that part is now over. I think the interesting part is now to figure out, \"Okay, is anybody actually deploying them in practice? How good are they, what kind of oversight mechanisms are there?\"', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"It's great to have five wonderful ethical principles. If you don't tell me how you actually operationalizing them, then I don't necessarily think the job's done there.\\n\\n[00:28:26] Sam Charrington: From the perspective of concerned parties, academia, what does the landscape look like in trying to address these issues?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"There are certainly papers like yours, where you identify the issue and show that it's not being addressed. What are the steps that we can build upon to get to something that's a better place?\\n\\n[00:28:54] Sandra Wachter: Yes. I think that's obviously a biased view here but I think that academia actually does have a very big role to play.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"I'm very happy to say that academia has played a very vocal and important role of the last years. I think if academia hadn't been as loud and persistent, a lot of things would have not have changed. So the questions around [inaudible] accountability and privacy protections have been front and center on a lot of agenda of people in the field and had they not been so persistent, I don't think that so much would change at the moment. So definitely that, and in that I think one of the reasons,\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"one of the reasons, again, is why many of them have been so powerful and influential is because they very often work with people that are not from the same discipline than they are, and I think that's the key thing here because I can just speak for myself. I think none of my papers, I could have not done it by myself. It was very important to have an ethicist and a machine learning person on there to teach me and have them also endure my teachings. I think that made the whole work stronger. I\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"work stronger. I think that's really what if you are thinking about how to govern things, I think you owe it that you try to look at the issue from as many as perspective as possible.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:30:28] Sam Charrington: Then the third pillar of your research is focused on bias, fairness, and discrimination with regard to the law. It sounds like this is your most recent work and what you're most excited about right now. Tell us a little bit more about that area.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:30:43] Sandra Wachter: Yes. Definitely, definitely extremely excited about that. I think everybody will know, as I said, that bias and unfairness is always an issue when we think about data and algorithms because unless you collect them in utopia, there's a fair chance that the data will bias in some way. That's reality we have to deal with.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:31:08] Sam Charrington: Now speaking about the fundamental premise of machine learning that we're training based on information we've collected about the past and these decisions that were made in the past. The mechanism fundamentally carries forth biases from the past into the future. If that's, there's not extreme care taken.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:31:31] Sandra Wachter: Yes, absolutely. I should have said that. Yes. That's, as you said, that's basically how all machine learning works is looking at the past, trying to predict a future. You feed the algorithm with a bunch of historical data. For example, who has been hired, who has gotten insurance, who was sent to prison, who did re-offend, who did get sick. You train the model based on that because you think that you have some ground truth because you have historical data. You know if\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"data. You know if somebody actually got sick. You know if somebody did well in law school. You know if they're re-offended and if somebody that looks similar to the person is now applying for the job, is now applying to be left out on parole, is now wanting to promote it. If they look like similar people that re-offended or did well on the job, then you give them the same chance because you assume that similar patterns will emerge. That's all great. Again, if we tend to make good decisions, fair\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"good decisions, fair and just decisions, that are accurate, but if they were honest, very often, debt is not the case. So unless you're very, very careful, you will just reinforce the biases and injustices that we had in human decision-making but much greater speed and much less detectable. So I got interested in this topic as well.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='The first question that I always ask myself, it\\'s like, well, is the law sleeping? Why not just use the law to solve that problem? I got interested in the question of on discrimination law because that\\'s the closest, the most sensible law to look at.\\n\\nGabby wrote two papers in the past .One is called, \"Why Fairness Cannot be Automated,\" which already tells you how I felt about whether this is possible.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"What we did there was quite similar to previous work where we showed that the law just wasn't designed in a way to govern algorithms. It was designed to govern people. So if you think about a discrimination setting, a discrimination setting, a traditional one is where somebody indirectly/directly is not giving you the job because you're a woman or they harass you because of your religious beliefs. Or you are in a hostile environment where other things are going on that prevent you from\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='prevent you from succeeding.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"Basic point is, you know that something's off. So you bring a complaint and non-discrimination law will help you with that. So we've awkward. And again, it's different because they discriminate behind your back without you actually being aware. So a complaint based system, such as non-discrimination law, is completely powerless if the person does know that they have been wronged, and again, that's not a failing of the law per se, and it's not a failing of the algorithm. It's just a very unhappy\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"just a very unhappy miss match of the two because again, the law was designed for people, not for algorithms. But discrimination still occurs. So what is it that I need to do? Which means we have to test and test and test because if I don't know, somebody has to know. The problem is you can only know if you test for it because that's the second problem.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='Very often, you might not even know that the data that you have collected is biased or unfair towards certain people because again, here the intuition breaks down. Non-discrimination law was very much based on intuition. A judge looks at the case and says, \"Oh, what you bent had scarves from the workplace. That\\'s a problem of freedom of religion.\" You don\\'t need much data to make that point because there is a clear understanding of the social reality or the social symbolism of headscarves and', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"of headscarves and religion. That's not much you need to do with that but what if I got fired because I don't have a dog?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"That sounds maybe odd, but do I know that, that correlates with ethnicity or gender or sexual orientation or just believe I really don't know anymore. So how am I supposed to bring a case in court if you using data where my social gut doesn't ring alarm bells anymore. So those two things that I might not know about it and that even if I know about it, that I have almost no way of proving.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='It means that fairness cannot be automated. [inaudible] So we thought, okay, then you need to test, you need to test, test, test. Somebody needs to test because otherwise you would know. So we came up with a bias test that lets you do that. So the test is called conditional demographic disparity, C-D-D.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='We chose that test because it aligns the most with European non-discrimination law in a way that other tests do not. Yeah, this year, in January or February, Amazon came across our work and that bias test, and they found interesting and they have decided to implement it in their own bias toolkit.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"So say Jamaica clarify. So now customers have of Amazon can use that test as well. But again, as with all of our research, it's publicly available. So if anybody's interested in that having a closer look or in the code or whatever, it's free and publicly available as well.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:37:37] Sam Charrington: So can you talk a little bit about what differentiates this conditional demographic disparity, C-D-D tests with tens or potentially hundreds of other statistical tests that have been used as metrics of bias in datasets?', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:37:56] Sandra Wachter: Yes, certainly. So that\\'s actually quite exciting and that\\'s the second paper that compliments the first one. Also we have a paper which is called \"Bias Preservation in Machine Learning: The Legality of Fairness Metrics and the Non-Discrimination Law.\" So exactly the question that you just asked me.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='So what we did there is we looked at 20 different fairness tests and we came up with a classification system on how they make decisions. The one category is called bias, preserving bias tests. The other one is called bias, preserving bias is transforming fairness tests.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='So what we looked at is that the majority of them, so 13 out of 20 bias preserving. So what they do is they look at the error rates to measure fairness. So they want to make sure that whatever type of decision has been made and is now being made has the same base rate for errors. The other ones, the other seven are more looking at decision rates.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='So they\\'re looking at how the outcome is distributed across certain groups. That is the main contribution coming up with that distinction and trying to tease out the underlying assumption of this. One bucket says, \"As long as we\\'re not making things worse than they used to be, I give my fairness check and it\\'s okay.\"', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"That bias, transforming metrics that look at the decision rates say I'm only happy if equal outcome are happening across groups. So does this down the line assumption? Fine. Unless you look at what European non-discrimination law wants to do. Nondiscrimination line Europe is not just about formal equality as in, do not actively treat somebody differently because of their race or gender or sexual orientation which is more like a negative forum as in passive forum of discrimination.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"of discrimination. Non-discrimination law in Europe is much more about substantive equality, which is more about actively dismantling inequality, keeping things as they are, is not good enough in Europe. You're supposed to take an active role as much as you can, both the private and the public sector, to actually make the world a fairer place.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"The majority of those fairness tests don't do that because they condition on an unequal status quo and they freeze that. That is the main problem and with our fairness tests, and with others that are bias transforming, you could counter beam act that at least will give the opportunity to actually make it better.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:41:09] Sam Charrington: Got it. Got it. So at least, for those whose problem is specifically covered under the regime of the European non-discrimination tests. This C-D-D is the only test, the only fairness test that is at a.\\n\\n[00:41:30] Sandra Wachter: No, not the only one, like anything that is bias, transforming, and there are seven others that are also a bias transforming that you can use.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"You could use those. Definitely. Those are absolutely fine to use. We point that out in that paper. So we listed exactly and the other tests that you could use. Also it is not to say that you cannot use bias preserving metrics completely in Europe. It just depends on what the context is. If you're using a bias, if you making decisions, life-changing decisions about people in Europe, in a sector that is a protector.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"That is be non to exhibit bias. Then you should use a bias transforming metrics because it at least gives you the ability to make something better than it used to be. It doesn't have to be, you don't have to make it better, but you need to at least justify in a way, however, you could still use a bias, preserving metrics, and either justify that as well.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"But I think it's difficult, but there are legitimate areas where you can use it, but you don't have a problem. So if you use it for research on where it doesn't affect people. Absolutely fine to use bias preserving in Europe as well. If you are unsure of what a good outcome would actually look like, it's much better to keep things as they are than making them worse.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"If you don't have a normative idea of how things ought to be, then you can use them as well. You can also use them if there are situation where have justified buys or even desired bias if we wanted that and wanted to preserve that, that is fine to use as well. Then areas where you do actually have ground truth, where there is no bias in the data set. You can also use bias preserving metrics.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"So there's a whole range where you can justify the use. The only problem is that if you're making life-changing decisions about people in a protected sector and that sector is known to exhibit certain biases, then the preference would be, it'd be easier for you from a legal perspective to use bias transforming ones because at least, they offered the possibility of making things that they used to be.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:44:00] Sam Charrington: So the first contribution to this paper is this drawing the distinction between bias preserving and bias, transforming, and correlating those two classes of fairness metrics or bias metrics to the European non-discrimination law.\\n\\nBut then you're also proposing this new test. How has that new test advantage relative to the class of bias transforming metrics that can work under the European law?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:44:36] Sandra Wachter: What you really need to do, and what a bias tests should help you do is reflect on what you are able to do in order to make a positive contribution. The bias test is not supposed to tell you what's right or wrong. It should just tell you that something might be a problem; supposed to act as an alarm system. So what you should be doing is that you run... Let's say 're you thinking about loan decisions, that you run your algorithm that is distributing low end decisions,\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='low end decisions, and it will tell you, \"Oh, did you know that you current deployment doesn\\'t give black people any loans?\"', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"Then it will tell you what kind of conditions, criteria and variables we're conditioned on. What that helps to do is to have an informed discussion of whether or not certain biases are justified or not. Because again, in Europe and the discrimination law, not everything needs to be fit.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"What needs to happen is if something is unfair, you need to tell me why. That is the thing that the test helps you to do, because let's go back to the bank example. You could say, for example, what we use income to make decisions on what somebody should get alone, which makes intuitive little sense.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='You could put those criteria conditioning on input in there, and it would tell you, \"Oh, hard to get any women are getting loans. Is that on purpose?\" and then you could ask the question. Okay. I\\'m conditioning on salary and it has a negative victim gender. Is that justified? Because you could say, well, how can we even use income? Since we know about the race and gender pay gap. That\\'s a horrible criteria to use in the first place. It\\'s like, \"Oh, we\\'re not going to use that. We don\\'t want to', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='We don\\'t want to do that.\" Or you could say, well, yes, we know about those inequalities, but it\\'s a very effective and defendable proxy. Whether or not somebody will be repairing alone and actually putting people in a situation where.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"I have to default the world default and in depth, the mean of further it's also irresponsible. So maybe we should be using income, right. Or you could say, well, income isn't great. But how about those other criteria? Additional criteria that are also very good at predicting something but are not as disadvantaged. That's for example, income. That's the dialogue you need to have, right? The test can help you to do that because it would lay open how your current decision system is affecting or is\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"is affecting or is making decisions across groups where you could see, does it actually make equal decisions across gender lines or airlines fitnessity or age or whatever, and it tells you what kind of criteria we're conditioned on. Then you can justify to yourself and ideally actually to the general public as to why those criteria are acceptable to use even if they may end up in unequal distribution, if it is the only way to go about it because that's the very unconvenient, and unhappy\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='and unhappy discussion we need to have is what kind of disparity is acceptable and which is not. That bias tests will let you do that.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:48:11] Sam Charrington: It sounds like and this is maybe apparent from the name that the key thing that you, the key innovation or contribution of this new test is that it makes explicit this conditioning on other factors, uh, something that's you, maybe you don't have the same degree of flexibility or the same mechanism to do that conditioning with some of the other tests.\\n\\n[00:48:35] Sandra Wachter: Yes, exactly.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:48:37] Sam Charrington: Got it. Got it. Then, so you've now got this test. You've got this. You've identified the relationship between these tests and this particular set of regulations in Europe. What are the next steps for you and pursuing this research or more broadly your interests in bias, fairness and discrimination in the law?\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:49:09] Sandra Wachter: Yes. Yeah. Fantastic question. I'm definitely going to maintain an interest in all those three areas going forward. I think one of the next topics that I will be diving a bit more into is the new regulation that is looming at the horizon here in Europe because there's a new draft that came up at a European commission.\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='The AI act that is the first ever first attempt at a regulatory comprehensive regulatory framework to govern that. So there will be, I think, a lot of work that not just me. I think a lot of people will try to dive to ,Teave into, to figure out whether this is a good attempt and what can be done there.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"So I think that will remain a very active research area. The other ones that I'm definitely going are areas of, of health that I'm particularly interested in as well as education and financial services.\\n\\n[00:50:20] Sam Charrington: Those latter two areas, health and well, three - health education, financial services, still looking at the intersections of those AI and the law, or..\", metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:50:35] Sandra Wachter: I think those three areas will accompany me definitely but I will probably look at it more from a power perspective and a broader regulatory landscape and oversight landscape.\\n\\n[00:50:52] Sam Charrington: Got it. Got it. Got it.\\n\\nWell, Sandra, thanks so much for taking the time to share a bit about what you are working on. Very interesting stuff and certainly enjoyed the conversation.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content='[00:51:05] Sandra Wachter: Thank you so much. It was great to be here. Thank you for the invitation.', metadata={'source': 'content/data/521 - Sandra Wachter.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: All right, everyone. I am here with Hima Lakkaraju. Hima is an assistant professor at Harvard university with joint appointments in both the business school and the department of computer science. Hima, welcome to the TWiML AI podcast.\\n\\n[00:00:17] Hima Lakkaraju: Thank you so much, Sam. I'm super excited to be here.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:00:20] Sam Charrington: Same here. I'm really looking forward to our conversation. We will start where we typically do on the show, and have you share a little bit about your background and how you came to work in machine learning. In particular, you're focused on fair and interpretable ML and the implications and mission critical, high stakes domains like criminal justice, healthcare, and public policy. How'd you get started in all this?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:00:53] Hima Lakkaraju: That's actually an interesting story. Let me try and summarize it in a hopefully fewer sentences so that we are not hogging all the time here. I was actually working in machine learning, right so basically I come from India, I moved to the United States for my PhD in 2012, I have been working in machine learning since I was a student in India. I was publishing actively in machine learning, but my interest in the applications of machine learning to some of these domains\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='of these domains like criminal justice or healthcare, that started or it became a prominent thread in my research when I started my PhD, and this was, I guess mostly due to a collaboration now between my advisor and another couple of professors and economists who were dealing with behavioral economics, and they introduced us to all these fascinating problems as I was, I think by then I had already explored machine learning to a reasonable extent, and I was looking for applications which were', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='which were more than just like add recommendations or friendship recommendations and so on so that I could keep myself going in the field and also anchor onto something which is more applied in the sense of real world settings and so on.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='I guess my PhD was like one of the main times in my life where I got into both machine learning as well as its applications to some of these domains, which are super fascinating and the broad field of fairness and interpretable interpretability in ML. Yeah.\\n\\n[00:02:42] Sam Charrington: You know I suspect when we dig into your upcoming, well, actually your recent talk at CVPR where you were at an invited speaker in the \"Fair, Data-Efficient and Trusted Computer Vision Workshop\"', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:02:57] Hima Lakkaraju: Yep.\\n\\n[00:02:58] Sam Charrington: We will learn about a bit of your research, but kind of broadly, how do you frame out the kinds of questions that you're looking to answer with your work?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:03:11] Hima Lakkaraju: Right. I guess in a broad sense, the way I think about my researchers is it's about enabling machine learning to help with decision making in high stake settings, right? And that involves some sub questions like how can we make sure tha machine learning models, which are of course getting more and more complex day by day, are in a more palatable form to these decision makers who are not necessarily experts in machine learning, so how do we explain these models? What\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"these models? What are the algorithms that we can use, which can in turn, explain these models to people who are not machine learning experts? That's of course, one of the key questions and also other core question behind interpretable ML, right? And beyond that, when we develop some of these tools, which will assist these decision makers in important decisions, how do we ensure that the tools or the algorithms that we are developing are by default fair? Otherwise, they can induce their own\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='can induce their own discriminatory biases and undesirable biases into the entire real world decision making.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"That's of course, another question and more broadly also just trying to develop models and methods to understand what kinds of biases exist as of now in human decision making, like even if there was no algorithm in [Walden] the picture, as well as how to diagnose biases, if someone gives me an algorithm, what is the best way to do that? These are roughly the broad questions I think about.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:04:43] Sam Charrington: Okay, and so your talk is titled \"Understanding the Limits of Explainability in ML-Assisted Decision-making\"\\n\\n[00:04:52] Hima Lakkaraju: Yep.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:04:54] Sam Charrington: There's some interesting tidbits that I'm looking forward to digging into, around like some of the explainability algorithms like LIME and SHAP but before we even do that, thinking about the topic of your talk in the workshop makes me think of Podcasts that I did with Cynthia Rudin last year. Her perspective seems to come from a different direction which is, we shouldn't even be using black box models for the kinds of problems that you're studying.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:05:30] Hima Lakkaraju: Right.\\n\\n[00:05:31] Sam Charrington: We should be using models that are more fundamentally understandable, and many conversations I've had in this topic, there's this tension between explainability, interpretability.\\n\\n[00:05:48] Hima Lakkaraju: [Inaudible] Yeah.\\n\\n[00:05:49] Sam Charrington: Yeah. I'm curious, out of the gate, what's your take on all that?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:05:55] Hima Lakkaraju: I think we are already starting with a very interesting and controversial topic. I mean, Cynthia has been a mentor and a collaborator for several years, but we somehow manage to coexist with this dichotomy. I mean, I agree with this point, or rather my take on this would be that if at all it is possible for you to develop a model that is interpretable by default and is also accurate, and you have the data to build such a model, by all means you should go for it, right?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='go for it, right? Because there are no barriers here, but unfortunately the real world is always not like that, so in some cases you may not have enough training data for example, to build a disease diagnosis model, right?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"You might be then using another proprietary model that some other company has built, and in that case you would still want to do some diagnostic checks to ensure that the model is doing what it's supposed to do, and the way it's making predictions is reasonable and so on. Those are the kinds of cases where explaining a given model or a black box model as we are calling it, is probably the only option, right?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"Because you don't have the ability to build such a model because of lack of data or resources and umpteen number of other reasons, but you have the capability to buy or get this model from a third party, but you still want to vet it or understand what's roughly going on with the tiny bit of data that you have, or like just doing some diagnostic checks with whatever little amount of data that you have, which may not be enough to develop an accurate model, but at the same time might be recent\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"time might be recent enough to vet a given model. If that is the context you're dealing with, then essentially explaining or understanding what the black box might be doing is probably the only option.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"These are of course, again as I mentioned earlier, these are constraints that is rising in the real world and that's what we are thinking about, but yes, if you have the means to develop an interpretable model from scratch, you have all the data, you have the necessary means, and it's also accurate of course, that is definitely the way to go. Just that there are many other real world context where that might not be the case of which you could actually pursue.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:08:27] Sam Charrington: In the scenarios where you can't do something that is more fundamentally transparent and you're doing something that's a black box and you want to explain it. There are some known and popular methods for achieving some level of explainability, and I mentioned a couple of those already LIME and SHAP, but a part of your presentation references, some previous research that you've done that has shown that that work can be vulnerable to attack.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"Maybe let's take a step back and you can tell me, with your presentation, what's kind of the broad landscape that you're looking to carve out and we'll get to the particulars of LIME and SHAP when we get to them.\\n\\n[00:09:34] Hima Lakkaraju: Sure.\\n\\n[00:09:36] Sam Charrington: How do you frame the problem of understanding the limits of the explainability tools?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:09:44] Hima Lakkaraju: I think the stock and more broadly my recent research has been exploring as we are thinking about the limits of explainability, and what I mean by that is, so far, at least in the past few years, there has been a lot of interest in coming up with new algorithms which can explain black boxes, right? There is like a huge research that has built up, I think since 2016, pretty much like paper on top of papers. Every paper comes up with another new method for explaining a', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='for explaining a given black box classifier or a prediction model. One of the things that as we were seeing more and more work on this topic, me and some of my collaborators of this work, we got excited about is how to now start thinking about what are all the ways in which these explanation techniques can be gamed or potentially even unintentionally misused to generate explanations, which could fool people or mislead and use us into trusting something that they should not trust, right?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"For example, maybe if your explanation, basically if your model, let's say if you have a black box model, which is actually using race or gender, some of these sensitive features, which are prohibited to be the key aspects for making critical decisions, like for example who gets a bail or who gets a loan and so on. If a black box model is using some of these features, and if your explanation is somehow misled to think that that's not the feature that it is using, but instead it's using another\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='it\\'s using another correlate. For example, a zip code when making prediction and end user might look at this explanation and just be misled that, \"Oh, this seems like a model that\\'s not using race, it\\'s not racially biased. It\\'s using other correlates. Maybe it\\'s fine to deploy it.\" Right?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='An explanation that can be misleading in terms of explaining what the black box is doing can have serious consequences in the real world, as we can just see with this kind of example, right?\\n\\n[00:11:53] Sam Charrington: Yeah.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:11:53] Hima Lakkaraju: The line of work that I'm pursuing currently is how to identify some of the issues or one of the abilities of existing methods, which can potentially lead to these kinds of misleading explanations and also understanding what is the real world impact if there is a misleading explanation, so what would be the consequences of that in real world? And for that, I'm also doing a bunch of user studies with students from law schools and healthcare professionals and so on to\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='and so on to see how a misleading explanation can affect their work.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:12:26] Sam Charrington: Okay.\\n\\n[00:12:27] Hima Lakkaraju: This is pretty much what the talk is all about, yep.\\n\\n[00:12:29] Sam Charrington: Got it. I've got to imagine that the effects of these misleading explanations vary pretty dramatically depending on the setting in which they're used.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:12:42] Hima Lakkaraju: That is definitely true, yeah. I think, for example, since anyways we are discussing this, let me segue a bit into the second part of the stock, which essentially talks about the effects of these explanations in a particular context. The context we are looking at is, let's say if there is a model that is designed to predict who should get a bail, right? At least it's designed to assist the judge in determining who should get a bail, but in the process, the model is\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='the model is also making predictions as to who should get a bail, right?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"Before such a model is even deployed in the real world, ideally the judges or the teams of the people, it'll definitely go through a lot of vetting and people would like to look at what the model is exactly doing before they decide to trust and deploy it in some sense, right?\\n\\n[00:13:38] Sam Charrington: Yeah.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:13:38] Hima Lakkaraju: That context, we designed a small experiment with law school students, of course, it's all proxy because the time from judges and these senior domain experts is, their time is much more valuable, and it's not as easily available, so we were trying to mimic that, but then with the law school students here at Harvard and Yukon.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='Basically, what we did was we essentially built a simple, in fact, Cynthia Rudin style rule-based model, which is the actual black box, which explicitly has some rules which are used to determine who gets a bail or not, okay? In that, we specifically used all these bad features or undesirable features like race or gender to determine who gets a bail.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"Then we constructed an explanation for this rule based model, which is another set of rules, and then in that we explicitly avoided the usage of the features, race, and gender, but the explanation is free to replace it with it's correlates. Like replace these features with its correlates, so race could be substituted by zip code or anything else, but the explanation is just not allowed to show race or gender explicitly, right?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='It should still make the same predictions as what would be made by the original black box model that we constructed.\\n\\n[00:14:55] Sam Charrington: Is this an actual system that generated these explanations, or did you create these explanations to simulate what a system might do under the set of conditions that you outlined?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:15:10] Hima Lakkaraju: One of the existing techniques is what we use to generate the explanations for this black box. It's just that we put an additional constraint on that technique that just makes sure that race or gender do not show up in the explanations.\\n\\n[00:15:23] Sam Charrington: Got it.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:15:24] Hima Lakkaraju: Now, the experiment was something that revealed very insightful things to us, which is we basically split people into a couple of groups, we took a bunch of law school students, we split them into two groups. For one set of people we showed the actual model, which has race and gender, and then we asked them if this is the model, or if this is an explanation of a model, which is showing you that race and gender are being used in making these predictions of who should be', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='of who should be jailed.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='Would you trust this model enough to deploy it in your court? If you were a judge, as a human, you were a judge, right? Most of the people of course as expected said, \"No, the model is using race and gender. I don\\'t want to deploy it anywhere close to me, sorry.\" But then when we give them the explanation, which was tailored to hide or cover up some of these problematic features, and then showed it to the other half of the people, and we said, this is an explanation generated by a state of the', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='by a state of the art machine learning to explain a black box using this. Now, do you trust the underlying model enough to deploy it? And most people said, yeah, sure. Because it seems to be doing something which reasonably matches my intuition of how we should determine someone should be given a bail or not.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"I don't see you usage of any prohibited features or problematic features. Yeah, sur,. Let's go ahead. So the actual true model, less than 10% of the people trusted it and the explanation that we generated, which is essentially doing the same thing, but replacing race and gender with its correlate almost about 80% plus people trusted it\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:17:03] Sam Charrington: Oh, wow. It reminds me a little bit of some experiments that Ayanna Howard shared with me in an interview with her, about her research into just the authority that we tend to confer on computing systems, in her case robots.\\n\\n[00:17:22] Hima Lakkaraju: Robots, yeah.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:17:23] Sam Charrington: The examples that she gave were, you know, a robot that is presumably supposed to lead you out of a fire or a dangerous condition in a building, you will like stand behind it, banging itself against the wall and waiting for it to, you know, all of a sudden, I think, because we just want to believe that these things are, you know, more infallible than they are.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:17:47] Hima Lakkaraju: Right. Yeah, no, definitely. I think this research, I guess also fits in line with some of that work in the sense that people are probably already approaching models and model explanations from the perspective of some prior trust, right? They're already willing to trust them, which is why some of these issues are like the things that we are seeing, are actually being seen, so yeah.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:18:15] Sam Charrington: Realizing we've kind of jumped ahead to the end talk, but did you further explore around different ways to present that result that helped, besides from the one example where you show the race and the other where you hide it, are there things that you've played with, like showing the different correlating features or other things that can help the human understand what's really happening?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:18:51] Hima Lakkaraju: Yeah, so that\\'s actually the ongoing research that we\\'re actually doing, which is what is the best way in which we can educate people that, \"Hey, the explanation that you saw, it is purely correlational.\" And it\\'s like, when it says that the court is being used, it could essentially mean that any zip code, [audits] correlate could be actually used to make predictions, right? In fact, one thing is we designed like a very short 5-10 minute, like a primer or tutorial,', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"primer or tutorial, just highlighting some of the examples that just because you don't see race, it could still be present because the correlation between race and zip code is like greater than 0.8 or something, right?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"Then designing some examples like these. It's a very short 10 minute tutorial and using that, we can already see some mega improvements in terms of how people already like latched onto some of those ideas, and the next time we ask them a similar question, they are like less likely to make this kind of a mistake. We're also just thinking about what training might help people in like realizing some of these things, because again, what we are designing or, you know, even the way that we are\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='the way that we are producing these explanations, our intention is that they would be used by someone who is not an expert in machine learning.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"We should also be prepared to teach them how to think about these explanations and what they can, or they cannot provide in terms of information. I guess that's the next step or the next research that we're conducting, and again going back to your earlier question, we are also looking at this, of course, one scenario, as we talked about where misleading explanations have this impact, we're also looking at other scenarios again in healthcare and a bit in like the business domains where we are\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='domains where we are looking at different kinds of decisions. Like some of which are more high stakes, the others, which are a bit more low stakes, so in those cases, what would be the implications of misleading explanations, yeah.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:20:53] Sam Charrington: Okay. Let's maybe take a few steps back and talk a little bit about the explainability techniques that you're seeing in use and, where you're seeing them in use. Have you done a survey of the various techniques and how they're being used in practice? I know you talked specifically about LIME and SHAP and I hear those come up probably more than any others, but I'm wondering if you looked broadly at that?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:21:26] Hima Lakkaraju: Yeah, so while it's not an active area of my research. There are, I think some other folks who are thinking about these things, but in general, you're right. These two techniques, one of the reasons we also picked those was because they were being very widely used in practice and industry and in other real world settings. That was also one reason to see if there are anyone that [abilities] in those first, because they're so widely used. Beyond that also there are like\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='also there are like several techniques which are probably much less popular, but they try to address some of the issues that are present in the first two techniques, LIME and SHAP, just to name a few. For example, like MAPLE is another approach that has been proposed, which tries to get rid of some more of an ad hoc.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[Inaudible] or like some of the ad hoc pieces within LIME and sort of make them more systematic, so that's another approach just to give an example. Of course there are like several more, which are like news, and a bunch of other things, anchors and so on. There has been a lot of work just built upon this entire explaining black boxes, as I said like since 2016.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"By now there are countless approaches, but I think the most well known among these are LIME and SHAP. Now coming to the second part of your question where you're thinking about how are people using these techniques? Honestly, the domains that I look at, so we are still trying to make decision makers, like doctors or judges aware of these techniques and how they should even use them, but that's the domains that, I deal with a lot, but I can easily imagine that if you're looking at maybe a startup\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='at maybe a startup or a tech company and so on, their people are like more well familiar with these kinds of techniques and they may already be using some of them in their day to day job, whether as a developer or an engineer, or a scientist, you are trying to understand what a particular model is doing, maybe to debug the model and so on.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"I can imagine all those kinds of use cases already underway and where explainability is playing a bigger role in practice and day-to-day applications. Yeah, the domains that I deal with, like especially where you're a bit more detached from the core machine learning, you're dealing with people who make different kinds of decisions, they're not tech people, they're not experts, so it is like these kinds of approaches are like reaching them at this point barely, I would say, yeah.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:24:15] Sam Charrington: Yeah. In your talk, did you go over how the different techniques work, and what some of the weaknesses or blind spots that are inherent to them are, and where they come from?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:24:31] Hima Lakkaraju: Yeah. I think the first part of this talk is mainly about what are the weaknesses of LIME and SHA,P and just to think about more broadly, the explanation techniques, you can roughly characterize them into two categories. One is local explanation methods and the other is global explanation methods. I guess, as the name suggests, local means you just think of explaining a complex behavior only within a particular tiny locality or neighborhood in the data, right? A small', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"data, right? A small piece of the feature space. You're trying to explain what the model is doing there as best as you can, so that's the local explanation methods. Then the global explanation methods is you somehow want to give the entire picture of what the black box model might be doing, like the whole big picture, so that like someone, like for example the use cases of these two could be different where in the case of global explanation, the idea would be that someone who is deciding if a\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='who is deciding if a model is good enough or whether it should be deployed, like maybe a team of judges are a stakeholder who has a lot of authority on deciding if some models should be deployed or not.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"He or she might use those to vet and decide, is this model even reasonable enough to deploy, right? That's where the global explanations come into picture, because you're giving a zoomed out view of what the model's behavior looks like, right? On the other hand, when you think of local explanations, it could be to just like as a model is deployed, after the model is deployed. Let's say in a hospital to diagnose a disease or something. For every patient, the model will give you a particular\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='you a particular diagnosis saying that this is basically what the diagnosis should be, say, someone has diabetes or not, for example, right? In such cases, you also want to get an explanation for why that prediction has made the [weight].', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"Then we focus more on the local or instance level, or like singular predictions, and that's the case where after a model is deployed, a doctor is just double checking that a single prediction makes sense, right? That's the use case. Then for the global, it has to decide if a model at a high level is even good enough to sort of be there.\\n\\n[00:27:06] Sam Charrington: Are you back?\\n\\n[00:27:15] Hima Lakkaraju: Yes.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:27:18] Sam Charrington: Okay. Did the local and global methods share the same weaknesses or issues, or are they different?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:27:28] Hima Lakkaraju: Yeah. In fact, the weaknesses are specific to the exact techniques employed to generate a global or local explanations. Like for example, the first part of my job is broadly focusing on what is called a perturbation based methods, right? I'll get into the details of what I mean by that a bit. Then there are other methods which focus on using gradients to sort of determine what features are being used when making a prediction. The attacks, these two classes of\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"these two classes of techniques are vulnerable to different kinds of attacks, so the same attack would not work both for the perturbation based methods as well as a gradient based method. Yeah, the attacks are specific to the exact techniques that these methods are using, so they're much more fine grained than even just local and global.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:28:20] Sam Charrington: Okay, so in the case of a perturbation type of method, like LIME, what does the attack look like? How are those attacks constructed?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:28:34] Hima Lakkaraju: Right. So let me start by just giving an intuition about what LIME does so that it becomes clear what the attack would look like, right? What line does is, it is trying to at a very basic or core level, LIME is trying to explain individual predictions of classifier, so for each prediction it's trying to give you, which features were important, and what was their weightage in making this prediction, right? Now, what lime does is it goes to sort of every data point, so\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"every data point, so basically if we want to explain a prediction of a particular data point, LIME takes that data point, and then it sort of perturbs that data point, and when I say that, think of it as like you add some noise to different features of this data point, okay? Then that's what we call as perturbation.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"You just kind of slightly massage the values of these data points, generate another artificial data point and keep doing this until you have a bunch of data points which resulted from perturbing that initial instance or the data point you wanted to explain, right? Now what we have, let's say we got hundred such perturbations or massage data points, and then you have this actual data point that you wanted to explain. Now, think of it as you just build a linear regression model on top of this, so\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"on top of this, so that that model is predicting what the black box models predictions are for these hundred data points. Okay? It's basically taking a data point, massage it to create some artificial data set around the data point, now just put a regression model and then it will give you what are the feature importance weights for each of the features, right? That's what LIME is doing. Now, why this is called a perturbation-based method is, in order to even flip a linear regression model there\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='model there or any local linear model there, you are generating some perturbations of this initial data point where you started from, right? Typically, these are the, this is what we call as perturbation-based methods, okay?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='Now the attack, once you sort of know, key intuition becomes very clear and obvious, so what we found as part of like analyzing what LIME is doing and so on, in fact one of the PhD students that works with us found this was the perturbations that are being generated by LIME are actually not the points that are in the data distribution. These points look very different than the points that are actually in the data distribution that we care about, okay? This could potentially be even often', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"be even often [manifold] data points or points that are like very far off, because you're just massaging a point, and assuming that you'll end up with a point that is sort of close enough, right? That does not always happen. Given that the perturbations that you are generating using LIME are not really the points belonging to the in-sample data distributions. That's a key point to sort of remember.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"Now that that has happened, or now that we realize that that was the case, what we did was design a simple attack or like build this, what we call as a [dual serial] classifier, which does something very sneaky which is, this classifier, it looks at a point and then it basically decides if the point is in the data sample or if it's a perturbation. You kind of make this prediction as to is this point generated by perturbation? Is this a synthetic data point or was this point in the data ? Now,\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='in the data ? Now, when a point is in the data, then this classifier says, \"Yeah, let\\'s use race or gender or any other undesired attribute that you could think of and make a prediction.\"', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='If a point is a synthetic data point, which means it\\'s a perturbation, then look like you\\'re super fair, like don\\'t touch any bad features, remain like super pristine, be very careful, like do something very clean and innocuous looking, right? When you do that, what happens is, and when I give that classifier to LIME to explain, since LIME relied so much on perturbations, it thinks,\" Oh, this model is doing fine on perturbations. I don\\'t see race as an important feature when it\\'s making', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='when it\\'s making predictions on those.\" It will just assume that the model is not using race as a feature when making predictions. Whereas underneath, what is happening is it\\'s like a wrapper, it\\'s like an [adversarial] rapper, you can think of that. It\\'s kind of nicely shielding, it\\'s kind of shady behavior, for lack of a better word, by doing all the shady things on in-sample data points, and then looking very innocent on any perturabtion, so that is the attack which is throwing off LIME, and', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='off LIME, and though the model uses race as the only and main feature and making predictions, because it has an innocent behavior on the perturbation data points. LIME is just assuming that it is using some very innocuous features when making predictions and it can never catch this underlying racial behavior or that desired behavior, which is this race, yeah.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:33:55] Sam Charrington: The setting kind of goes back to your set up at the very beginning of our conversation. Maybe you can't use a transparent model that you developed yourself, so you're getting a model from someone else kind of [shelf].\\n\\n[00:34:14] Hima Lakkaraju: Yep.\\n\\n[00:34:15] Sam Charrington: The attacker in this case is whoever's creating the model.\\n\\n[00:34:19] Hima Lakkaraju: Yep.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:34:20] Sam Charrington: The scenario kind of reminds me of Volkswagen gaming the EPA, when the cars detected that they were being tested for emissions test.\\n\\n[00:34:30] Hima Lakkaraju: Right.\\n\\n[00:34:31] Sam Charrington: They changed the way that they were throttled or whatever, it would make their emissions fall within spec but you know, out on the road, they were--\\n\\n[00:34:39] Hima Lakkaraju: Yeah.\\n\\n[00:34:40] Sam Charrington: Seeding the levels.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:34:42] Hima Lakkaraju: Exactly. Yeah, this is I think a very good analogy. Yeah. That's pretty much what this adversity who is designing this classifier is also doing. Those off the shelf classifier is also doing, so the main idea is if people are just using like for example, LIME or SHAP to determine are there any underlying racial agenda biases in this classifier, then the adversary can successfully fool them because they're able to fool these explanation methods.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:35:12] Sam Charrington: In this work, in this presentation, do you propose any protections for this or are you identifying the attack--\\n\\n[00:35:24] Hima Lakkaraju: Yeah.\\n\\n[00:35:25] Sam Charrington: The attack vector?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:35:27] Hima Lakkaraju: Right. That particular piece of work was just identifying the attack because that itself was, I think one of the initial works, which even talks about attacks on explanation methods, but our ongoing work is definitely looking at how to design these explanation methods which are robust to those attacks, or which cannot be game to sort of make these kinds of attacks successful, so how to think about them, so that's an ongoing stream of research, yeah.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:35:57] Sam Charrington: Does a method like lime work if your perturbations are only producing, or in the direction of kind of in distribution results? Like, is that a direction that you're looking at?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:36:12] Hima Lakkaraju: Right. Yeah, so that's one of the directions we are looking at, but then you can also think of this as there are some two problems, which are like two sides of a coin, right? One is, then you can basically make these perturbations more and more similar to your data instances, right? That will potentially subvert this kind of attack so we can make a line plus plus where your perturbations look more and more similar to your data instance.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:36:39] Sam Charrington: Yeah.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:36:39] Hima Lakkaraju: Right? So that's one thing, but then there comes another problem, that's a fix for the setup, right? Then there comes another problem, which is your explanations will start becoming more and more data dependent, right? Because if you have a data set, then the explanation that you build will only hold for that dataset. Which means if you change the data set or something, then the explanation is no longer going to hold, so that's another problem of this, because you are\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='because you are making this explanation very tied to the data.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"So now how do we fix that is another problem, but I think this is again, like a bit of a trade off where you can think of this like a scale where the more you move to one side, you're probably creating some issues on the other side, so we are also looking at formalizing those tradeoffs and like, saying that, yeah, as you try to achieve more of perturbations that look more and more similar to your data, yes you support one attack, but then you are creating explanations that are only holding for\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='are only holding for your data. Is that good or is that bad? Like what are the trade offs between these two?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:37:46] Sam Charrington: Okay. In your research, have you identified any other similar types of attacks, are there others that have been proposed?', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:37:56] Hima Lakkaraju: Again, as I said like this is one of the initial ones, I think, as a followup paper or as a followup work, there is another team in Utah that has a recent ICML paper on specific attacks to SHAP, so that is a followup work which again, sort of plays on, or builds on some of our earlier work, but I think, so far there have mostly been items [like] looking at like perturbation-based methods. There is a lot of scope for open work on other kinds of methods including', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"of methods including gradient-based methods, and even global versus local, what needs to be attacked and what is most vulnerable in each of these, and so on. There's like a whole set of open problems that haven't really been addressed so far.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:38:41] Sam Charrington: Are there any interesting connections between the work that you're doing here, and the broader research field of adversarial machine learning attacks? A lot of this is based on perturbations and noise, and so there's at least a nomenclature overlap, does one have something to offer than the other and vice versa?\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:39:10] Hima Lakkaraju: Yeah. Yes, I think this work is actually inspired by, some adversarial machine learning literature. There, the focus was more on finding examples or data points which can throw off a classifier, right? Whereas here, the focus is \"Now let\\'s find something which throws off an explanation method.\" Like I guess, that way there is like a very clear [parallel]. What adversarial machine learning was doing for classifiers and prediction models, we are trying to do that with', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='to do that with explanation, so I guess that way there is like a pretty tight connection.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='In fact, you know as I was saying about some ongoing work which tries to address some of these vulnerabilities like in perturbation methods or otherwise. The way we also try to fix the vulnerabilities and come up with a new explanation method is also inspired by how people think of adversarially robust classifiers in the adversarial machine learning literature.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"Just like people had this, let's first see what are the vulnerabilites where things are breaking down in terms of classifiers, then how can we develop a robust classifier, so the same thing is playing out in parallel in the explainability literature, so yeah, there is a pretty clear connection.\\n\\n[00:40:32] Sam Charrington: A lot of that ended up saying more regularization, is the approach. Is that going to be the answer here too?\\n\\n[Inaudible] equally.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:40:43] Hima Lakkaraju: Yeah, but I guess there are a couple of things though, right? For example, one thing is even beyond regularization, it's also about thinking about like formulations, like maybe a min-max, which is, you know, like thinking about the maximum possible error that you could have on a variety of distributions that you want your model to work on, or like a variety of data sets you want your explanation to hold on, and minimizing that maximum error, so I guess those kinds of\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='guess those kinds of formulations are also very helpful, apart from regularization and so on. I think those ideas are useful to flow from that community to the explainability community. Beyond that, I also am hopeful that there could be other interesting challenges with explainability.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='The reason why I say that is because, as algorithms are being increasingly used for various decisions like whether someone gets a loan, right? Whether someone gets a particular treatment, or whether they are given a bail or not, so there is an increasing call from both legal scholars and social sciences scholars to make these machines also provide recources to people. When I say that, what do I mean is if I as a bank, am using an algorithm, and if I tell someone a loan is denied for you, I also', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"for you, I also need to tell them what needs to be changed in their profiles so that they can come back and get a loan, right? They're making these algorithms more accountable, which means the gaming of these kinds of methods is going to be very real.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='Like when you think of classifiers and some adversaries, giving you an adversarial sample or example and so on. I guess the danger of that somehow seems a little bit more limited to me than like when it comes to explainability where people are relying heavily on this and like things are moving increasingly in the directions that people are looking at these and making decisions of what models to use, making decisions, like whether a prediction is reliable or not.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"So as you're hitting more and more of these real world scenarios, we also need to be worried because the risk of these things being manipulated and gamed is very real and very high, but at the same time I can see a lot more real world applications, or like usages of these scenarios probably way more than someone trying to change pixels and an image, and so on, right? While that's an interesting concept to think about to solve the problem, or like from an engineering perspective, technical\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"technical perspective, here, the social implications are very real. I'm hoping that this would also bring with that more interesting technical challenges as well.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:43:42] Sam Charrington: Is there a GAN application here where you've got some model that's trained to try to fool some model that, you've got these two adversarial models that are trained to try to pick out the distribution samples or something like that, and one of the model's trying to cheat the other? [Inaudible]\\n\\n[00:44:08] Hima Lakkaraju: Yeah. No I think [ Inaudible] there, I think some of them are even ongoing work, is sort of headed there.\\n\\n[00:44:13] Sam Charrington: Okay.\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:44:13] Hima Lakkaraju: I guess the way, at least like, me and my group or some of the other researchers are approaching this problem is trying to keep a real ear to the ground because a case where someone can build a classifier, which can do something messy within sample data points and look very pristine and clean with these perturbations that the approach relies on is like a very realistic thing, and it's not even a super sophisticated attack if you think about it, right?Wwe are trying to,\", metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='are trying to, at this point, keep our ear to the ground and look at those most plausible scenarios and how to fix them, and then of course some of these will automatically happen, which are definitely interesting from technical perspective and so on.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content='[00:44:59] Sam Charrington: Yeah. Yeah. Great. Great. Well, HIma, thanks so much for sharing a bit about your presentation and your research.\\n\\n[00:45:08] Hima Lakkaraju: Yeah, thank you so much. Yeah, this was amazing. I had a great time talking to you.\\n\\n[00:45:13] Sam Charrington: Same here. Same here. Thank you.\\n\\n[00:45:14] Hima Lakkaraju: Thank you.', metadata={'source': 'content/data/387 - Hima Lakkaraju.txt'}), Document(page_content=\"[00:00:00] Sam Charrington: Welcome to the TWIML AI podcast. I'm your host, Sam Charrington. Thanks so much for joining us. And if this is your first time, I invite you to hit subscribe in Apple Podcasts, Spotify, YouTube, or wherever else you might be listening to the show.\\n\\nAll right, everyone. I am here with Yunyao Li. Yunyao is a Senior Research Manager with IBM Research working on natural language processing. Yunyao, welcome to the TWIML AI Podcast.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:00:45] Yunyao Li: Thank you so much for having me here.\\n\\n[00:00:47] Sam Charrington: I'm looking forward to digging into our chat. We'll be talking of course, about NLP and some of your experience on the research side, as well as making it useful for IBM's enterprise customers. To get us started I'd love to have you share a little bit about your background and how you came to work in the field.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:01:07] Yunyao Li: Sure. So, as you mentioned, right now I'm a Senior Research Manager at IBM Research. Before that, how did I get there? It's actually a long story. So, I have to say, I grew up in my small town in China. Before I went to college I did not even see a computer. But when I picked my major, I picked the major of automation because I thought if I automated everything, I don't have to do anything. So, that's how I started really thinking about AI helping people.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:01:41] Sam Charrington: Okay.\\n\\n[00:01:41] Yunyao Li: When I went to college I also did a second degree, I did a dual degree. I did automation and economics. Then I went down to come to the U.S. to pursue my graduate studies. So, I did two master's degrees again. I did one in computer science, another one in information science, because I wanted to understand the technology itself, but I also wanted to understand how technology's impacting people.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, my information science is more focused on the HCI and the information economics. Then, I pursued my PhD in database. However, it's not a traditional database PhD. What I did was to enable people to [create/query] a database using natural language. That's basically one of the hardest the topics today in natural language processing. So, I would say my connection with AI basically started from the very beginning of when I started my higher education.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:02:43] Sam Charrington: Nice, nice. And now as a Senior Research Manager, talk a little bit about your research interests and more broadly, the role. It sounds like you're focused on traditional research, but you also have these customer engagement element to your role. Can you talk a little bit about that?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:03:07] Yunyao Li: Sure. So, my general research interest is quite broad. But in general, I'm a very passionate about building systems and the tools to enable people, a wide range of users to be able to use technology. In this particular instance, I work in the field of natural language processing. My passion is really to empower people to harvest information from text, to build the next generation of AI applications.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, within IBM, we have a lot of products based on natural language processing, [inaudible] like Watson NLU, Watson Discovery, and so on. So, behind this technology, I'm very proud to say a lot of the products are part of a technology developed by my team. So, really empower the product themselves.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='Meanwhile, we have things in the lab that may not always mature enough to put in a product yet. So, then we\\'ll also often engage with customers and also our technical sales team to say, \"Okay, for this particular problem, we don\\'t have a product yet. What can we do for the customer?\" And that really helps me to understand, what are the key challenges that we need to address from a research point of view? In my mind, as someone working in an industry research lab for over 10 years, I really', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"10 years, I really enjoyed that because when I was in school, you always need to think about what's your motivation behind the work? Here in industrial research. I don't have that problem. The problems come to me.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"And then, the interesting part is how do I generalize one person's specific problem into a research problem that can be solved in a staged fashion? Both very ambitious from a scientific point of view, but at the same time with the [nearer] sense, [of the way to go].\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:05:04] Sam Charrington: Yeah. Well, I want to dig into some of the specific challenges that you've identified in the NLP domain, but that last point you made about projecting from the individual customer's challenge to a broader, interesting research problem is one that I'm also interested in. Can we maybe start there? I'd love to get your take on that.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:05:28] Yunyao Li: Sure. So, maybe I can share a story. When I joined IBM, I worked on a project called the SystemT. SystemT is a declarative system for natural language processing. And I have to say, to a certain extent, I'm still working on this system. The reason is that when we have a larger research agenda, we cannot solve the problem at once.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, for example, how did the system come into being? That was because at the beginning, we wanted to build a better enterprise search system. So, when we were trying to support enterprise search internally within IBM, we found the traditional AI systems do not understand the document enough, but once you differentiate internet search and the internal searches in internet search. When you try to find the answer to a question, maybe it's only one page that has the answer. Unlike when you do a\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"Unlike when you do a Google search on the internet, when you search for a certain question, you may have hundreds of pages. So, [plain] internet it's really important to understand every single document. And that really motivated the team to build a natural language processing system.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='And then, at that point, what we found is there are a lot of problems in creating natural language understanding system. But at the most basic one is really, for example, \"Do information instructions identify important entities, identify important events and so on?\" But at that point, we don\\'t have a very scalable system to perform the task.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='So, then we\\'ll start building the SystemT where we abstract out, \"What are the common text analytics operations that we need to capture? Then we built the system. At the beginning our concern is about expressivity and the [around hand] performance, to be able to express the kind of tasks that are important for supporting enterprise search.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='Then as we go, we find out that, \"Okay, we can build a system that is really good to build in extractors for supporting enterprise search.\" But then we want to enable more people to use them, right? [So, it\\'s kind of like] saying, \"Okay, now we have the problem of how do we build a better tooling into it? How do we incorporate a more advanced machine learning capability into it?\"', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, at a different period of time, we have different focus, but overall, because we have this one bigger project, we can build one thing top the other. I think that's really the advantage of working in an industry lab, where our research is not a bounded by a fixed period of time for grant. But it is kind of generalizing the overall lifecycle. Like we have a concrete, a business problem.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='For example, we started with, \"How do we support a better enterprise search?\" Right? Then it turns into like, \"How do we build a system to support a class of such a problem?\" And then, we solved some of them, we built some prototypes, we evaluated with concrete use cases, and then we get a feedback. When we can solve certain kinds of concrete problems, we can push it out into the wild, and then we get additional feedback from the wild. Then we\\'re encourage to say, \"Okay, now we have this system.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='we have this system. Should we focus on improving the system itself? Or should we focus on the toolings? Should we focus on other things?\" I think a lot of the work from the team really comes with the same life cycle.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:09:08] Sam Charrington: Interesting. It does strike me that there's maybe a unique IBM element to this approach that carries through in different areas of research.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:09:20] Yunyao Li: Yeah, I think that it is possible. The one thing that is interesting in the [forum where I am], IBM is an enterprise-facing company. So, when we build things, even within research, we always think about how do we enable other people to use this? How do we build things that other people can leverage? I think in some of the--like we mentioned Google, right? So, if you think about do they share, tyically what they share is not a big system. Like they share maybe a model or', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"maybe a model or some ideas, but then other people incorporate it into their own work. But within IBM, I think we're often really focused on empowering other people, the [tooling type].\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"This is also passion. Like for example, the kind of work we're going to talk about like human-in-the-loop system and so on. You don't really see that a lot in other companies because our consumers facing--the kind of challenges they have to address, it's very different from ours because consumer-facing basically means people...you know? Also, like Microsoft. Microsoft Research and IBM Research are more similar to each other than iBM Research and the Google Research, because both IBM and\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='because both IBM and Microsoft are enterprise-facing.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:10:41] Sam Charrington: Got it. Well, let's maybe jump into some of the challenges that we referenced earlier. When you are thinking about and trying to help teams productize NLP in the enterprise, what are some of the challenges that you run into and how do you think about those challenges? How have you organized those in your head?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:11:08] Yunyao Li: Yeah. So, that's a very good question. I will say we can think of the full category or major challenges. One is complexity. Complexity in terms of--because we'll talk about natural language processing, right? In terms of the complexity of the document, we have to deal with and the complexity of the tasks themselves, we have to deal with.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"The secondary category is small data. So, again, we want to talk about enterprise-facing challenges, right? We also have to build things that work for everybody, but we don't necessarily have data that are representing everyone's problem, right?\\n\\n[00:11:49] Sam Charrington: Yeah.\\n\\n[00:11:49] Yunyao Li: So, therefore we need to be able to address this small data problem, either based on what we have internally or have some way to enable people to provide data for us to help themselves.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"And then the third part is customization. No matter what we build, how well we build it, the out-of-the-box capability may not be sufficient for a customer's specific use case or works as well as it could be on their own data. Then, how do we enable the customers to quickly costumize? What do we build to fit into their use case their data very quickly using the [tool] to not necessarily require someone like me, some with a PhD degree to work with them? So, instead maybe someone with the business\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='with the business knowledge to be able to do the work on their own.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"And then, the fourth part is the explainability. I know everybody's talking about [Trusted AI] and so on these days, right? One big part of trusted AI is explainability. Then here, we need to understand what kind of explainability makes sense to a wider kind of audience. And how do we provide variety of explainability to help people?\\n\\nSo, I would say, yeah, those are the four major challenges we are focused on from the enterprise natural language processing point of view.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:13:18] Sam Charrington: And when you think about those challenges, do you think about it independently, meaning do you have a set of solutions or a set of research directions to try to address complexity and a separate set to try to address small data, etc.? Or is there a way that you unify these in the solutions that you're trying to apply to these various problems?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:13:45] Yunyao Li: Yeah, I would say we have a few common approaches, a combination of them to solve all the problems. Maybe with different combinations. I think the four things we often you are the following.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='Number one is data augmentation, right? The second is to have a very powerful declarative language that captures some of the main primitives that are important to conduct the task. And the third one is neuro-symbolic AI, where we leverage the best of both worlds in neural network, as well as the symbolic system. And the fourth one human-in-the-loop. How do we involve humans beyond just providing labeled data? So, those are the four things. Basically, the secret, the formula that we have been', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='that we have been following. And therefore to solve different challenges, we may use a combination of two of them or three of them.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:14:44] Sam Charrington: Got it. Yeah, got it. I want to go through those in turn, but maybe to set some context, it'd be helpful to have you talk about some specific challenges and where each of those comes in.\\n\\n[00:14:58] Yunyao Li: Sure. I think maybe I can describe a particular system we have recently built, and I think that this system is kind of representative for all the challenges.\\n\\n[00:15:06] Sam Charrington: Okay.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:15:06] Yunyao Li: So, one I've been working on with the Watson Discovery team was to build something called Watson Discovery's Content Intelligence. What this system does is to enable lawyers and law professionals to quickly review contract documents.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"If you think about a contract, it's probably one of the most important business documents in the business world. And it's very expensive to review those contracts because you need to hire legal professionals and the contracts so often have many, many million pages and contain a lot of the information that is challenging, even for you and me to understand, right?\\n\\n[00:15:48] Sam Charrington: Yep.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:15:49] Yunyao Li: So, to build out that system, what is required? First of all, the first step is a lot of contracts are in PDF format. So, we need to convert the PDF into a form consumable by the machine, right? Then secondly, we need to build models to simulate what the non-professionals will do so that we can can help them. So, [what kind of] understanding is involved on how [inaudible]. Given every single document, identify the clause. For simplicity, you can think of sentences. For', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='of sentences. For every single sentence, identify, what are the categories of that particular sentence and what are the parties involved in a sentence?', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='For example, if I say, \"The buyers shall pay supplier $1 million,\" right? So in legal terms, this is the obligation. And the party involved is a buyer and a supplier. And then, there is some amount. Then we turned it into--first of all, identify the sentence, identify sentences from the document and then do a classification so that we can categorize the sentence and also do instruction to extract what are the parties involved like supplier and the buyer.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='So, now once we have this system built, it will not work perfectly, right? So, we need to surface it to a legal professional so the legal professional can say, \"Okay, now I want to review all of the clauses related to obligation and then look at those sentences to be able to say, \\'Okay, this is indeed the obligation. I want to do something like mark it as high-risk or low-risk, or no problem.\\'\"', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='But it still has the challenge that we just mentioned, right? Complexity. First of all the complexity involving the document itself, the document is the multi-paged PDF document that we need to preserve all the structure, all the information. Assuming the document conversion is correct, we also need to identify the document structure to be able to identify individual sentences under the context. Right?\\n\\n[00:18:08] Sam Charrington: Right.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:18:09] Yunyao Li: Then why is that a small data problem? Because when it comes to a contract, nobody's gonna share their contract with IBM for us to create a training data, right? So, if we want to build a model, we have to rely on IBM contract data. But at the same time, what we build needs to work for other people, right?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"Then why is that a customization problem? Because even though we're talking about the legal professionals follow some general taxonomy related to the classification, every single company, they may have some difference. For example, if a sentence mentions patent of a trademark, it can be viewed as a clause related to intellectual property.\\n\\n[00:18:58] Sam Charrington: Right.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:18:59] Yunyao Li: But some companies want to separate them. They want to say, \"Okay, I only identify all the clauses related to trademark as trademark, but everything else related to the intellectual property is intellectual property.\"\\n\\n[00:19:13] Sam Charrington: Okay.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:19:14] Yunyao Li: And then finally, explainability. When we surface the results to the legal professionals, especially when there\\'s a mistake from the prediction, we need to explain to the legal professional why we predict this sentence as something, right? Like, \"This is obligation rather than something else.\" We need to explain that.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='And also, what that does to help us is when they say, \"This is not correct,\" we can also look into potentially how to fix them. And they can explain to us why a certain sentence is not a labeled correctly, like what I just described earlier related with customization, right? When they come back to say, \"Oh, this sentence should be labeled a trademark instead of intellectual property,\" they can explain to us to say, \"Okay, for this particular sentence, you identify this clause related to', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='clause related to trademark, but in our company, this is regarded as a trademark rather than intellectual property.\" So, they also have the model developers to make some changes.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='Yeah. So, I hope this example kind of illustrates all the different threads. But I will also be happy to talk about how do we solve that?', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:20:30] Sam Charrington: Yeah. Yeah, we'll definitely do that. One question that does come to mind...I've talked in the past with folks that are working on these production NLP systems. And over time, the need to supplement the learn models with rule-based systems and heuristics has decreased. And I'm curious, in the cases that you deal with. In addition to the data augmentation, declarative, neuro-symbolic, human-in-the-loop, are you still worrying about rules and exceptions and all of these\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='and all of these things as well? And do you see those decreasing over time?', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:21:14] Yunyao Li: I think, I can say our interest--I think depending on the use case. So, for example, for some use case when full explainability is important, we are going to see a requirement to combine both.\\n\\nSo, let me give you an example, right? If we think about model of development, it has a life cycle, right? We'll have data gathering. We have developing the model itself. We have test and validation.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='So, for some industries, for example, for retail banking. The training, test and the validation, what we learned is if you use a black-box model, like a [neural approach], assuming you have sufficent data, the training is very fast. Hence, it also will not take too much time. But a validation will take a lot of time. So, what they in do in validation really ensures the model works as a predicted under different variable conditions, and also be able to explain why certain predictions produced the', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='produced the particular results versus what is expected, right? So, this takes a lot of time.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"If we use rule-based approach, it's kind of opposite. So, the development of this rule is taken a lot of times. Testing also takes some time. Validation doesn't take too much time. So overall, you see the time and effort distributed in different ways.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='So, what my team has been working on is actually kind of getting the best of both worlds. So basically, what we do is we take a neural network. We leverage all the advantages of neural network to be able to learn from larger model data, right? But then, we produce a set of rules that are completely transparent and explainable.\\n\\n[00:23:09] Sam Charrington: Okay.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:23:10] Yunyao Li: So, the advantage over this, a domain expert can actually come in to do further inspection and augmentation to ensure the model does not just learn from the data, the model also learns from the domain expert, the corresponding domain knowledge.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, the benefit of this approach is the training does not take as much time as the purely rule-based system, right? Takes similar time as whatever approach you are taking for black-box model. Testing is also similar, but a validation takes significantly shorter amount of time than if you take a black-box model. Depending on the use case, right? In some use cases, you really don't need to have full explainability. Then, I think using neural models probably is the way to go. But in the use cases\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"But in the use cases where explainability is important, it's important to hold us somewhat accountable when the system makes a mistake, so then this approach works really well.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='Another aspect is remember what we were talking about, about a small data problem?\\n\\n[00:24:22] Sam Charrington: Right.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:24:23] Yunyao Li: So, the issue is in a lot of the areas, we don't have sufficient data. So, when you learn from the data alone, it will not capture the whole domain knowledge, right? I think, in our experience, the domain experts really like the fact that they can not just provide input by labelling, they can also provide an input by inspecting what was learned from the model and a make changes, not just to understand how the model performed, but they're able to make changes.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='For example, a simple sentence like what I just described earlier. You say, \"Okay, buyer should pay supplier $1 million.\" A potential rule that we can learn is when there is a predicate indicating, like a verb indicating purchase, indicating some business transaction. And then there is a modality of a necessity modified on a particular verb, then it\\'s potentially an indication of negation. This is something completely transparent. We can learn such a rule. But what are considered are the', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='considered are the important business transaction verbs. This can be given by the domain expert, not just by learning from the data, right? We can also let the domain expert to inspect the [niche/initial] of the dictionaries we learned, [initial/initial] rules we learned so that we can the insure their knowledge is captured by our model.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"And then, we can combine, right? So, this model can be then combined with a black-box model so that we can really ensure the overall performance is as good as possible, but at the same time, we're able to predict or explain significant portions of the prediction. And how the two models are combined together, is depending on your use case.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='For example, if you were to say, \"I want to have as good a performance as possible,\" then if I can explain some of the results that\\'s good, then we can combine in one way. Or if you were to say, \"Explainability is most important to me.\" Then, with that, I also learn how good the performance is then you can combine these two in a different way.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='With this particular approach, we really can get the best of both worlds, be able to leverage the fact that neural network is very powerful to be able to really capture [novel nuances] from the data that is very hard to express in rules, right? But at the same time capture, as much as possible, the domain knowledge that can be clearly articulated through rules.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='Another thing I want to mention is the rules are not based on syntactical [problems]. The rules are based on obstruction of [terms] through language understanding. Like for example, given a sentence, \"Buyer shall pay supplier,\" through natural language understanding it shows money passing. We will know there is an action of pay and then, the performer of the action is the buyer and the target of the action is the supplier. And then, the manner is pay in dollars. So, this kind of the semantics is', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"of the semantics is captured through advanced natural language understanding, therefore we can express rules in a very concise, but a very powerful way. I think that's another thing people need to think about.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='Rules are not necessarily one token for another, right? Traditionally, when we think about rules, it\\'s like, \"Okay, when you said \\'buyer,\\' maybe in the following two tokens there is a supplier.\" But then, that cannot capture the nuance of language, right? But if we build rules on top of semantic abstraction, they can be much more powerful. And then, behind the scenes, it\\'s also leveraging deep learning, right? So, behind the scenes, leveraging neural network models to do natural language', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='do natural language understanding.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:28:29] Sam Charrington: Got it, got it. And now, just to make sure that we're on the same page. What you described, I came at it from the perspective of rules. But is this the neuro-symbolic AI that you spoke about earlier?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:28:43] Yunyao Li: Correct. Correct. Yeah. So I think, neuro-symbolic AI, you can basically think of the two approaches, right? One approach is you embed symbolic information or expression into a neural model, right? That's how people can ingest some domain knowledge into a neural model, but then the neural model coming out, it's still not a completely transparent. Right? The other way you can do this is you can use the neural model to produce a symbolic model or symbolic obstruction, then we\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='obstruction, then we can build a symbolic model on top of it.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"Right now, imagine we can have both at first, but what I'm describing is more of a ladder where we leverage neural models to empower the symbolic model because the symbolic model has a lot of advantages that people are fully aware. Explainability and the part where it's easier for people in the [actual ways] to understand. Yeah so, this is one particular neuro-symbolic approach way have been taking.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:29:47] Sam Charrington: And then one of the other techniques that you mentioned was the use of declarative languages. I'm imagining that you've used this neural model to create this abstract rule, let's say, about a particular scenario you want to make that accessible to the humans in the loop, who we also talked about. A way to do that is to represent this abstraction, using some kind of declarative language.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:30:19] Yunyao Li: Yeah, I think that's a very good point, right? So, you can express rules in grammar. But the challenge is that grammar also dictates how the rules will be executed, right? Then, that'll make the rule creation much more challenging and less expressive and also how [long time] performance issue.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, we can overcome that by leveraging the declarative system we mentioned the earlier, like the system I have been working with since I joined IBM. If we can separate the execution from the actual semantics, so you can specify the semantics using declarative language, but how it will be executed is determined by the optimizer. The optimizer would determine what's the most efficient way to execute it.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"SO, for exampe, my role is to identify all the sentences that contain business transactions and encode the modality indicating necessity. I can do it in the traditional way, right? One is I can identify all the sentences with necessity and then see whether there is the business transaction next to it, or I can do the other round. Which one's more efficient is decided by the optimizer. Like when I created a rule whether manually or automatically, I don't need to worry about execution. The\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='about execution. The execution will be done automatically by the declarative system to ensure we get the most optimized plan in terms of execution.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:31:55] Sam Charrington: And when we talk about execution in this context, what do we mean? We typically think of neural network inference or even more broadly, ML model inference as kind of this one--you make a request, you get a prediction back. Are you thinking about execution more from the perspective of information retrieval and queries and that kind of thing?', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:32:23] Yunyao Li: So, here we have a rule based on this kind of model, right? So, for example, for simplicity let's say we do two parts. One part is just do natural language understanding. The second part is just enforce the predicates, right? So, the execution is composed of a few different options. One option is that you perform this natural language understanding operations, the neural model we have, on every single sentence. Then, for every single sentence you also check whether it\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"check whether it contains any business transaction mentioned, and also some words indicating necessity. So, that's one way of execution.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"Another way of executing is that I can actually do some optimization. Instead of looking at every single sentence, I can first retrieve only the sentence that contains the business transaction. Then I perform natural language understanding. Then I check my predicates. So, it's really how we produce the final results. That's the different ways to produce that final results and how we do that, [you're facing] the manner. So, that's the execution I'm talking about.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:33:43] Sam Charrington: Got it, got it. So, to maybe recap this and put it back in the context of this original problem where you're trying to enable legal discovery across lots of contracts, one approach one might take is to use traditional deep neural networks and maybe a supervised learning kind of thing, or even unsupervised and clustering the different clauses or sentences. But what you've found is that by combining, by using the neural network instead of to classify, but rather to do\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"but rather to do something akin to like entity extraction or to semantic parsing, you can use that to generate this, essentially a rule set, that's expressed in this declarative language. And then you've got a system that executes those rules against a given contract and uses that to essentially make sense of it and identify whatever it is that you might want to identify at a give time.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:34:54] Yunyao Li: Correct. Yeah. On the [one hand] you can view it that way, but we can also do a combination, right? So, you can basically think of--I can either build a black-box classifier, or I can get a white-box or I combine the black-box and a white-box together so that I can get to the best of both worlds. So, I think in reality, we actually do both.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"I think the challenge of doing this black-box, another [challenge] data formula. Especially when we started with building the product, we don't have even a lot of labeled data.\\n\\n[00:35:26] Sam Charrington: Yeah.\\n\\n[00:35:28] Yunyao Li: And also, as I mentioned, we have this small data problem. We have data from IBM, but we don't have data from other companies.\\n\\n[00:35:35] Sam Charrington: Right.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:35:35] Yunyao Li: How do I ensure the model I build works well? So here, the out-of-domain performance is very important. So, we actually started there with a model with a different approach, right? You can think about it. I mean, in IBM Research we also build a lot of different neural networks. Anything that's accessible to other people we also have it. But when we built them side by side, what we found is that the in-domain performance for the deep neural network works really, really well.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='really, really well. But then, it drops very significantly when we do out-of-domain.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, that's really passionately motivated us to build more of this transparent model so that the out-of-domain performance is very similar to in-domain. Then, we can augment this particular model if we want to have a better performance. So, say if we have additional training data, we can also augment this with a black-box model, but at the same time, we can benefit from the explainability, transferability and also be able to really quickly start with a particular customer's use case without worry\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"case without worry about training data. Because, I think, a lot of times I'm deeply involved in natural language processing research, right?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, if you look at the papers, people often assume we already have labeled data very nicely available. Then, if you don't have labeled data you can just do crowdsourcing. But in the case of enterprise applications, I cannot even label this data. The contextual information is really, really rich.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='I remember at the beginning, when we built this product, we looked at all the sentences and two sentences looks almost identical. We go to ask the lawyer to say, \"Okay why? Why are those two sentences that look identical are labeled differently?\" The lawyer tells us, \"Oh, because one is within this section with this information, but the other do not.\" Right? Again, how do you even capture--let\\'s say you have this information, I can quickly and basically encode a rule to say, \"Okay, take this', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='\"Okay, take this section information into account.\" Right? I can do that in a few minutes. But the thing about how do I retrain my model to do that? Now I have to... yeah.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='So, in general, I would say depending on the use case. So, in my opinion, there is no one solution. We need to really use the combination of all this technology, the techniques available in our tool kit and take the practical challenges and also what\\'s the final goal in mind, right? Like for example, in our case, our goal is not to say, \"Build the best possible model for IBM contract.\" If that\\'s my goal, I don\\'t need to have this approach. I can just do this, the training and then have a model', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='then have a model that works really, really well for in-domain.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='But our goal is to build a good model for other people and enable them to customize. And that really comes to the solution that I mentioned, right? So, we want to take advantage of both.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:38:54] Sam Charrington: And describing that solution, you mentioned a lot of different options, the white-box, the black-box, etc. I'm wondering where you're making those decisions. It's not at the level of product because you want--I'm imagining--a platform that kind of does--they can handle multiple use cases. Do you have different paths that you go down for different use cases? Or am I thinking about this incorrectly and it's more of you have this tool kit and you have to apply this\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"have to apply this toolkit more in a consulting or orientation when you're faced with a particular use case?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:39:42] Yunyao Li: I think there are few different ways to approach it. One is like, for example, when we build the what I just described: this particular offering in Watson Discovery's Content Intelligence, it's one offering, right? And then, in the other offering, we take this particular approach and then, we show it's really useful.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"But assuming the customer comes to me with something else, one thing we're actually doing right now is to take more of an AutoAI approach, where the user gives us the constraint. We will figure out, based on the constraints they give to us, what's the optimal combination. So, you probably are aware that AutoML is a very trending topic. So, for example, HuggingFace recently pushed out a new feature called the AutoNLP, right? Because even with the black-box, you still have a lot of challenges like\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='of challenges like which models you use, how do you [tune/choose] the hyper parameter and so on?', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='So, here actually we think about the main parameter we introduce is we have additional type of models and then we have additional ways of ensembling them together. And how we do those could be automated when the user specifies constraints. So, for example, the user can say, \"I want to have the best performing model with some explainability.\" Right? Or the user can say,\" I want the best performing model. I don\\'t care about explainability.\" Then with those constraints, we can automatically figure', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='automatically figure that out.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"This is something we are building in our project for the other [Auto Air Force Task]. So, we're building all these operators, that are supporting different kinds of model and different models have different properties. So then, based on the user constraints, we can decide which combination of models we use and then, which model to refine further. We can refine the hyper parameter tuning and refine how do the final ensemble.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:41:51] Sam Charrington: Got it. Got it. Got it. Since you mentioned the AutoNLP and HuggingFace, I'll quickly mention to folks that I interviewed one of the folks who worked on that, Abhishek Thakur, and we'll drop a link to that interview in the show notes.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"But I want to get back to data augmentation, because we haven't really talked about that so much here. And I think it's often easier to think about how to do that in the context of computer vision. Add noise or change the orientation or flip or rotate or that kind of thing. What does that mean in the context of NLP and how have you included it or incorporated it into your projects?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:42:36] Yunyao Li: Yeah, sure. So, talking about data augmentation in NLP, actually, there is an excellent tutorial or [survey] paper that came out very recently that summarized some of the techniques. I can send the link later. But in the context of what we are working on, we do data augmentation in a few different ways.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"The first one is--so I mentioned we do natural language understanding, right? We do--data sentences we parse into some semantic structure. We have enough data for English to do that. However, for other languages, we don't have this nice data. We don't have labels then how to perform the same task, but we want to also support other languages. So, one technique we have been using in terms of data augmentation is we can leverage the fact there's the [by text]. We have a sentence in one language\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='in one language like English and a sentence in another language that is a translation of the English sentence. We can do sentence alignment, right? Align each token with each other, and then we can project the annotation we produce in English into other languages.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So now, we have some very noisy label data to start with, right? Because you can think about there's always loss in translation, right? So, when you do this projection problem, there are going to be some mistakes. So, we also do additional filtering to ensure that the data we produce is as good as possible. And then, we're gonna use this data to train a semantic [parsing]. I showed them [semantic parsing] in the other language to further augment the data. I can now repair the data.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='So, maybe after a prediction, for example, in my sentence, I only have some portion with annotation and in the other portion we do not, then we can do this [bootstrapping] to other additional ones. So, this way we can automatically, at scale, produce large amounts of data. So, this is one way to do data augmentation.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"Another way you can also do it is--so for example, one of my colleagues, they have been working on dependency parsing for other languages. Again, we may not have sufficient data for other languages. So, what do they have done is they translate the English sentences of other languages into English sentences and then back and forth. So, this way you can also produce large amounts of what we call [sewer] data. It's not good data because it does still contains a good amount of noise, but when you\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='noise, but when you train from this data, the neural model is able to distill the noise and to be able to learn a pretty reasonable model. A lot of the data augmentation in natural language [cannot] do this synthetic data or annotation projection, annotation transfer.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"There are also ways to generate them. Like for example, if you have--there's actually a recent paper we published in ACL early this year. So, one of the tasks that is challenging for the parser is handling questions because most of the training data for natural language processing are statements, right? News reports and so on. But often we have data load that actually are questions. So, what we find is the parser trend of using the typical datasets do not work very well for questions. But then,\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='questions. But then, label question is very expensive. Producing labels that are for questions are really expensive.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='So, what we did is there is a datset of called the question bank. It has some, maybe a couple of thousand sentences and so on. So, we basically generalize from those questions from the question bank to generalize into templates. So, with a template, it generates a lot of label data for questions. And then we can add those generated questions back into the training data so that the parser can handle questions very well.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"It's actually [pretty extend] similar to what people are doing in computer vision, right? It's just how you manipulate the data is different, because well, you don't deal with text here, instead of vision.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:47:03] Sam Charrington: Nice, nice. We haven't talked much about human-in-the-loop. I think a lot of our folks are familiar with some of the common uses of human-in-the-loop. Of course, exception handling is one that comes to mind. Is that the kind of thing you are referring to when you mentioned it?\\n\\n[00:47:25] Yunyao Li: That's a very good question, because I happen to have a very strong opinion about that. But I don't know.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"The human-in-the-loop is actually very broad and I can describe, a few different aspects. In my opinion, humans can be very important as part of the model development process, right?\\n\\n[00:47:48] Sam Charrington: Okay.\\n\\n[00:47:48] Yunyao Li: Often, when we think about the human-in-the-loop, it's more about labeling.\\n\\n[00:47:52] Sam Charrington: Sure.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:47:52] Yunyao Li: Right? Like how do we involve people to provide label data? That's very important. In fact, we have spent a few years trying to speed up how we enable average persons to be able to provide high-quality data for [inaudible] parsing because our initial way of doing this shows that the human cannot perform as good as our machine learning model. Then when you do come out with that more intelligent flow to enable average people to do as much as possible and then enable experts\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='then enable experts to do the rest.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, I think that's one big part, when we talk about the human-in-the-loop is how do we enable a humans to generate high-quality data? That's not necessarily all being done by crowdsource workers because not every task is possible, but then at the same time, we don't necessarily need to always fall back to the expert in the loop. So, we need to kind of have a crowd in the loop but at the same time involve experts or automatic methods as much as possible.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"Then Watson people don't really talk too much. So, human-in-the-loop is the model development. The reason is very simple, most of the time, when people talk about a model development, you are talking about a black-box model, right? But when we talk about white-box model or grey box model, we want to involve humans in the loop in a few different ways.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"One is what I described before, we use this neural network learns by [trying to run] the model. Now, humans can inspect the model, augment the model, modify the model. That's one big part of human-in-the-loop. Right?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='The second part is maybe the users do not need to give us a lot of data at the beginning. Instead, we can have the model creation and data gathering in one intelligent simplified mode. Like for example, when I talk about classification of this particular class. So, instead the user gave me a few thousand label data, I tune the model. And then, we can run it. What we can do is the user may not even specify a [parse] up front. The user just says, \"Hey, this sentence is interesting.\" I will label a', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"I will label a few interesting sentences as the example, and then let the machine figure out what are other similar sentences. But again, the machine may not fully understand what I mean by similar. So, the machine will propose some potential interpretation. Also, the user provides feedback and then other users provider feedback, the machine can learn a bit more and refine what the machine has learned. And in the end, it will produce a model, but it's a very collaborative process, right?\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='And in between, the user may go beyond, \"Just give me an example.\" The user may even give me a rationale to say, \"Here\\'s why I think this sentence is interesting.\" Or, \"Why I think, what you propose is wrong.\" And then, it\\'s very interesting to incorporate this, what we call rich feedback into the machine learning process. Again, this is like a model development process.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='And then, another approach is as I mentioned before, I will have this declarative system. The declarative system is actually very good for parse, because I have very [optimistic parses], right? So, rather than trying let the black-box model figure it out, we can specify that. But to specify that can be expensive. We can also have this process of users giving an example. I can explain to you the user, in my declarative language, what I have learned. And then, the user can give me either', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"can give me either additional feedback or modify that particular declarative statement directly. So, that's one big part of human-in-the-loop model development.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"Finally, about user feedback. So, how do we enable the user to provide additional input to the system when is the system is already deployed? So, again that's also an important part. Like think about today, in a lot of systems, if they users are not happy, you cannot really do anything. So, the system produces whatever it produces. That's it. But you can imagine a system where...for example, they contract intelligence system I mentioned before, right? When the user sees the outputs, they're\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='the outputs, they\\'re usually not completely happy with it. The user can explain why she\\'s not happy with the results. And then, can also maybe provide some additional input to say, \"Okay,\" let\\'s say, for example, \"in my company, we will differentiate trademark and IP.\" So, we can learn from those and that can come back to our development team to be able to say, \"Okay, is this something we need to address in our baseline model? Or is this something we need to address by enabling the user to be', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='the user to be able to do some customization?\" So, that allows us to do a much more intelligent model informant and maintenance.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='[00:53:20] Sam Charrington: Got it. Got it. It sounds like the elements of this that you feel most strongly about are a combination of closing the loop. So, you put the human-in-the-loop, but then close the loop so that it improves your model. But also, as an idea of intelligent human-in-the-loop, you use machine intelligence to optimize the way the human intelligence is being used in the loop itself.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"[00:53:44] Yunyao Li: Right. Exactly. I think we need to give the human more agency, right? We need to empower humans rather than just, you know? Sometimes if you think about it, if all the user can do is give you a label data and then leave everything to the machin. The human is almost powerless. You cannot do anything. You know the machine is not correct but as a domain expert, you don't know how to modify the model. You don't know what to do. You're kind of waiting, waiting, waiting.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='waiting, waiting. Hopefully, someone will incorporate the data or the knowledge properly. But when we actually give humans agency, I think that they can do much more.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"For example, actually in 2021, we can see a very interesting trend. In 2021, we [seized] three workshops from top NLP conferences that are related to humans and NLP. So, we have a workshop on interactive and machine learning. We have a workshop on NLP and the HCI, and then we have a workshop on data science with the human-in-the-loop language advancement. And next year, in 2022, we're also going to have a special theme in [NAACL] that is focused on HCI for NLP.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"So, basically, more and more--when NLP becomes more and more used in practice, humans become an important aspect. When it's just in the lab all you need to do is produce some numbers and then compare with benchmark data. You don't need to consult a human, right? But now, when the NLP is actually impacting business, when it's actually used by people, how do we use people to help with the entire development life cycle, including evaluation and so on? It becomes more and more important. And you can\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content='And you can see that trend.', metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"Sam Charrington: Awesome. Awesome. Awesome. Well, Yunyao, thanks so much for taking the time to share a bit about what you're up to and walk us through these four different tools that you've had some success with and delivering enterprise NLP.\\n\\nYunyao Li: Thank you so much for having me here.\\n\\nSam Charrington: Thank you.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'}), Document(page_content=\"All right everyone, that's our show for today. To learn more about today's guest or the topics mentioned in this interview, visit twimlai.com. Of course, if you like what you hear on the podcast, please subscribe, rate, and review the show on your favorite podcatcher. Thanks so much for listening and catch you next time.\", metadata={'source': 'content/data/537 - Yunyao Li.txt'})]\n"
          ]
        }
      ],
      "source": [
        "print(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857,
          "referenced_widgets": [
            "59baeec6d783438e8a798959fc6885c2",
            "f059f038342e430586d71dec52194793",
            "a437b3c6371f4303bcc8b5245fac08ea",
            "56f90d69416d4aa1a8b9c8daa016ba6a",
            "e0ab43141a5d44278cba23259229db0d",
            "bb8b910963f642829f20d1683a067abf",
            "1067f06e2aac41c894e6d619a1ad4e2b",
            "979a4dffb5364142b3c0142ef5ba5680",
            "5e378e4ea15646b2b55f67ece88a230b",
            "bb735781bd5e406b89bafdb01c0270a6",
            "98f220c88b1b494690b61d891c40dd4c",
            "3ec2b16cdaca440a96d3f2316d5c8504",
            "3d302f3a55b7469b9b6c8f29566e5917",
            "28f66c5017f648e886c8cb34ff96d2da",
            "f5740146f8cf490590bdcba943096ac8",
            "10dac229dff549c5b01f4e7dd9b129ca",
            "d7c9d379e72445d5a343f08d3a56ee76",
            "2b74c3090dad4a58b8549926fad86271",
            "3626ac95bc944c0ab056f33f7c64ca8c",
            "820df94b12cd4f2da911b89271980b9b",
            "5dae446e7a1d4b34962de9ac4456e014",
            "b7d02009e2074ba399cf2bb47946f083",
            "3b29d6cb19d84a13b697b90647075cb9",
            "86075f014ff346cdb926459e1b3db711",
            "a065eb2b40b34dd3a3ea1b65ce67002d",
            "57142f73a2a941c9a28fa8747a3d98d0",
            "9ff11a6f4ea445548739785086c5d669",
            "b0318f9195624f0987b07d8fa7b10a6b",
            "2cc9dea0129542f582f6c7d9877cc1c8",
            "248d087c8e414fe584227814160a7f2b",
            "0c003ee77ba44f13a3fae4a34c1328f6",
            "411eb90269d442f09ee052032cee09a5",
            "49b6d94c2eab42a99b695419074f8958",
            "9fb430b5ba8e4003a95c43c00d4e2d00",
            "25d3948447bd438d904efdfccc3d7ea0",
            "cabb9f7137f042859b32af306f34549e",
            "7b31d104d2fe4170849de99e81d400f4",
            "4f08da63072a4898b1d521fb4a876f0d",
            "21215f2fa6bb4b5982ddf0198a98e9d4",
            "98fda223455743638835b78eabd1d4b5",
            "4d8df2c34fca4eeeb87670fe25d29a8a",
            "7c0b9ac6cd5f4498b810f0b0beb802bb",
            "822d81dc5fdf49fe9f950bf839a7de2f",
            "aed9acfd105c44f09c2b9675457a0689",
            "549062259cb64f81a979d8700345f8e9",
            "b1dfa23ff85a4f2f828c900476ef0804",
            "adc53ec8fb6d48b59998093ee1c52b66",
            "2a8ed199e7e840fdae0f99d378ee9644",
            "dbcfcc38507c4df8b28599c3e7420350",
            "c7b2af652a0c41278e62fd447331acd6",
            "6bd26ba594fd4f0e87c4d9659483b233",
            "919e05f8e0af4b25b55986409dc1f2ef",
            "e1f8bde65bc84ce99902ce5de17ccb0e",
            "54b4391624a34d3fafa7cba61bffa269",
            "1667053ee9d349dca8c2170016a431cb",
            "f3285ec1908d48f295b63b7349967959",
            "ed1df9840ebb43edbd6d95b4fa1e3e04",
            "fd08f2fb701d456b89050272ca9bd20d",
            "c35cdfd8fac24ad0b5f07e76004525cc",
            "c254856a8a524e70a54fcfc1e389306d",
            "f91e3c066389464b986306eaf5db61c8",
            "8d27d15788a14d90ba20be096a46c442",
            "3d288674e7b140cf85ebff0b86662045",
            "c612d8951e2c4e279cf263cf2b2b70bc",
            "df9cf009019849839111ad0f22195e3d",
            "0c375fec344a4d109cd9d869430bb999",
            "cf85d1be377e47fdb11fd8f654a2d2c8",
            "e8154cdd6da945be90467e689f53c21f",
            "4bf75d64c602432a9c9ccf62f4454f5c",
            "4c31196cd8684de283a1544fac8b0c94",
            "3655e618833c4ac0b3b303a54c9c2c62",
            "f7a527e85b5246fc8eeb73b5cdc6f128",
            "8454c711aa4c42f1992bd81597293808",
            "deeea70f2a654af58073c63429472657",
            "b867fa2c3e424ad388d566a5bd5c580e",
            "4974341254624b059e9b4c9739c4acd4",
            "c974169e945e48528316b6d33902b8f8",
            "158f3842044a4c49bfb2edceb616f98f",
            "c9b848dea9eb4c52a447529c818b29be",
            "ce3d41add0c14319b4d20de160a9259f",
            "b04f1b4d17b3403894893087ec523a2b",
            "067f757f43db45cc8022e8fba5c9c817",
            "1686038625114cc48d8942f3d4893de9",
            "85e89982b0df473dba7649e3d464bae7",
            "b0cfa0cf699c457b9b8d8bacb9b98794",
            "71723a2d3a384acba891a37f2e5f48c8",
            "c8d53bc71965475498f147a5f8a908b7",
            "a22492795b384194879c071a2f452233",
            "e419f8bfded94d9b8c2b326af0dc6e70",
            "30e1579510dd478a8e397cc56fd3fc89",
            "67cd54af507240679e1a3596685d05f7",
            "b4da1de31cc84107ab3429bc62037381",
            "c62e0de5b14e403a88840d74fd642966",
            "111d8d310add429f9603fbadeac20cf5",
            "2c475b6f31c144019d72a429891b1f89",
            "3ef4dbff55a942efaf0f6582baf4c8da",
            "347d180f557d41dbad1ac2332c729271",
            "df1372bd5cb040ac85141d5f11e13343",
            "6a41612156be4c688425dd6a8e2d425c",
            "e2655b00362a46238665bb973c18bff8",
            "59b6ac5d644048faa53103b561462eaa",
            "a2058ae051734f299da6e4aa329a4844",
            "4b33b4a1c9344044a6fc5d7e00438f5d",
            "63ecc46d58c84800be60d0bafe968ad1",
            "5cb8d31e4ea7496cb1b7be636ff1f0f6",
            "8101ef7678fb4535a82401039495efa3",
            "bc80761af4bd4506a7dce043b5bb1dcb",
            "aada1ceacb4949c290acdf68b561da8c",
            "6f633d3909424c8d9ea3c353f69b2534",
            "1012292cb6284d8b8b7dbe6da8089d03",
            "79029f8c0c9f4376af59bca97fc5bc83",
            "69c672cd74674eda925ab87e41360ae2",
            "8e89291c024044f3a21bfffb45ae1f4e",
            "b5873d590a154464894239be04937aea",
            "c4585a9ad4e0444f881a8c262766eace",
            "bc5fb63da52b4d6ea5279a371780c0e9",
            "3869c5c49f244907bfcdf3e862cddb34",
            "49a2b91eb9504c2781fb7fce431cbd18",
            "a530fc9783be4a7fb2dae89166d5df2b",
            "5c9496b5fa4540369265d9c11c3d6ca9",
            "698cbb3b46724f079132d9108e89e305",
            "ef5fbedad6724d8bb2c95a294c047880",
            "cae253847f634c359b844bbce9790286",
            "637ee292775f4d8e9e8e9fbeddedc9ab",
            "b21ab6efb2a846e59fb89ae16bc3c9c2",
            "deafe043ea334e60ad5dd87fcb9d3e51",
            "5c48fe79b60340e5bd5b55740cf1b732",
            "31074b283ec14133a7c9bada6aea11ce",
            "6d0545256e1b4893b50623facbfb5696",
            "2402bbbdd88a48bfa4ce51a12d25a3f2",
            "a1a5aa9bc8534451aa449405fe61d912",
            "802c1c2babca4409b7972b0cea66c78f",
            "14c27fddbbb3405e95f03eadf4b586be",
            "1f700c80bdbe4fc2a44826fa07874e7d",
            "a6c4eb8aa80b4adb8596ee26f6dac38e",
            "b3e7b167c30040518ad37a3993984843",
            "d8badcd24a4e489b83692dac0d3d8e8a",
            "01ab4a50d1cb4e4b810428cacc47cc33",
            "16fced5e75c245e3aaf9b90a1e12c70e",
            "325f251b981f4cd484cb67a0a77d9f31",
            "e5472172f7aa4a55806e39dfec56745b",
            "34b398d4010b40eca0c00193a3be877d",
            "820f869f678b44778fa4985cfd494832",
            "98557d5b7c184e5585cc393462bf968e",
            "e4f3845cf6ae4e4e962b04bd9a31942c",
            "2dcb289429e14663aeca16ae696a0018",
            "86b442b4220f4137b9d782cfc83db705",
            "de3524aeca7b4c41a044460c16897711",
            "7a921e69de4d49b6a8e09e9d1886878e",
            "ab97349ea06948db8eeac8125c901a0f",
            "18498a3349384437b2b59fbeffec1d67",
            "0c3f924672e64932b8c03f89bbfad8e8",
            "112ee3c1fe3b4729aba2bb3518a7973d",
            "c6f7b982fd7f40f7ae8000816f235200"
          ]
        },
        "id": "F5GY9voPa0av",
        "outputId": "5516d2a2-91d8-40b8-b0cd-dad0434e78c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/cataluna84/anaconda3/envs/generative-ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s2p3rUwvOvW",
        "outputId": "f47e5661-04ae-4e12-843d-42f64a29d6ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_result = embeddings.embed_query(\"Hello world\")\n",
        "len(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXhIY5SrrRec",
        "outputId": "5e3973e3-f60c-4e55-a73a-46fe1078b086"
      },
      "outputs": [],
      "source": [
        "# !pip install pinecone-client -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vySq5oI5sU5V"
      },
      "source": [
        "https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/pinecone.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hfIpYLV-acks"
      },
      "outputs": [],
      "source": [
        "import pinecone \n",
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=\"\",  # find at app.pinecone.io\n",
        "    environment=\"gcp-starter\"  # next to api key in console\n",
        ")\n",
        "\n",
        "index_name = \"demo\"\n",
        "\n",
        "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5r7YLpbchAD",
        "outputId": "5afe195d-df66-4a88-ff24-daeb6981f516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"[00:15:37] Ababa: Yeah, so thi- this is actually at the heart of the whole, uh, relational ethics trying to- to reframe the whole idea of what ethics is. So, because as you said, a lot of people working on AI ethics really are about, you know, whether it's explainability or calculating fairness or justice, it's really is usually lost in the fine grain details. So, um, it's not something implementable that I provide, but it's about kind of really zooming out and thinking, um, you know, what- what\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'}),\n",
              " Document(page_content='be the focus of AI ethics as opposed to, you know, hypothetical sentient beings.', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}),\n",
              " Document(page_content=\"[00:50:02] Sam Charrington: Yeah, that's maybe a segue to talking about ethics and responsible AI, and the intersection with computer vision. You've alluded to the importance of that several times in our discussion already. I'm curious if you would expand on your thoughts there and where you see the big challenges and opportunities.\", metadata={'source': 'content/data/549 - Georgia Gkioxari.txt'}),\n",
              " Document(page_content='[00:01:22] Ababa: Thank you.\\n\\n[00:01:22] Interviewer: Uh, so [laughing] your background.\\n\\n[00:01:24] Ababa: Yes. Yes, yeah.\\n\\n[00:01:25] Interviewer: How did you get started working in AI ethics?', metadata={'source': 'content/data/348 - Abeba Birhane.txt'}),\n",
              " Document(page_content=\"Uh, so we use that post Cartesian, uh, approach to- to get at the heart of how philosophically speaking robots or any machine learning tools or any machines at all are not the same beings as humans or even animals. And- and then the se-, the second part, uh, where we get adds, the urgent questions that AI ethics really needs to focus because sometimes, not sometimes, most times it's really frustrating to hear, uh, robot ethics classified as part of AI ethics. And for me personally, it comes\", metadata={'source': 'content/data/348 - Abeba Birhane.txt'})]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_similiar_docs(query, k=5, score=False):\n",
        "  if score:\n",
        "    similar_docs = index.similarity_search_with_score(query, k=k)\n",
        "  else:\n",
        "    similar_docs = index.similarity_search(query, k=k)\n",
        "  return similar_docs\n",
        "\n",
        "query = \"Did the guests talk about AI Ethics?\"\n",
        "similar_docs = get_similiar_docs(query)\n",
        "similar_docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlkrKhY1PMXm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01ab4a50d1cb4e4b810428cacc47cc33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067f757f43db45cc8022e8fba5c9c817": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c003ee77ba44f13a3fae4a34c1328f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c375fec344a4d109cd9d869430bb999": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c3f924672e64932b8c03f89bbfad8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1012292cb6284d8b8b7dbe6da8089d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1067f06e2aac41c894e6d619a1ad4e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10dac229dff549c5b01f4e7dd9b129ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111d8d310add429f9603fbadeac20cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "112ee3c1fe3b4729aba2bb3518a7973d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c27fddbbb3405e95f03eadf4b586be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f700c80bdbe4fc2a44826fa07874e7d",
              "IPY_MODEL_a6c4eb8aa80b4adb8596ee26f6dac38e",
              "IPY_MODEL_b3e7b167c30040518ad37a3993984843"
            ],
            "layout": "IPY_MODEL_d8badcd24a4e489b83692dac0d3d8e8a"
          }
        },
        "158f3842044a4c49bfb2edceb616f98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9b848dea9eb4c52a447529c818b29be",
              "IPY_MODEL_ce3d41add0c14319b4d20de160a9259f",
              "IPY_MODEL_b04f1b4d17b3403894893087ec523a2b"
            ],
            "layout": "IPY_MODEL_067f757f43db45cc8022e8fba5c9c817"
          }
        },
        "1667053ee9d349dca8c2170016a431cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1686038625114cc48d8942f3d4893de9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16fced5e75c245e3aaf9b90a1e12c70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18498a3349384437b2b59fbeffec1d67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f700c80bdbe4fc2a44826fa07874e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ab4a50d1cb4e4b810428cacc47cc33",
            "placeholder": "",
            "style": "IPY_MODEL_16fced5e75c245e3aaf9b90a1e12c70e",
            "value": "Downloading ()7e55de9125/vocab.txt: 100%"
          }
        },
        "21215f2fa6bb4b5982ddf0198a98e9d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2402bbbdd88a48bfa4ce51a12d25a3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "248d087c8e414fe584227814160a7f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d3948447bd438d904efdfccc3d7ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21215f2fa6bb4b5982ddf0198a98e9d4",
            "placeholder": "",
            "style": "IPY_MODEL_98fda223455743638835b78eabd1d4b5",
            "value": "Downloading ()55de9125/config.json: 100%"
          }
        },
        "28f66c5017f648e886c8cb34ff96d2da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3626ac95bc944c0ab056f33f7c64ca8c",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_820df94b12cd4f2da911b89271980b9b",
            "value": 190
          }
        },
        "2a8ed199e7e840fdae0f99d378ee9644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54b4391624a34d3fafa7cba61bffa269",
            "placeholder": "",
            "style": "IPY_MODEL_1667053ee9d349dca8c2170016a431cb",
            "value": " 116/116 [00:00&lt;00:00, 4.00kB/s]"
          }
        },
        "2b74c3090dad4a58b8549926fad86271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c475b6f31c144019d72a429891b1f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cc9dea0129542f582f6c7d9877cc1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dcb289429e14663aeca16ae696a0018": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18498a3349384437b2b59fbeffec1d67",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c3f924672e64932b8c03f89bbfad8e8",
            "value": 349
          }
        },
        "30e1579510dd478a8e397cc56fd3fc89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111d8d310add429f9603fbadeac20cf5",
            "placeholder": "",
            "style": "IPY_MODEL_2c475b6f31c144019d72a429891b1f89",
            "value": "Downloading ()cial_tokens_map.json: 100%"
          }
        },
        "31074b283ec14133a7c9bada6aea11ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "325f251b981f4cd484cb67a0a77d9f31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347d180f557d41dbad1ac2332c729271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34b398d4010b40eca0c00193a3be877d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3626ac95bc944c0ab056f33f7c64ca8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3655e618833c4ac0b3b303a54c9c2c62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3869c5c49f244907bfcdf3e862cddb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b29d6cb19d84a13b697b90647075cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86075f014ff346cdb926459e1b3db711",
              "IPY_MODEL_a065eb2b40b34dd3a3ea1b65ce67002d",
              "IPY_MODEL_57142f73a2a941c9a28fa8747a3d98d0"
            ],
            "layout": "IPY_MODEL_9ff11a6f4ea445548739785086c5d669"
          }
        },
        "3d288674e7b140cf85ebff0b86662045": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d302f3a55b7469b9b6c8f29566e5917": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c9d379e72445d5a343f08d3a56ee76",
            "placeholder": "",
            "style": "IPY_MODEL_2b74c3090dad4a58b8549926fad86271",
            "value": "Downloading ()_Pooling/config.json: 100%"
          }
        },
        "3ec2b16cdaca440a96d3f2316d5c8504": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d302f3a55b7469b9b6c8f29566e5917",
              "IPY_MODEL_28f66c5017f648e886c8cb34ff96d2da",
              "IPY_MODEL_f5740146f8cf490590bdcba943096ac8"
            ],
            "layout": "IPY_MODEL_10dac229dff549c5b01f4e7dd9b129ca"
          }
        },
        "3ef4dbff55a942efaf0f6582baf4c8da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "411eb90269d442f09ee052032cee09a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4974341254624b059e9b4c9739c4acd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a2b91eb9504c2781fb7fce431cbd18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b6d94c2eab42a99b695419074f8958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b33b4a1c9344044a6fc5d7e00438f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f633d3909424c8d9ea3c353f69b2534",
            "placeholder": "",
            "style": "IPY_MODEL_1012292cb6284d8b8b7dbe6da8089d03",
            "value": " 466k/466k [00:00&lt;00:00, 2.27MB/s]"
          }
        },
        "4bf75d64c602432a9c9ccf62f4454f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deeea70f2a654af58073c63429472657",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b867fa2c3e424ad388d566a5bd5c580e",
            "value": 90888945
          }
        },
        "4c31196cd8684de283a1544fac8b0c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4974341254624b059e9b4c9739c4acd4",
            "placeholder": "",
            "style": "IPY_MODEL_c974169e945e48528316b6d33902b8f8",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 92.5MB/s]"
          }
        },
        "4d8df2c34fca4eeeb87670fe25d29a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f08da63072a4898b1d521fb4a876f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "549062259cb64f81a979d8700345f8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1dfa23ff85a4f2f828c900476ef0804",
              "IPY_MODEL_adc53ec8fb6d48b59998093ee1c52b66",
              "IPY_MODEL_2a8ed199e7e840fdae0f99d378ee9644"
            ],
            "layout": "IPY_MODEL_dbcfcc38507c4df8b28599c3e7420350"
          }
        },
        "54b4391624a34d3fafa7cba61bffa269": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f90d69416d4aa1a8b9c8daa016ba6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb735781bd5e406b89bafdb01c0270a6",
            "placeholder": "",
            "style": "IPY_MODEL_98f220c88b1b494690b61d891c40dd4c",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 68.5kB/s]"
          }
        },
        "57142f73a2a941c9a28fa8747a3d98d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_411eb90269d442f09ee052032cee09a5",
            "placeholder": "",
            "style": "IPY_MODEL_49b6d94c2eab42a99b695419074f8958",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 406kB/s]"
          }
        },
        "59b6ac5d644048faa53103b561462eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb8d31e4ea7496cb1b7be636ff1f0f6",
            "placeholder": "",
            "style": "IPY_MODEL_8101ef7678fb4535a82401039495efa3",
            "value": "Downloading ()e9125/tokenizer.json: 100%"
          }
        },
        "59baeec6d783438e8a798959fc6885c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f059f038342e430586d71dec52194793",
              "IPY_MODEL_a437b3c6371f4303bcc8b5245fac08ea",
              "IPY_MODEL_56f90d69416d4aa1a8b9c8daa016ba6a"
            ],
            "layout": "IPY_MODEL_e0ab43141a5d44278cba23259229db0d"
          }
        },
        "5c48fe79b60340e5bd5b55740cf1b732": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9496b5fa4540369265d9c11c3d6ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb8d31e4ea7496cb1b7be636ff1f0f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dae446e7a1d4b34962de9ac4456e014": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e378e4ea15646b2b55f67ece88a230b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "637ee292775f4d8e9e8e9fbeddedc9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d0545256e1b4893b50623facbfb5696",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2402bbbdd88a48bfa4ce51a12d25a3f2",
            "value": 13156
          }
        },
        "63ecc46d58c84800be60d0bafe968ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67cd54af507240679e1a3596685d05f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef4dbff55a942efaf0f6582baf4c8da",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_347d180f557d41dbad1ac2332c729271",
            "value": 112
          }
        },
        "698cbb3b46724f079132d9108e89e305": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69c672cd74674eda925ab87e41360ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc5fb63da52b4d6ea5279a371780c0e9",
            "placeholder": "",
            "style": "IPY_MODEL_3869c5c49f244907bfcdf3e862cddb34",
            "value": "Downloading ()okenizer_config.json: 100%"
          }
        },
        "6a41612156be4c688425dd6a8e2d425c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bd26ba594fd4f0e87c4d9659483b233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d0545256e1b4893b50623facbfb5696": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f633d3909424c8d9ea3c353f69b2534": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71723a2d3a384acba891a37f2e5f48c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79029f8c0c9f4376af59bca97fc5bc83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69c672cd74674eda925ab87e41360ae2",
              "IPY_MODEL_8e89291c024044f3a21bfffb45ae1f4e",
              "IPY_MODEL_b5873d590a154464894239be04937aea"
            ],
            "layout": "IPY_MODEL_c4585a9ad4e0444f881a8c262766eace"
          }
        },
        "7a921e69de4d49b6a8e09e9d1886878e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b31d104d2fe4170849de99e81d400f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822d81dc5fdf49fe9f950bf839a7de2f",
            "placeholder": "",
            "style": "IPY_MODEL_aed9acfd105c44f09c2b9675457a0689",
            "value": " 612/612 [00:00&lt;00:00, 25.6kB/s]"
          }
        },
        "7c0b9ac6cd5f4498b810f0b0beb802bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "802c1c2babca4409b7972b0cea66c78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8101ef7678fb4535a82401039495efa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "820df94b12cd4f2da911b89271980b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "820f869f678b44778fa4985cfd494832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "822d81dc5fdf49fe9f950bf839a7de2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8454c711aa4c42f1992bd81597293808": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85e89982b0df473dba7649e3d464bae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86075f014ff346cdb926459e1b3db711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0318f9195624f0987b07d8fa7b10a6b",
            "placeholder": "",
            "style": "IPY_MODEL_2cc9dea0129542f582f6c7d9877cc1c8",
            "value": "Downloading ()7e55de9125/README.md: 100%"
          }
        },
        "86b442b4220f4137b9d782cfc83db705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_112ee3c1fe3b4729aba2bb3518a7973d",
            "placeholder": "",
            "style": "IPY_MODEL_c6f7b982fd7f40f7ae8000816f235200",
            "value": " 349/349 [00:00&lt;00:00, 9.86kB/s]"
          }
        },
        "8d27d15788a14d90ba20be096a46c442": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e89291c024044f3a21bfffb45ae1f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a2b91eb9504c2781fb7fce431cbd18",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a530fc9783be4a7fb2dae89166d5df2b",
            "value": 350
          }
        },
        "919e05f8e0af4b25b55986409dc1f2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979a4dffb5364142b3c0142ef5ba5680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98557d5b7c184e5585cc393462bf968e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4f3845cf6ae4e4e962b04bd9a31942c",
              "IPY_MODEL_2dcb289429e14663aeca16ae696a0018",
              "IPY_MODEL_86b442b4220f4137b9d782cfc83db705"
            ],
            "layout": "IPY_MODEL_de3524aeca7b4c41a044460c16897711"
          }
        },
        "98f220c88b1b494690b61d891c40dd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98fda223455743638835b78eabd1d4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fb430b5ba8e4003a95c43c00d4e2d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25d3948447bd438d904efdfccc3d7ea0",
              "IPY_MODEL_cabb9f7137f042859b32af306f34549e",
              "IPY_MODEL_7b31d104d2fe4170849de99e81d400f4"
            ],
            "layout": "IPY_MODEL_4f08da63072a4898b1d521fb4a876f0d"
          }
        },
        "9ff11a6f4ea445548739785086c5d669": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a065eb2b40b34dd3a3ea1b65ce67002d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_248d087c8e414fe584227814160a7f2b",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c003ee77ba44f13a3fae4a34c1328f6",
            "value": 10610
          }
        },
        "a1a5aa9bc8534451aa449405fe61d912": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2058ae051734f299da6e4aa329a4844": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc80761af4bd4506a7dce043b5bb1dcb",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aada1ceacb4949c290acdf68b561da8c",
            "value": 466247
          }
        },
        "a22492795b384194879c071a2f452233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a437b3c6371f4303bcc8b5245fac08ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979a4dffb5364142b3c0142ef5ba5680",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e378e4ea15646b2b55f67ece88a230b",
            "value": 1175
          }
        },
        "a530fc9783be4a7fb2dae89166d5df2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6c4eb8aa80b4adb8596ee26f6dac38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_325f251b981f4cd484cb67a0a77d9f31",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5472172f7aa4a55806e39dfec56745b",
            "value": 231508
          }
        },
        "aada1ceacb4949c290acdf68b561da8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab97349ea06948db8eeac8125c901a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adc53ec8fb6d48b59998093ee1c52b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_919e05f8e0af4b25b55986409dc1f2ef",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1f8bde65bc84ce99902ce5de17ccb0e",
            "value": 116
          }
        },
        "aed9acfd105c44f09c2b9675457a0689": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0318f9195624f0987b07d8fa7b10a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b04f1b4d17b3403894893087ec523a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8d53bc71965475498f147a5f8a908b7",
            "placeholder": "",
            "style": "IPY_MODEL_a22492795b384194879c071a2f452233",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.73kB/s]"
          }
        },
        "b0cfa0cf699c457b9b8d8bacb9b98794": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1dfa23ff85a4f2f828c900476ef0804": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b2af652a0c41278e62fd447331acd6",
            "placeholder": "",
            "style": "IPY_MODEL_6bd26ba594fd4f0e87c4d9659483b233",
            "value": "Downloading ()ce_transformers.json: 100%"
          }
        },
        "b21ab6efb2a846e59fb89ae16bc3c9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1a5aa9bc8534451aa449405fe61d912",
            "placeholder": "",
            "style": "IPY_MODEL_802c1c2babca4409b7972b0cea66c78f",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 654kB/s]"
          }
        },
        "b3e7b167c30040518ad37a3993984843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b398d4010b40eca0c00193a3be877d",
            "placeholder": "",
            "style": "IPY_MODEL_820f869f678b44778fa4985cfd494832",
            "value": " 232k/232k [00:00&lt;00:00, 11.7MB/s]"
          }
        },
        "b4da1de31cc84107ab3429bc62037381": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1372bd5cb040ac85141d5f11e13343",
            "placeholder": "",
            "style": "IPY_MODEL_6a41612156be4c688425dd6a8e2d425c",
            "value": " 112/112 [00:00&lt;00:00, 4.47kB/s]"
          }
        },
        "b5873d590a154464894239be04937aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9496b5fa4540369265d9c11c3d6ca9",
            "placeholder": "",
            "style": "IPY_MODEL_698cbb3b46724f079132d9108e89e305",
            "value": " 350/350 [00:00&lt;00:00, 14.0kB/s]"
          }
        },
        "b7d02009e2074ba399cf2bb47946f083": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b867fa2c3e424ad388d566a5bd5c580e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb735781bd5e406b89bafdb01c0270a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8b910963f642829f20d1683a067abf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5fb63da52b4d6ea5279a371780c0e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc80761af4bd4506a7dce043b5bb1dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c254856a8a524e70a54fcfc1e389306d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35cdfd8fac24ad0b5f07e76004525cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df9cf009019849839111ad0f22195e3d",
            "placeholder": "",
            "style": "IPY_MODEL_0c375fec344a4d109cd9d869430bb999",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 608kB/s]"
          }
        },
        "c4585a9ad4e0444f881a8c262766eace": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c612d8951e2c4e279cf263cf2b2b70bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c62e0de5b14e403a88840d74fd642966": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f7b982fd7f40f7ae8000816f235200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b2af652a0c41278e62fd447331acd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d53bc71965475498f147a5f8a908b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c974169e945e48528316b6d33902b8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9b848dea9eb4c52a447529c818b29be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1686038625114cc48d8942f3d4893de9",
            "placeholder": "",
            "style": "IPY_MODEL_85e89982b0df473dba7649e3d464bae7",
            "value": "Downloading ()nce_bert_config.json: 100%"
          }
        },
        "cabb9f7137f042859b32af306f34549e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d8df2c34fca4eeeb87670fe25d29a8a",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c0b9ac6cd5f4498b810f0b0beb802bb",
            "value": 612
          }
        },
        "cae253847f634c359b844bbce9790286": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c48fe79b60340e5bd5b55740cf1b732",
            "placeholder": "",
            "style": "IPY_MODEL_31074b283ec14133a7c9bada6aea11ce",
            "value": "Downloading ()9125/train_script.py: 100%"
          }
        },
        "ce3d41add0c14319b4d20de160a9259f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0cfa0cf699c457b9b8d8bacb9b98794",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71723a2d3a384acba891a37f2e5f48c8",
            "value": 53
          }
        },
        "cf85d1be377e47fdb11fd8f654a2d2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8154cdd6da945be90467e689f53c21f",
              "IPY_MODEL_4bf75d64c602432a9c9ccf62f4454f5c",
              "IPY_MODEL_4c31196cd8684de283a1544fac8b0c94"
            ],
            "layout": "IPY_MODEL_3655e618833c4ac0b3b303a54c9c2c62"
          }
        },
        "d7c9d379e72445d5a343f08d3a56ee76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8badcd24a4e489b83692dac0d3d8e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbcfcc38507c4df8b28599c3e7420350": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de3524aeca7b4c41a044460c16897711": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deafe043ea334e60ad5dd87fcb9d3e51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deeea70f2a654af58073c63429472657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1372bd5cb040ac85141d5f11e13343": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df9cf009019849839111ad0f22195e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0ab43141a5d44278cba23259229db0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1f8bde65bc84ce99902ce5de17ccb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2655b00362a46238665bb973c18bff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59b6ac5d644048faa53103b561462eaa",
              "IPY_MODEL_a2058ae051734f299da6e4aa329a4844",
              "IPY_MODEL_4b33b4a1c9344044a6fc5d7e00438f5d"
            ],
            "layout": "IPY_MODEL_63ecc46d58c84800be60d0bafe968ad1"
          }
        },
        "e419f8bfded94d9b8c2b326af0dc6e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30e1579510dd478a8e397cc56fd3fc89",
              "IPY_MODEL_67cd54af507240679e1a3596685d05f7",
              "IPY_MODEL_b4da1de31cc84107ab3429bc62037381"
            ],
            "layout": "IPY_MODEL_c62e0de5b14e403a88840d74fd642966"
          }
        },
        "e4f3845cf6ae4e4e962b04bd9a31942c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a921e69de4d49b6a8e09e9d1886878e",
            "placeholder": "",
            "style": "IPY_MODEL_ab97349ea06948db8eeac8125c901a0f",
            "value": "Downloading ()5de9125/modules.json: 100%"
          }
        },
        "e5472172f7aa4a55806e39dfec56745b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8154cdd6da945be90467e689f53c21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7a527e85b5246fc8eeb73b5cdc6f128",
            "placeholder": "",
            "style": "IPY_MODEL_8454c711aa4c42f1992bd81597293808",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "ed1df9840ebb43edbd6d95b4fa1e3e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f91e3c066389464b986306eaf5db61c8",
            "placeholder": "",
            "style": "IPY_MODEL_8d27d15788a14d90ba20be096a46c442",
            "value": "Downloading ()125/data_config.json: 100%"
          }
        },
        "ef5fbedad6724d8bb2c95a294c047880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cae253847f634c359b844bbce9790286",
              "IPY_MODEL_637ee292775f4d8e9e8e9fbeddedc9ab",
              "IPY_MODEL_b21ab6efb2a846e59fb89ae16bc3c9c2"
            ],
            "layout": "IPY_MODEL_deafe043ea334e60ad5dd87fcb9d3e51"
          }
        },
        "f059f038342e430586d71dec52194793": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb8b910963f642829f20d1683a067abf",
            "placeholder": "",
            "style": "IPY_MODEL_1067f06e2aac41c894e6d619a1ad4e2b",
            "value": "Downloading ()e9125/.gitattributes: 100%"
          }
        },
        "f3285ec1908d48f295b63b7349967959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed1df9840ebb43edbd6d95b4fa1e3e04",
              "IPY_MODEL_fd08f2fb701d456b89050272ca9bd20d",
              "IPY_MODEL_c35cdfd8fac24ad0b5f07e76004525cc"
            ],
            "layout": "IPY_MODEL_c254856a8a524e70a54fcfc1e389306d"
          }
        },
        "f5740146f8cf490590bdcba943096ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dae446e7a1d4b34962de9ac4456e014",
            "placeholder": "",
            "style": "IPY_MODEL_b7d02009e2074ba399cf2bb47946f083",
            "value": " 190/190 [00:00&lt;00:00, 9.38kB/s]"
          }
        },
        "f7a527e85b5246fc8eeb73b5cdc6f128": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f91e3c066389464b986306eaf5db61c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd08f2fb701d456b89050272ca9bd20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d288674e7b140cf85ebff0b86662045",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c612d8951e2c4e279cf263cf2b2b70bc",
            "value": 39265
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
